%% The openany option is here just to remove the blank pages before a new chapter
\documentclass[11pt,openany]{book}

\title{Analyse syntaxique automatique du langage naturel}

\usepackage{pagenote}
\usepackage{booktabs}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{mathabx}

\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{snakes}
\usetikzlibrary{matrix}
\usetikzlibrary{shapes}
\usetikzlibrary{calc}
\usepackage{comment}
\usepackage{minted}
\usepackage{tikz-dependency}%dependency trees




\newtheorem{definition}{Définition}[chapter]
\newtheorem{exo}{Exercice}[chapter]
\includecomment{solution}
%\excludecomment{solution}


%%%%%%%%%%%%% For customising the endnote markers. Comment these out if you don't want them.
% To prefix each note number with the chapter number
\renewcommand{\thepagenote}{\thechapter-\arabic{pagenote}}

% To have a slightly different formatting for the endnote numbers in the text -- smaller text, sans-serif, square brackets
\renewcommand\notenumintext[1]{\space{\footnotesize\sffamily[FN-#1]}}

% To have a slightly different formatting for the endnote numbers in the notes section. Just the square brackets and sans-serif; normal size.
\renewcommand\notenuminnotes[1]{{\sffamily[FN-#1] }}

% If you want a different name/heading for the end notes
\renewcommand{\notesname}{End Notes}
%%%%%%%%%%%%% End customisation


%% THIS LINE IS MANDATORY
\makepagenote

\usepackage{hyperref}
\usepackage{tikz}

\newcommand{\ac}[1]{{\sc #1}} %acronym
\newcommand{\kw}[1]{{\bf #1}} %keyword

\begin{document}


\chapter*{Notations}

\url{http://www-users.cs.umn.edu/~karypis/parbook/Lectures/AG/chap12_slides.pdf}
\url{http://www.aclweb.org/anthology/C08-5001}
\url{http://www.cs.columbia.edu/~mcollins/}

\paragraph{Pseudo Code}
\begin{description}
\item $X|Y$ concatène les listes $X$ et $Y$
\item $x_i$ le $i$-ème élément de la liste $X$
\item $_{\ominus}X$ la liste $X$ sans son premier élément
\item $X_{\ominus}$ la liste $X$ sans son dernier élément
\end{description}
 

\chapter{Aspects algorithmiques}

\section{Prédiction de séquences}
Un nombre important de problèmes de traitement automatique des langues (\ac{Tal}) peuvent se formaliser comme des problèmes de recherche de chemin le plus long (ou parfois le plus court) dans un graphe acyclique orienté (\ac{Dag}).

Un exemple intuitif est le problème d'étiquetage de séquences appelé étiquetage morphosyntaxique. \'{E}tant donnée une séquence de $n$ mots $w_1\ldots w_n$,  on se donne pour tâche de prédire leurs parties de discours $t_1\ldots t_n$. 

En première approche, on peut considérer deux méthodes pour  étiqueter des séquences de mots~: d'une part on peut envisager étiqueter chaque mot $w_i$ par une étiquette $t_i$ en fonction du contexte $C$ où il apparaît à l'aide d'une fonction $f: W, C \mapsto T$ (où $W$ dénote un ensemble de mots, $C$ un ensemble de contextes\footnote{Typiquement un élément de $C$ sera un tuple de mots qui sont situés à gauche et à droite de $w_i$} et $T$ un ensemble de parties de discours). La première approche met en jeu  un {\bf modèle local} qui prédit  chacune des étiquettes $t_i$ indépendamment de toute autre étiquette $t_j\, (i\not = j)$.

L'approche alternative, dite globale et qui fait intervenir un {\bf modèle structuré} cherche à prédire la séquence de tags $t_1\ldots t_n$ en une fois.  La fonction de prédiction est de la forme $f:W^n \mapsto T^n$, autrement dit elle envoie une séquence de $n$ mots sur des séquences d'étiquettes de $n$ tags.  Utiliser cette seconde alternative  revient à supposer que les séquences forment une structure intéressante pour la prédiction. Ainsi un modèle local
peut faire des erreurs pour prédire le tag $t_i$ qui sont liées à l'ignorance des prédictions 
faites pour les tags avoisinants (comme par exemple $t_{i-1},t_{i-2}$\ldots). 

\begin{center}
\begin{tabular}{ccc}\toprule
\multicolumn{3}{c}{Prédiction globale ?}\\\midrule
D & A & N\\
Le & grand & est\\\bottomrule
\end{tabular}
\begin{tabular}{ccc}\toprule
\multicolumn{3}{c}{Prédiction locale ?}\\\midrule
D & A & {\bf\color{red} V}\\
Le & grand & est\\\bottomrule
\end{tabular}
\end{center}

Le problème de prédiction globale ou structurée est plus complexe que le problème de prédiction locale. En effet pour un jeu de tags $T$ un modèle local doit choisir $n$ fois parmi $|T|$ alternatives pour étiqueter une phrase,  alors qu'un modèle global doit choisir parmi un ensemble de $|T|^n$ alternatives, ce qui a un coût~: réaliser ce choix naïvement demande d'enumérer un ensemble  exponentiel d'alternatives d'étiquetages de la phrase.

\paragraph{Fonction de pondération}
Réaliser le tagging d'une séquence de mots $\mathbf{w} =  w_1\ldots w_n$ demande de choisir une séquence de tags $\mathbf{t} = t_1\ldots t_n \in T^n$. 
Ce  choix s'appuie en général sur une \kw{fonction de pondération} $\sigma : T^n\times W^n \mapsto \mathbb{R}$ qui associe un score à toute séquence de tags.
La méthode de pondération permet alors d'ordonner les différentes séquences de tags en fonction du score qui leur est associé.  La \kw{fonction de décision} réalise le choix de la séquence à préférer en utilisant souvent une forme du type :
\begin{equation}
\label{eq-decision}
\hat{\mathbf{t}} = \mathop{\text{argmax}}_{\mathbf{t} \in T^n}\quad \sigma(\mathbf{t},\mathbf{w})
\end{equation}
Généralement la fonction de pondération est instanciée par une méthode d'apprentissage automatique. Indiquons également que le calcul de la solution de (\ref{eq-decision})  consiste essentiellement à résoudre un \kw{problème d'optimisation} de la forme :
\begin{equation}
\label{eq-combi-optim}
m = \mathop{\text{max}}_{\mathbf{t} \in T^n}\quad \sigma(\mathbf{t},\mathbf{w})
\end{equation}
à partir de là on tire généralement la solution de (\ref{eq-decision}) 
par effet de bord.

Ce qui distingue \ref{eq-combi-optim} d'un problème d'optimisation classique,
c'est qu'il s'agit de chercher une valeur optimale dans un ensemble énumérable de taille finie dont les valeurs sont structurées en séquences.
Bien que de taille finie, l'ensemble des solutions est en général de taille considérable de telle sorte qu'une méthode de recherche de solutions qui consiste à énumérer exhaustivement chacune des solutions est en général inutilisable.


\section{Arbre de recherche de solutions}
\marginpar{Biblio (AIMA : a modern approach)}

La recherche de solutions à des problèmes de type (\ref{eq-combi-optim}) 
peut s'exprimer sous la forme générale d'un problème de recherche~:
\begin{itemize}
\item Un espace de recherche qui est un ensemble $Q$ d'états
\item Un état initial $q_0 \in Q$ qui est l'état à partir duquel le tagger commence.    
\item Un ensemble $F\subseteq Q$ d'états finaux qui indique les états dans lequel le tagger a terminé.
\item Un ensemble $A$ d'actions, dans le cas d'un tagger la seule action possible est de tagguer le mot suivant. On définit un ensemble d'actions $A$ pour lequel chaque élément représente l'attribution d'un tag au mot suivant dans la phrase.
\item Un ensemble $T\subseteq Q\times Q \times A$ de transitions qui induit une structure d'arbre.
\item Une fonction de coût $\sigma$ ou de score qui représente le score d'une séquence d'états calculé depuis l'état initial. On suppose que toute transition  $(q_i,q_{i+1},a_i) \in T$ se voit attribuer un coût $\psi(q_i,q_{i+1},a_i)$ par une fonction $\psi: T \mapsto \mathbb{R}$. On pose par convention que le coût de la séquence de transitions qui mène à l'état $q_k$ est le produit des coûts des transitions qui la composent~: 
\begin{displaymath}
\sigma(q_k) = \bigotimes_{0\leq i < k} \psi(q_i,q_{i+1},a_i)
\end{displaymath}
\end{itemize}
\begin{figure}[htbp]
\begin{tikzpicture}[xscale=2,yscale=2]

    \node[shape=circle,draw=black,double=red] (S) at (0,3) {S};
     \node[shape=circle,draw=black,double=red] (E) at (6,3) {E};


    \node[shape=circle,draw=black] (A1) at (1,1) {D};
    \node[shape=circle,draw=black] (B1) at (1,2) {N};
    \node[shape=circle,draw=black] (C1) at (1,3) {A};
    \node[shape=circle,draw=black] (D1) at (1,4) {P};
    \node[shape=circle,draw=black] (E1) at (1,5) {V};

 \draw [opacity=0.5](B1.east) -- (1.5,1.6) -- (1.5,2.4) -- cycle;
 \draw [opacity=0.5](C1.east) -- (1.5,3.4) -- (1.5,2.6) -- cycle;
 \draw [opacity=0.5](D1.east) -- (1.5,4.4) -- (1.5,3.6) -- cycle;
 \draw [opacity=0.5](E1.east) -- (1.5,5.4) -- (1.5,4.6) -- cycle;
 
    \node[shape=circle,draw=black] (A2) at (2,-1){D};
    \node[shape=circle,draw=black] (B2) at (2,0) {N};
    \node[shape=circle,draw=black] (C2) at (2,1) {A};
    \node[shape=circle,draw=black] (D2) at (2,2) {P};
    \node[shape=circle,draw=black] (E2) at (2,3) {V};

     \draw [opacity=0.5](A2.east) -- (2.5,-1.4) -- (2.5,-0.6) -- cycle;
     \draw [opacity=0.5](B2.east) -- (2.5,0.4) -- (2.5,-0.4) -- cycle;
     \draw [opacity=0.5](C2.east) -- (2.5,0.6) -- (2.5,1.4) -- cycle;
      \draw [opacity=0.5](D2.east) -- (2.5,2.4) -- (2.5,1.6) -- cycle;
       \draw [opacity=0.5](E2.east) -- (2.5,3.4) -- (2.5,2.6) -- cycle;
     
      \draw [->,decorate,decoration={snake,amplitude=.8mm,segment length=2mm,post length=1mm},opacity=0.5](2,5)  --  (E.west);
      \draw [->,decorate,decoration={snake,amplitude=.8mm,segment length=2mm,post length=1mm},opacity=0.5](3,3)  --  (E.west);
      \draw [->,decorate,decoration={snake,amplitude=.8mm,segment length=2mm,post length=1mm},opacity=0.5](3,-1)  --  (E.west);

	 \draw [->,ultra thick,opacity=0.5] (S) -- (A1);
	 \draw [->,opacity=0.5] (S) -- (B1);
	 \draw [->,opacity=0.5] (S) -- (C1);
	 \draw [->,opacity=0.5] (S) -- (D1);
	 \draw [->,opacity=0.5] (S) -- (E1);

     \draw [->,opacity=0.5] (A1) -- (A2);
	 \draw [->,opacity=0.5] (A1) -- (B2);
	 \draw [->,ultra thick,opacity=0.5] (A1) -- (C2);
	 \draw [->,opacity=0.5] (A1) -- (D2);
	 \draw [->,opacity=0.5] (A1) -- (E2);



 \node[draw=white,text depth=0.25ex,text height=1cm] (W1) at (1,-2) {La} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W2) at (2,-2) {belle} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W3) at (3,-2) {porte} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W4) at (4,-2) {le} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W5) at (5,-2) {cache} ;

\end{tikzpicture}
\caption{\label{fig-searchtree}Arbre de recherche de solutions}
\end{figure}
On peut illustrer la  structure d'un problème de recherche par un arbre comme en figure \ref{fig-searchtree} pour un problème d'étiquetage morphosyntaxique (les scores sont omis). En fait un nombre très important de problèmes de \ac{tal} peut s'analyser en termes de problème de recherche de solutions dans de grands ensembles à valeurs structurées. On verra qu'on peut ainsi définir des variantes quant à la nature des états, du système de transition, des actions et que la fonction de coût dépend en général de la méthode d'apprentissage utilisée. 
\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{MaxSearch}{S,B,$\sigma$}
\If{$B \not = \epsilon$}
\State maxscore $\gets \bar{0}$
\ForAll{$t \in T$}
	\State pscore $\gets \sigma \otimes \psi(S,B,t)$
	\State maxscore $\gets $\Call{$\oplus$}{}(maxscore,\Call{MaxSearch}{$S|t$,$_{\ominus}$B,pscore})
\EndFor
\State\Return maxscore
\Else
  \State\Return $\sigma$
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-searchtree}Algorithme de recherche structuré en arbre (cas du tagger)}
\end{algorithm}
En principe, quand l'arbre de recherche a une taille raisonnable, l'exploration des solutions peut se faire exhaustivement.  Mais en pratique cette première solution est en général utilisée rarement telle quelle~: on utilise plutôt des méthodes de programmation dynamique, de recherche approximative ou une combinaison des deux.

On  donne en algorithme \ref{algo-searchtree},
un exemple d'algorithme de recherche pour un problème structuré en arbre. On peut notamment constater que la structure d'arbre de recherche n'est pas exprimée par une structure de donnée explicite mais plutôt implicitement par la structure d'appels récursifs du programme. Comme exercice, il peut être intéressant de repérer les différentes composantes du problème de recherche dans le pseudo-code  (Algorithme \ref{algo-searchtree}).



\begin{exo}Réécrire l'algorithme de parcours d'arbre de recherche
pour que le résultat renvoyé soit maintenant un couple qui comporte la valeur de score maximale mais aussi la séquence de tags correspondante
\end{exo}






\section{Systèmes de transition}

Pour spécifier explicitement un problème de recherche de solutions en \ac{tal}, on utilise fréquemment une spécification sous forme de système de transitions. Ce type de spécification a été popularisé par la tâche d'analyse syntaxique en dépendances.  Mais celle-ci est très générale, on trouve ce type de systèmes également pour spécifier des problèmes de planification en intelligence artificielle et (parfois) des méthodes de démonstration automatique. 

On propose de les introduire immédiatement par un premier exemple qui caractérise explicitement une tâche de tagging. Spécifier un système de transitions revient à spécifier chacun des éléments suivants~:
\begin{itemize}
\item L'ensemble $Q$ des états est structuré. Chaque état $q\in Q$ est un couple $(S,B)$ où $S$ est une séquence de tags déjà prédits et $B$ une séquence de mots encore à traiter dans la phrase. 
\item L'état initial $q_0$ est l'état $(\epsilon , B)$ où $B$ est la liste des mots de la phrase à étiqueter.
\item L'ensemble des états finaux est l'ensemble $F$ des états tels que $B$ est vide. 
\item L'ensemble $A$ des actions est l'ensemble qui représente le jeu de tags $t\in A$ utilisé par le tagger.
\item L'ensemble $T$ des transitions est la relation
entre états qui satisfait le critère suivant~: 
\begin{displaymath}
(S,b_0|B) \stackrel{t}{\Rightarrow}(S|t,B)\qquad (t \in A)
\end{displaymath}
Ce qui signifie que le premier mot de $B$ est enlevé; le tag qui correspond à l'action exécutée est ajouté à $S$.
\item Le coût local d'une transition $\psi(S,B,t)$ est calculé par un modèle d'apprentissage approprié. 
\end{itemize}

Notons que les systèmes de transitions peuvent servir à exprimer des automates et des transducteurs à nombre finis d'états ou des contreparties d'automates à pile. Mais il est commun en \ac{tal} de ne pas limiter l'usage des systèmes de transition au seul encodage de ce type de machines.

\begin{exo}
Définir une variante de ce système de transition qui permet à un tagger d'accéder également aux mots qui précèdent dans la phrase avec la fonction de score $\psi(S,B,t)$ ou une de ses variantes. 
\end{exo}
\begin{exo}
Réécrire l'algorithme de parcours d'un arbre de recherche pour qu'il renvoie le poids de la solution de poids maximal à l'aide du système de transitions donné ci-dessus.
\end{exo}
\begin{solution}
\begin{algorithmic}
\Function{MaxSearch}{S,B,$\sigma$}
\If {B $\not = \epsilon$}
\State maxscore $\gets \bar{0}$
\ForAll{$t \in A$}
\State pscore $\gets \sigma \otimes \psi(S,B,t)$ 
\State maxscore $\gets$ \Call{$\oplus$}{}(maxscore,\Call{MaxSearch}{$S|t$,$_\ominus B$,pscore})
\EndFor
\State\Return maxscore
\Else
\State\Return $\sigma$
\EndIf
\EndFunction
\end{algorithmic}
\end{solution}
\begin{exo}
Modifier la formulation de l'exercice précédent pour faire en sorte qu'il renvoie la séquence de tags ainsi que le poids de cette solution
\end{exo}

Lorsque l'espace des solutions est trop grand (ce qui est généralement le cas pour la plupart des problèmes de \ac{tal}) l'algorithme naïf de recherche vu jusqu'à présent, qui a une complexité exponentielle en $\mathcal{O}(A^n)$ est inutilisable. On se tourne alors vers des solutions qui s'appuient sur de la programmation dynamique (Section \ref{sec-DP}) ou des solutions  de recherche approximative ou une combinaison des deux.




\section{Programmation dynamique}
\label{sec-DP}
Une des faiblesses de l'algorithme de recherche de solutions
vu jusqu'à présent est qu'il réplique une quantité très importante de calculs.
Pour nous en rendre compte, considérons deux séquences de tags 
\begin{center}
\begin{tabular}{ccccc}\toprule
D &A& N& D& V\\
D& A& N& P& V\\\midrule
La&belle&porte&le&cache\\\bottomrule
\end{tabular}
\end{center}
qui diffèrent par un élément.  On constate qu'une méthode de recherche en arbre (qui procède ici de droite à gauche)  va recalculer au moins deux foix la valeur du préfixe {\sl D A N}.  De manière générale la méthode de recherche de solutions en arbre reduplique une quantité considérable de calculs de préfixes, ce qui est largement inefficace.
\begin{center}
\begin{tikzpicture}[xscale=1.75,yscale=1.75]

\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
\node[shape=circle,draw=black,double=red] (E) at (6,0) {E};
\node[shape=circle,draw=black] (A1) at (5,0) {V};
\node[shape=circle,draw=black] (A2) at (4,-1) {P};
\node[shape=circle,draw=black] (B2) at (4,1) {D};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (C2) at (3,-1) {N};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (C1) at (3,1) {N};
\draw [->,opacity=0.5](E) -- (A1);
\draw [->,opacity=0.5](A1) -- (A2);
\draw [->,opacity=0.5](A1) -- (B2);
\draw [->,opacity=0.5](A2) -- (C2);
\draw [->,opacity=0.5](B2) -- (C1);
\draw [->,opacity=0.5, decorate,decoration={snake,amplitude=.2mm,segment length=2mm,post length=1mm}] (C1) -- (S.east);
\draw [->,opacity=0.5, decorate,decoration={snake,amplitude=.2mm,segment length=2mm,post length=1mm}] (C2) -- (S.east);
\end{tikzpicture}
\end{center}
L'idée des méthodes de \kw{programmation dynamique}, c'est d'éviter les reduplications de calculs inutiles pour réutiliser des résultats intermédiaires (partage de calcul). Ainsi l'espace des états est organisé en  graphe (\ac{dag}) plutôt qu'en arbre. Cette nouvelle organisation permet de proposer des solutions algorithmiques en temps polynomial plutôt qu'en temps exponentiel aux problèmes de recherche qui nous concernent.

\begin{center}
\begin{tikzpicture}[xscale=1.75,yscale=1.75]

\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
\node[shape=circle,draw=black,double=red] (E) at (6,0) {E};
\node[shape=circle,draw=black] (A1) at (5,0) {V};
\node[shape=circle,draw=black] (A2) at (4,-1) {P};
\node[shape=circle,draw=black] (B2) at (4,1) {D};
\node[shape=circle,fill=green,fill opacity=0.2,draw=black] (C1) at (3,0) {N};
\draw [->,opacity=0.5](E) -- (A1);
\draw [->,opacity=0.5](A1) -- (A2);
\draw [->,opacity=0.5](A1) -- (B2);
\draw [->,opacity=0.5](A2) -- (C1);
\draw [->,opacity=0.5](B2) -- (C1);
\draw [->,opacity=0.5, decorate,decoration={snake,amplitude=.2mm,segment length=2mm,post length=1mm}] (C1) -- (S.east);
\end{tikzpicture}
\end{center}



\subsection{Graphe Acyclique orienté}

\begin{definition}[DAG] 
Un graphe acyclique orienté (\ac{dag}) est un graphe $G = \langle V,E \rangle$ où $V$ est un ensemble de noeuds et $E$ un ensemble d'arcs
($E \subseteq V\times V$) tel qu'il ne comporte pas de circuit.
Dans le cas pondéré, on  y ajoute une fonction $s: E \mapsto \mathbb{R}$
qui donne un score à chacun des arcs.
\end{definition}

\begin{definition}[Arc entrants] 
Soit un noeud $x\in V$, l'ensemble $AE(x) = \{(y,x) \,|\, (y,x) \in E , y \in V \}$ est l'ensemble des arcs entrants sur ce noeud. 
\end{definition}

\begin{definition}[Arc sortants] 
Soit un noeud $x\in V$, l'ensemble $AS(x) = \{(x,y) \,|\, (x,y) \in E , y \in V \}$ est l'ensemble des arcs sortants de ce noeud. 
\end{definition}

\begin{definition}[Chemin]
Un chemin de longeur $n$ est une séquence de noeuds $\pi \in V^n$ de la forme $\pi = v_1 v_2\ldots v_n$ tel que $(v_i,v_{i+1}) \in E$ pour tout $1\leq i < n$. Le score $\sigma(\pi)$ d'un chemin est le produit :
\begin{displaymath}
\sigma(\pi) = \bigotimes_{i=1}^{n-1} \psi(v_i,v_{i+1}) 
\end{displaymath}
\end{definition}

\begin{definition}[Poids maximal depuis la source]
Soit un \ac{dag} dont un noeud distingué $s\in V$ est appelé noeud source. En notant $P(x)$ l'ensemble des chemins qui mènent de la source
à $x$, on définit le poids maximal de $x$ comme suit~: 
\begin{displaymath}
\delta(x)  = \left\{ 
\begin{array}{ll}
\bar{0} & \text{si } $x = s$ \\
\bigoplus_{\pi \in P(x)} \sigma(\pi) &\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{definition}


\subsection{Optimisation de fonctions récursives}
Un problème de programmation dynamique est typiquement formulé comme un problème d'optimisation entre différentes alternatives~: il s'agit par exemple de trouver un chemin de poids maximum parmi plusieurs chemins pondérés.

\begin{center}
\begin{tikzpicture}[xscale=2,yscale=2]
\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0) {E};
\node[shape=circle,draw=black] (1) at (1,1) {A};
\node[shape=circle,draw=black] (2) at (3,1) {C};
\node[shape=circle,draw=black] (3) at (2,0) {B};
\draw [->,opacity=0.5](S) -- (1) node[midway,fill=white]{$s(S,A)$};
\draw [->,opacity=0.5](S) -- (3) node[midway,fill=white]{$s(S,B)$};
\draw [->,opacity=0.5](1) -- (3) node[midway,fill=white]{$s(A,B)$};
\draw [->,opacity=0.5](1) -- (2) node[midway,fill=white]{$s(A,C)$};
\draw [->,opacity=0.5](3) -- (2) node[midway,fill=white]{$s(B,C)$};
\draw [->,opacity=0.5](2) -- (E) node[midway,fill=white]{$s(C,E)$};
\draw [->,opacity=0.5](3) -- (E) node[midway,fill=white]{$s(B,E)$};
\end{tikzpicture}
\end{center}

Notons $\sigma(x)$ le coût d'un chemin entre le noeud initial du \ac{dag} et un noeud $x$. En notant $x_{-1},x_{-2}\ldots x_{-k}$ les prédécesseurs d'un noeud $x$ dans le graphe ($x_{-i} \in AE(x)$), on a que le chemin de poids maximal pour arriver à $x$ depuis ses prédécesseurs est donné par l'équation :
\begin{equation}
\label{eq-bellmann}
\delta(x) = \left\{ 
\begin{array}{ll}
\bar{0} & \text{si }  x = q_0\\
\oplus \left[ \alpha(x_{-1}) \otimes \psi(x_{-1},x), \ldots ,\alpha(x_{-k}) \otimes \psi(x_{-k},x) \right] &\text{sinon}
\end{array}
\right.
\end{equation}
qui est appelée équation de programmation dynamique ou \kw{équation de Bellmann}. Il s'agit d'une formule récursive qui fait intervenir deux opérations~: $\oplus$ est une opération d'aggrégation parmi plusieurs alternatives comme typiquemen {\sl max} ou {\sl min} et $\otimes$ est un opération de composition destinée à calculer le score de chemins dans un \ac{dag} comme typiquement $+$ ou $\times$. 

La récurrence exprimée en (\ref{eq-bellmann})  indique que pour déterminer le poids du chemin optimal qui mène à $x$, il faut comparer le poids de l'ensemble des chemins qui passent par les prédécesseurs de $x$ dans le \ac{dag}.

Mais cette récurrence indique surtout que pour déterminer le coût du chemin optimal pour atteindre $x$ il faut essentiellement réutiliser la solution du sous-problème pour chacun des prédécesseurs de $x$, ce qui revient à déterminer le chemin optimal qui mène à chacun des $x_{-i}$.

Lorsque certains sous-problèmes sont à recalculer plusieurs fois, on  dit qu'il y a \kw{recouvrement de sous-problèmes}. Les techniques de programmation dynamique consistent à éviter l'évaluation multiple d'un même sous-problème en mémorisant les solutions intermédiaires.

Plusieurs techniques pour réaliser la mémorisation seront présentées mais celles-ci font généralement appel à une table dite table de programmation dynamique pour mémoriser les résultats intermédiaires. Celle-ci mémorise les valeurs $\delta(x)$ des états $x$ visités lors de la résolution du problème.

Une solution simple et directe pour exprimer ce qui précède est la technique de \kw{mémoisation}. Celle-ci repose sur l'usage de \kw{mémo-fonctions}. L'idée est de mémoriser la solution $\delta(x)$ dans une table dès que celle-ci est déterminée. Cette table est alors consultée dans les étapes ultérieures de l'algorithme de telle sorte que la valeur mémorisée est réutilisée au lieu de réexécuter l'appel récursif.

L'algorithme \ref{algo-searchMemo} illustre le principe de la mémoisation. On suppose que le \ac{dag} a un état final $q_f$, et que la table {\sl memo} est initialisée à $\delta(x) = \bar{0}$ pour tout  $x\in V$ (sauf $\delta(q_0) = \bar{1}$). La fonction est initialement appelée avec le paramètre $q_f$.  

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{MaxSearchMemo}{x}
\If{$\text{memo}[x] \not = \bar{0}$}
\Comment{Score mémoisé}
\State\Return memo[x]
\EndIf
\ForAll{$y \in AE(x)$}
\State memo[x] $\gets$ \Call{$\oplus$}{}(memo[x],\Call{MaxSearchMemo}{y} $\otimes \psi(y,x)$)
\EndFor
\State\Return memo[x]
\EndFunction
\end{algorithmic}
\caption{\label{algo-searchMemo}Algorithme de recherche d'une valeur optimale mémoisé}
\end{algorithm}

\begin{exo}Donner une valuation numérique aux arcs du \ac{dag} suivant et  simuler l'exécution de l'algorithme \ref{algo-searchMemo} sur papier.
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=2]
\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0) {E};
\node[shape=circle,draw=black] (1) at (1,1) {A};
\node[shape=circle,draw=black] (2) at (3,1) {C};
\node[shape=circle,draw=black] (3) at (2,0) {B};
\draw [->,opacity=0.5](S) -- (1) node[midway,fill=white]{$s(S,A)$};
\draw [->,opacity=0.5](S) -- (3) node[midway,fill=white]{$s(S,B)$};
\draw [->,opacity=0.5](1) -- (3) node[midway,fill=white]{$s(A,B)$};
\draw [->,opacity=0.5](1) -- (2) node[midway,fill=white]{$s(A,C)$};
\draw [->,opacity=0.5](3) -- (2) node[midway,fill=white]{$s(B,C)$};
\draw [->,opacity=0.5](2) -- (E) node[midway,fill=white]{$s(C,E)$};
\draw [->,opacity=0.5](3) -- (E) node[midway,fill=white]{$s(B,E)$};
\end{tikzpicture}
\end{center}
\end{exo}
\begin{exo}
Reformuler l'algorithme \ref{algo-searchMemo} de telle sorte que le chemin optimal 
soit celui de poids minimum.  Simuler son exécution sur papier.
\end{exo}
\begin{exo}
Reformuler l'algorithme \ref{algo-searchMemo} en utilisant la notation en opérations abstraites $\oplus$ et $\otimes$
\end{exo}
\begin{exo}
Reformuler l'algorithme \ref{algo-searchMemo} en supprimant la conditionnelle qui réalise la mémoisation.  Tenter de le simuler sur papier.
\end{exo}

\section{Algorithme de Viterbi}
L'algorithme mémoisé présenté dans la section précédente peut se reformuler par une version souvent plus pratique à l'usage. C'est l'\kw{algorithme de Viterbi}.

\begin{definition}[Ordre topologique] Un ordre topologique sur un \ac{dag} $G=(V,E)$ est tout ordre total sur les noeuds $V$ de ce \ac{dag} tel que pour tout couple de noeuds $(x,y) \in E$,  $x \prec y$. Il existe en général plusieurs ordres topologiques valides pour un \ac{dag} donné.
\end{definition}

L'algorithme de Viterbi est un algorithme de recherche du chemin de
poids maximal dans un \ac{dag} (Figure \ref{algo-viterbi-general}). 
 En supposant un noeud source $s$ unique dont le poids $\delta(s)$ est
 initialisé à 1, l'algorithme parcourt le \ac{dag} en suivant l'ordre
 topologique. Chaque noeud est à son tour valué par le poids
 $\delta(s)$ du chemin maximal qui mène de la source jusqu'à ce
 noeud. Toute l'idée de l'algorithme consiste à mémoriser les poids
 $\delta(s)$ au fur et à mesure qu'ils sont calculés pour les
 réutiliser lors de calculs ultérieurs.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\delta(s) \gets \bar{1}$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\delta(s) \gets \bar{0}$
\ForAll {$(s',s) \in AE(s)$}
\State  $\delta(s) \gets \Call{$\oplus$}{\delta(s) , \delta(s')  \otimes \psi(s',s) $}
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-general}Algorithme de Viterbi}
\end{algorithm}

On donne en figure \ref{fig-viterbi-general-dag} un exemple de
résultat de l'exécution de l'algorithme sur un cas concret. Chacun des
noeuds du \ac{dag} est annoté (case bleue) par la valeur du $\delta(x)$
qui lui correspond.

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%deltas
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){135};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){15};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){20};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){40};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){45};
\end{tikzpicture}
\end{center}
\caption{\label{fig-viterbi-general-dag}\ac{dag} annoté par $\delta(x)$}
\end{figure}


\begin{exo}[Limitation aux \ac{dags}]
L'algorithme de Viterbi ne peut pas être utilisé si le graphe contient
au moins un cycle (le graphe n'est pas un \ac{dag}). Expliquer
pourquoi par un exemple.
\end{exo}
\begin{exo}[Extraction de la séquence de poids maximal]
Donner une extension de l'algorithme donné en figure
\ref{algo-viterbi-general} qui permet de renvoyer comme résultat non
seulement le score du chemin de poids maximal (plus long chemin) mais
aussi la séquence de tags de ce chemin.
\end{exo}


\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=1.5,yscale=1.5]
    \node[shape=circle,draw=black] (A1) at (1,1) {D};
    \node[shape=circle,draw=black] (B1) at (1,2) {N};
    \node[shape=circle,draw=black] (C1) at (1,3) {A};
    \node[shape=circle,draw=black] (D1) at (1,4) {P};
    \node[shape=circle,draw=black] (E1) at (1,5) {V};
     \node[shape=circle,draw=black] (A2) at (2,1) {D};
    \node[shape=circle,draw=black] (B2) at (2,2) {N};
    \node[shape=circle,draw=black] (C2) at (2,3) {A};
    \node[shape=circle,draw=black] (D2) at (2,4) {P};
    \node[shape=circle,draw=black] (E2) at (2,5) {V};
     \node[shape=circle,draw=black] (A3) at (3,1) {D};
    \node[shape=circle,draw=black] (B3) at (3,2) {N};
    \node[shape=circle,draw=black] (C3) at (3,3) {A};
    \node[shape=circle,draw=black] (D3) at (3,4) {P};
    \node[shape=circle,draw=black] (E3) at (3,5) {V};
     \node[shape=circle,draw=black] (A4) at (4,1) {D};
    \node[shape=circle,draw=black] (B4) at (4,2) {N};
    \node[shape=circle,draw=black] (C4) at (4,3) {A};
    \node[shape=circle,draw=black] (D4) at (4,4) {P};
    \node[shape=circle,draw=black] (E4) at (4,5) {V};
     \node[shape=circle,draw=black] (A5) at (5,1) {D};
    \node[shape=circle,draw=black] (B5) at (5,2) {N};
    \node[shape=circle,draw=black] (C5) at (5,3) {A};
    \node[shape=circle,draw=black] (D5) at (5,4) {P};
    \node[shape=circle,draw=black] (E5) at (5,5) {V};
    \node[draw=white,text depth=0.25ex,text height=1cm] (W1) at (1,0) {La} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W2) at (2,0) {belle} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W3) at (3,0) {porte} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W4) at (4,0) {le} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W5) at (5,0) {cache} ;
    \node[shape=circle,draw=black,double=red] (S) at (0,3) {S};
 \node[shape=circle,draw=black,double=red] (E) at (6,3) {E};

 \draw [->,ultra thick,opacity=0.5] (S) -- (A1);
 \draw [->,opacity=0.5] (S) -- (B1);
 \draw [->,opacity=0.5] (S) -- (C1);
 \draw [->,opacity=0.5] (S) -- (D1);
 \draw [->,opacity=0.5] (S) -- (E1);
 
 \draw [->,opacity=0.5] (A1) -- (A2);
 \draw [->,opacity=0.5] (A1) -- (B2);
 \draw [->,ultra thick,opacity=0.5] (A1) -- (C2);
 \draw [->,opacity=0.5] (A1) -- (D2);
 \draw [->,opacity=0.5] (A1) -- (E2);

\draw [->,opacity=0.5] (B1) -- (A2);
 \draw [->,opacity=0.5] (B1) -- (B2);
 \draw [->,opacity=0.5] (B1) -- (C2);
 \draw [->,opacity=0.5] (B1) -- (D2);
 \draw [->,opacity=0.5] (B1) -- (E2);

\draw [->,opacity=0.5]  (C1) -- (A2);
 \draw [->,opacity=0.5] (C1) -- (B2);
 \draw [->,opacity=0.5] (C1) -- (C2);
 \draw [->,opacity=0.5] (C1) -- (D2);
 \draw [->,opacity=0.5] (C1) -- (E2);

\draw [->,opacity=0.5]  (D1) -- (A2);
 \draw [->,opacity=0.5] (D1) -- (B2);
 \draw [->,opacity=0.5] (D1) -- (C2);
 \draw [->,opacity=0.5] (D1) -- (D2);
 \draw [->,opacity=0.5] (D1) -- (E2);
 
 \draw [->,opacity=0.5]  (E1) -- (A2);
 \draw [->,opacity=0.5] (E1) -- (B2);
 \draw [->,opacity=0.5] (E1) -- (C2);
 \draw [->,opacity=0.5] (E1) -- (D2);
 \draw [->,opacity=0.5] (E1) -- (E2);
 
 \draw [->,opacity=0.5] (A2) -- (A3);
 \draw [->,opacity=0.5] (A2) -- (B3);
 \draw [->,opacity=0.5] (A2) -- (C3);
 \draw [->,opacity=0.5] (A2) -- (D3);
 \draw [->,opacity=0.5] (A2) -- (E3);

\draw [->,opacity=0.5] (B2) -- (A3);
 \draw [->,opacity=0.5] (B2) -- (B3);
 \draw [->,opacity=0.5] (B2) -- (C3);
 \draw [->,opacity=0.5] (B2) -- (D3);
 \draw [->,opacity=0.5] (B2) -- (E3);

\draw [->,opacity=0.5]  (C2) -- (A3);
 \draw [->,ultra thick,opacity=0.5] (C2) -- (B3);
 \draw [->,opacity=0.5] (C2) -- (C3);
 \draw [->,opacity=0.5] (C2) -- (D3);
 \draw [->,opacity=0.5] (C2) -- (E3);

\draw [->,opacity=0.5]  (D2) -- (A3);
 \draw [->,opacity=0.5] (D2) -- (B3);
 \draw [->,opacity=0.5] (D2) -- (C3);
 \draw [->,opacity=0.5] (D2) -- (D3);
 \draw [->,opacity=0.5] (D2) -- (E3);
 
 \draw [->,opacity=0.5]  (E2) -- (A3);
 \draw [->,opacity=0.5] (E2) -- (B3);
 \draw [->,opacity=0.5] (E2) -- (C3);
 \draw [->,opacity=0.5] (E2) -- (D3);
 \draw [->,opacity=0.5] (E2) -- (E3);

 \draw [->,opacity=0.5] (A3) -- (A4);
 \draw [->,opacity=0.5] (A3) -- (B4);
 \draw [->,opacity=0.5] (A3) -- (C4);
 \draw [->,opacity=0.5] (A3) -- (D4);
 \draw [->,opacity=0.5] (A3) -- (E4);

\draw [->,opacity=0.5] (B3) -- (A4);
 \draw [->,opacity=0.5] (B3) -- (B4);
 \draw [->,opacity=0.5] (B3) -- (C4);
 \draw [->,ultra thick,opacity=0.5] (B3) -- (D4);
 \draw [->,opacity=0.5] (B3) -- (E4);

\draw [->,opacity=0.5]  (C3) -- (A4);
 \draw [->,opacity=0.5] (C3) -- (B4);
 \draw [->,opacity=0.5] (C3) -- (C4);
 \draw [->,opacity=0.5] (C3) -- (D4);
 \draw [->,opacity=0.5] (C3) -- (E4);

\draw [->,opacity=0.5]  (D3) -- (A4);
 \draw [->,opacity=0.5] (D3) -- (B4);
 \draw [->,opacity=0.5] (D3) -- (C4);
 \draw [->,opacity=0.5] (D3) -- (D4);
 \draw [->,opacity=0.5] (D3) -- (E4);
 
 \draw [->,opacity=0.5] (E3) -- (A4);
 \draw [->,opacity=0.5] (E3) -- (B4);
 \draw [->,opacity=0.5] (E3) -- (C4);
 \draw [->,opacity=0.5] (E3) -- (D4);
 \draw [->,opacity=0.5] (E3) -- (E4);

 \draw [->,opacity=0.5] (A4) -- (A5);
 \draw [->,opacity=0.5] (A4) -- (B5);
 \draw [->,opacity=0.5] (A4) -- (C5);
 \draw [->,opacity=0.5] (A4) -- (D5);
 \draw [->,opacity=0.5] (A4) -- (E5);

\draw [->,opacity=0.5] (B4) -- (A5);
 \draw [->,opacity=0.5] (B4) -- (B5);
 \draw [->,opacity=0.5] (B4) -- (C5);
 \draw [->,opacity=0.5] (B4) -- (D5);
 \draw [->,opacity=0.5] (B4) -- (E5);

\draw [->,opacity=0.5]  (C4) -- (A5);
 \draw [->,opacity=0.5] (C4) -- (B5);
 \draw [->,opacity=0.5] (C4) -- (C5);
 \draw [->,opacity=0.5] (C4) -- (D5);
 \draw [->,opacity=0.5] (C4) -- (E5);

\draw [->,opacity=0.5]  (D4) -- (A5);
 \draw [->,opacity=0.5] (D4) -- (B5);
 \draw [->,opacity=0.5] (D4) -- (C5);
 \draw [->,opacity=0.5] (D4) -- (D5);
 \draw [->,ultra thick,opacity=0.5] (D4) -- (E5);
 
 \draw [->,opacity=0.5] (E4) -- (A5);
 \draw [->,opacity=0.5] (E4) -- (B5);
 \draw [->,opacity=0.5] (E4) -- (C5);
 \draw [->,opacity=0.5] (E4) -- (D5);
 \draw [->,opacity=0.5] (E4) -- (E5);

 \draw [->,opacity=0.5] (A5) -- (E);
 \draw [->,opacity=0.5] (B5) -- (E);
 \draw [->,opacity=0.5] (C5) -- (E);
 \draw [->,opacity=0.5] (D5) -- (E);
 \draw [->,ultra thick,opacity=0.5] (E5) -- (E);

\end{tikzpicture}
\end{center}
\caption{\label{fig-pos-dag}Graphe acyclique orienté pour énumérer les solutions de manière compacte}
\end{figure}


\paragraph{Viterbi pour l'étiquetage morphosyntaxique}
Dans le cas de l'étiquetage morphosyntaxique en \ac{tal}, le \ac{dag}
de programmation dynamique est conventionnellement construit comme
illustré en figure \ref{fig-pos-dag}. Pour chaque occurrence de mot
$w_i$ dans la phrase, on construit un noeud correspondant à chacun des tags possibles.
Chacun de ces noeuds est connecté par un arc à l'ensemble des noeuds
de la position suivante $w_{i+1}$ dans la phrase. 



En utilisant cette représentation, évaluer successivement les noeuds
de gauche à droite,  c'est-à-dire en valuant l'ensemble des mots de
$w_i$  avant ceux de $w_{i+1}$ revient à valuer le graphe suivant un
ordre topologique valide.

Dans ce contexte spécifique, il est classique de stocker les quantités
$\delta(s)$ dans une matrice $\Delta$ à $i$ colonnes et $j$ lignes.
Chaque ligne correspond à un pos tag parmi un ensemble de $K$ tags et chaque colonne à une position
dans une phrase de $N$ mots. Ainsi $\delta(i,j)$ correspond au score du noeud en
position $i$ taggué par le tag $j$. L'algorithme prend alors la forme
donnée en Algorithme \ref{algo-viterbi-table} où on choisit de 
ne pas expliciter l'état cible noté $E$ dans les exemples précédents.

Cette dernière version permet également de mettre en évidence que la complexité
de l'algorithme est en ${\cal O}(NK^2)$.  
Autrement dit la méthode de programmation dynamique permet de
donner une solution en temps polynomial à un problème dont la
résolution naïve est en temps exponentiel.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{$N$,$K$,$s$}
\For{$j \leq 0 < K $}\Comment{Initialisation}
\State $\delta(0,j) \gets \psi(s ,[0,j]$) 
\EndFor
\For {$0 < i <  N$}\Comment{Recurrence}
    \For{$j \leq 0 < K $}
        \State $\delta(i,j) \gets \bar{0}$
        \For {$0\leq  k < K$}
        \State  $\delta(i,j) \gets \Call{$\oplus$}{\delta(i,j) ,
          \delta(i-1,k)  \otimes \psi([i-1,k] ,[i,j]) $}
\EndFor
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-table}Algorithme de Viterbi (version tabulaire)}
\end{algorithm}

Ce type de formulation est fréquemment utilisée dans les
implémentations. Signalons que dans un contexte d'implémentation il est d'usage de
ne pas représenter explicitement les arcs du \ac{dag} mais plutôt de
construire directement la matrice de scores $\Delta$.

\begin{exo}[Historique de dérivation]
Augmenter l'algorithme \ref{algo-viterbi-table} pour qu'il renvoie
également la séquence de tags de score maximal.
\end{exo}

\section{Abstractions algébriques}
\label{sec-semi-ring}

Les algorithmes que nous présentons ici sont destinés à être utilisés
en combinaison avec une méthode d'apprentissage.
C'est cette dernière
qui donne une méthode pour valuer la fonction $\psi$ et pour estimer
les éventuels paramètres qui lui sont associés.

L'algorithme de Viterbi est un algorithme qui ne fait rien
d'autre que de calculer un {\sl max} ou un {\sl argmax} pour un
très grand ensemble de séquences.

Or chaque méthode d'apprentissage manipule des poids qui se combinent
différemment. Par exemple pour calculer le poids d'une séquence avec
un \ac{hmm} il faut réaliser une multiplication alors qu'avec un
perceptron il faut réaliser une addition. L'algorithme de Viterbi peut
être réutilisé pour chacun de ces paradigmes mais avec les ajustements
nécessaires au système de pondération du paradigme en question.

Nous introduisons ici la notion de demi-anneau
car elle permet de spécifier l'interface entre les
algorithmes présentés ici et des
modèles d'apprentissage variés. 
Plus spécifiquement cette notion aide à caractériser
les conditions d'utilisation d'un algorithme de recherche (notamment
celui de Dijkstra) pour un
un modèle d'apprentissage. En second lieu elle donne des points de
repères sur les paramètres à considérer pour adapter les algorithmes
aux problèmes d'apprentissage traités. Et finalement cela permet de
dériver de nouvelles utilisations pour un algorithme donné.

Un \kw{demi-anneau} est une structure algébrique abstraite qui
permet de généraliser le calcul avec des nombres naturels (ensemble
$\mathbb{N}$)\footnote{Le calcul avec des entiers (ou des réels) se
  généralise par une structure d'\kw{anneau}. C'est-à-dire qu'on a
  nécessairement des
additifs inverses.}.
Le calcul suppose deux opérations~: l'addition qui est commutative et
qui a un élément neutre noté $\bar{0}$, la multiplication qui peut
être commutative et qui a un élément neutre noté
$\bar{1}$. De plus la multiplication distribue sur l'addition et
$\bar{0}$ est absorbant pour la multiplication.
Contrairement aux \kw{anneaux}, les demi-anneaux n'ont pas
nécessairement un additif inverse tel que $a \oplus -a = \bar{0}$.

Un demi anneau est un quintuple $(E,\oplus,\otimes,\bar{0},\bar{1})$
où $E$ est un ensemble, 
$\oplus$ l'opération d'addition, $\otimes$ l'opération de multiplication, $\bar{0}$ le neutre pour l'addition et
$\bar{1}$ le neutre pour la multiplication.  

L'intérêt d'utiliser cette généralisation dans la spécification des
algorithmes est de donner une formulation unique d'un algorithme qu'il
ne reste plus qu'à instancier avec le demi-anneau correspondant au
problème d'apprentissage à traiter. On donne en figure \ref{fig-semirings} quelques exemples de
demi-anneaux qui sont utilisés dans ce cours.

\begin{figure}[htbp]
\begin{center}
\scalebox{0.85}{
\begin{tabular}{llccccl}\toprule
Nom   &Ensemble&$\oplus$&$\otimes$&$\bar{0}$&$\bar{1}$&Usage possible\\\midrule
Viterbi& $[0,1]$    & max&$\times$&0&1&meilleure séquence
(\ac{hmm})\\
Viterbi-\ac{crf}& $\mathbb{R}^+$  & max&$\times$&0&1&meilleure
séquence (\ac{crf})\\
Viterbi-réel& $\mathbb{R}\cup\{-\infty\} $ &max&+&$-\infty$&0&meilleure
séquence (perceptron)\\
Tropical& $\mathbb{R}^+\cup \{-\infty\}$&min&+&$-\infty$&0&plus court chemin ($-log(p)$)\\
Avant    &$[0,1]$ &+&$\times$&0&1&Algorithme avant (\ac{hmm})\\
Avant-\ac{crf} &$\mathbb{R}^+$ &+&$\times$&0&1&Algorithme avant (\ac{crf})\\
Comptage&$\mathbb{N}$ &+&$\times$&0&1&Compte le nombre de séquences\\
\bottomrule
\end{tabular}}
\end{center}
\caption{\label{fig-semirings}Quelques demi-anneaux utilisés dans ce cours}
\end{figure}

On termine par donner quelques définitions et propriétés qui seront
utiles notamment dans les sections suivantes.  Un demi-anneau
$(E,\oplus,\otimes,\bar{0},\bar{1})$ 
est \kw{idempotent} si $e \oplus e = e \qquad (\forall e \in E)$.
Si le demi-anneau est idempotent, on peut alors définir la relation
d'ordre partiel $\leq$ comme suit~:
\begin{displaymath}
a \leq b \,\Leftrightarrow\,  (a\oplus b) = a
\end{displaymath}
appelée ordre naturel de $E$. On dit qu'un demi-anneau a la propriété
de \kw{supériorité} si pour tout couple $a,b \in E$:
\begin{displaymath}
a\leq a \otimes b, \qquad b \leq a\otimes b
\end{displaymath}
Ce qui revient à dire que combiner par multiplication deux quantités
$a,b$ renvoie comme résultat une valeur plus grande. Cette propriété est
requise pour utiliser l'algorithme de Dijkstra ou ses dérivés (y
compris l'algorithme de Knuth) dans un contexte de prédiction structurée.




\begin{exo}[Algorithme somme produit]
Instancier l'algorithme de Viterbi (Algorithme
\ref{algo-viterbi-general}) en utilisant le demi anneau 
appelé Avant-\ac{crf} (Figure \ref{fig-semirings}). Simuler ce nouvel
algorithme à l'aide de l'exemple  de \ac{dag} donné en figure
\ref{fig-viterbi-general-dag}. Donner en français une explication de
ce que cet algorithme calcule. 
\end{exo}


\section{Algorithme de Dijkstra et recherche A$\star$}

Dans certains cas, il est possible de reformuler le problème de recherche de la séquence
de poids maximal dans un \ac{dag} comme un problème du plus court
chemin dans un graphe de telle sorte que le problème se résoud avec
l'algorithme de Dijkstra.
 
Intuitivement l'algorithme de Dijkstra peut s'utiliser dans un
contexte de tagging lorsque les scores associés aux arcs
s'interprètent comme des mesures dites de surprise (\cite{hale}) que l'on obtient à partir
de probabilités $(\text{surprise} =  -\log_2(p))$.


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Dijsktra}{$S$,$E$,source,but}
\State $ \delta(s) \gets +\infty$\qquad$(\forall s \in S)$ 
\State $ \delta(\text{source}) \gets \bar{1}$ 
\State $Q \gets s$
\State $V \gets \emptyset$
\While {$Q \not = \emptyset$}
    \State $s \gets$ \Call{Extraire-Min}{$Q$} 
    \State $V \gets V \cup \{s\}$
    \If{$s =$ but}
        \State\Return $\delta(s)$
    \EndIf
    \ForAll{$(s,s') \in AS(s)$}
    \If{$s'\not \in V$}
        \State localscore $\gets \delta(s) \otimes \psi(s,s')$
        \If{localscore $<\delta(s')$}
              \State $\delta(s') \gets$ localscore
              \State \Call{ReordonnerClé}{Q,s'}
        \EndIf
       \EndIf
    \EndFor
\EndWhile
\EndFunction
\end{algorithmic}
\caption{\label{algo-dijkstra-general}Algorithme de Dijkstra}
\end{algorithm}


Commençons par rappeler le fonctionnement de l'algorithme de Dijkstra
dans le cas classique. On suppose un graphe dont les arcs sont
pondérés par des distances entre des stations de métro. Le problème est de trouver le
plus court chemin entre deux stations, la première est appelée la
source, la seconde la destination.

L'algorithme suppose un graphe $G= \langle S,E \rangle$ une file de priorité $Q$. Une file de priorité
est une structure de donnée qui maintient ses arguments triés. On peut
ainsi lui ajouter des éléments pondérés et extraire l'élément de
poids minimal\footnote{On suppose que les poids des éléments
  définissent la relation d'ordre.}.

L'algorithme de Dijkstra, détaillé en Algorithme
\ref{algo-dijkstra-general}, est conceptuellement très simple. 
L'invariant se résume comme suit.
L'algorithme procède en évaluant comment progresser à partir du noeud
$s$ du graphe qui est le plus proche de la source.
Aucun chemin alternatif plus court ne peut mener à $s$ sinon ce serait
un noeud sur ce chemin alternatif qui serait
sélectionné à la place de $s$. L'algorithme termine quand le noeud $s$
est le but à atteindre.

Il faut remarquer que l'algorithme de Dijkstra fonctionne uniquement
si les poids des chemins sont positifs. Dans le cas où certains
chemins ont des poids négatifs, l'algorithme donne un résultat incorrect.

\begin{figure}
\scalebox{0.7}{
\begin{tikzpicture}[xscale=2.5,yscale=2.5]
    \node[shape=ellipse,draw=black] (C) at (-0.5,0.3) {Châtelet};
    \node[shape=ellipse,draw=black] (E) at (-2.5,1) {Etoile};
    \node[shape=ellipse,draw=black] (N) at (3,0) {Nation};
    \node[shape=ellipse,draw=black] (S) at (-1.5,2.5) {Saint-Lazare};
    \node[shape=ellipse,draw=black] (R) at (1,1) {République};
    \node[shape=ellipse,draw=black] (B) at (0.75,-0.25) {Bastille};
    \node[shape=ellipse,draw=black] (M) at (-1.4,-1.5) {Montparnasse};
    \node[shape=ellipse,draw=black] (O) at (-1,1) {Opéra};
    \node[shape=ellipse,draw=black] (I) at (0.75,-2) {Pl. Italie};


    \node[shape=rectangle,fill=white] (X) at (-0.55,1.5) {3};
    \node[shape=rectangle,fill=white] (Y) at (-0.25,2.4) {22};

    \draw [-,opacity=1] (C) -- (O) node[midway,fill=white]{3};
    \draw [-,opacity=1] (C) -- (B) node[midway,fill=white]{3};
    \draw [-,opacity=1] (C) -- (R) node[near end,fill=white]{4};
    \draw [-,opacity=1] (C) -- (E) node[midway,fill=white]{7};
    \draw [-,opacity=1] (C) -- (M) node[midway,fill=white]{7};
    \draw [-,opacity=1] (C) -- (I) node[midway,fill=white]{7};
    \draw [-,opacity=1] (C) -- (I) node[midway,fill=white]{6};
    \draw [-,opacity=1] (C) to [out=30,in=-70] (S);
    \draw [-,opacity=1] (E) -- (M) node[midway,fill=white]{11};
    \draw [-,opacity=1] (M) -- (I) node[midway,fill=white]{7};
    \draw [-,opacity=1] (B) -- (I) node[midway,fill=white]{5};
    \draw [-,opacity=1] (B) -- (R) node[midway,fill=white]{4};
    \draw [-,opacity=1] (N) -- (I) node[midway,fill=white]{9};
    \draw [-,opacity=1] (N) -- (B) node[midway,fill=white]{3};
    \draw [-,opacity=1] (N) -- (R) node[midway,fill=white]{6};
    \draw [-,opacity=1] (O) -- (R) node[near end,fill=white]{5};
    \draw [-,opacity=1] (O) -- (E) node[midway,fill=white]{3};
    \draw [-,opacity=1] (S) -- (M) node[near end,fill=white]{9};
    \draw [-,opacity=1] (S) -- (O) node[midway,fill=white]{2};
    \draw [-,opacity=1] (S) -- (R) node[midway,fill=white]{9};
    \draw [-,opacity=1] (E) to [out=70,in=90] (N);
\end{tikzpicture}
}
\caption{\label{fig-ratp}Plan simplifié du métro parisien}
\end{figure}

\begin{exo}[De \'Etoile à Nation]
Simuler l'algorithme de Dijkstra pour calculer le plus court chemin
entre \'Etoile et Nation sur le plan du métro parisien donné en Figure \ref{fig-ratp}.
\end{exo}
\begin{exo}[De place d'Italie à Saint-Lazare]
Simuler l'algorithme de Dijkstra pour calculer le plus court chemin
entre Place d'Italie et Saint-Lazare sur le plan du métro parisien donné en Figure \ref{fig-ratp}.
\end{exo}
\begin{center}
\scalebox{0.7}{
\begin{tabular}{cl}\toprule
Itération&File de priorité ($Q$)\\\midrule
1& Italie(0)\\
2& Bastille(5) $\prec$ Chatelet(6) $\prec$ Montparnasse(7) $\prec$ Nation(9)\\
3& Chatelet(6) $\prec$ Montparnasse(7) $\prec$ Nation(8) $\prec$ République(9)\\
4& Montparnasse(7) $\prec$ Nation(8) $\prec$ Saint-Lazare(9) $\prec$ Opéra(9) $\prec$ Republique(10) $\prec$ Etoile(13)\\
5 & Nation(8) $\prec$ Saint-Lazare(9) $\prec$ Opéra(9) $\prec$ Republique(10) $\prec$ Etoile(13)\\
6 & {\bf Saint-Lazare(9)} $\prec$ Opéra(9) $\prec$ Republique(10) $\prec$ Etoile(13)\\\bottomrule
\end{tabular}}
\end{center}

\begin{exo}[Historique]
Donner une extension au pseudo-code en figure
\ref{algo-dijkstra-general} pour renvoyer également le plus court
chemin et pas seulement sa valeur.
\end{exo}
\begin{exo}[Invariant de l'algorithme et poids négatifs]
Donner un exemple de graphe comportant au moins un arc de poids
négatif pour lequel une exécution naïve de l'algorithme de Dijkstra
renvoie un résultat incorrect.
\end{exo}
\begin{exo}[Graphe acyclique orienté]
En faisant l'hypothèse que le graphe est un \ac{dag}, proposez une
simplification de l'algorithme \ref{algo-dijkstra-general}
\end{exo}

\paragraph{Application de l'algorithme de Dijkstra en \ac{tal}} 
 Pour les problèmes de \ac{tal} comme le tagging, le problème peut se
 reformuler comme un problème de recherche du plus court chemin
 lorsque le modèle d'apprentissage produit des poids qui s'apparentent
 à des probabilités.  Dans le cadre de ce cours, cet algorithme sera donc approprié pour
être utilisé en combinaison avec des modèles d'apprentissage tels que
\ac{hmm}, \ac{memm} et des modèles neuronaux qui généralisent \ac{memm}.

L'algorithme peut ainsi être réutilisé en représentant le problème par
un graphe identique aux \ac{dags} de programmation dynamique manipulés
par l'algorithme de Viterbi. Contrairement à l'algorithme
de Viterbi, l'algorithme de Dijkstra cherche explicitement un court
chemin, ce qui demande de remplacer la fonction de pondération
probabiliste par une fonction de pondération qui calcule des scores
qui se comportent de manière analogue aux distances entre stations de métro.

Il est d'usage, notamment pour \ac{hmm},
d'utiliser des log-probabilités dans les implémentations pour éviter
les problèmes de manque de précision dans la manipulation de réels
trop proches de 0.  Ici on réutilise cette pratique allègrement~:  si
$p$ est une probabilité de transition, on peut interpréter $-\log(p)$ comme l'effort (ou une longueur de chemin ou encore une surprise) qui permet
d'avancer dans la séquence. Dans ce cas suivre un chemin de très haute
probabilité ($p\approx 1.0$) aura un coût très faible ($-\log(1.0)\approx 0$)
alors que suivre un chemin de très basse probabilité ($p\approx 0.0$)
aura un coût énorme ($-\log(0.0) \approx +\infty$). 
Autrement dit, on suppose que fonction de score $\psi(s_i,s_{i+1}) =
-\log(p)$ où $p$ est une probabilité de transition.
Dans ce contexte, utiliser l'algorithme de Dijkstra revient à chercher
le chemin pour lequel l'effort (ou la surprise) global est le plus
faible\footnote{On verra en section \ref{sec-semi-ring} que ces
  intuitions se formalisent explicitement en termes algébriques. 
L'algorithme de Dijkstra est utilisable lorsque le demi-anneau utilisé pour combiner les
  scores possède une propriété dite de supériorité. Celle-ci
  généralise l'idée que lorsque deux chemins sont combinés la distance
  augmente. Le demi-anneau décrit informellement ici est en fait le demi-anneau tropical.
}.

On peut illustrer cela par un exemple. Considérons les séquence de tags 
$t_1,t_2,t_3,t_4$ et $t_1,t_2,t_3,t_5$. Supposons que $P(t_1) = 0.2, P(t_2|t_1) = 0.8,
P(t_3|t_2) = 0.1,P(t_4|t_3) = 0.5, P(t_5|t_3) = 0.2$. En termes de surprise cumulée, 
on a que~:
\begin{displaymath}
\sigma(t_1,t_2,t_3,t_4) = \sum_{i} \psi(t_{i}, t_{i-1}) = 1.61 + 0.22 + 2.30 + 0.69 
\end{displaymath}
\begin{displaymath}
\sigma(t_1,t_2,t_3,t_5) = \sum_{i} \psi(t_{i} , t_{i-1})  = 1.61 + 0.22 + 2.30 + 1.61 
\end{displaymath}
On voit que la surprise cumulée augmente lors de chaque transition.
et que la séquence de plus haute probabilité aura la plus petite
surprise cumulée. 

On peut démontrer que dans le pire des cas, l'algorithme de Dijkstra a
une complexité un peu plus élevée que l'algorithme de Viterbi. 
La complexité additionnelle est liée à l'usage de la file de priorité
$Q$. 
Par
contre l'algorithme de Viterbi explore en largeur l'ensemble des
noeuds du graphe alors que l'algorithme de Dijkstra est un exemple
d'algorithme d'exploration en profondeur (meilleur d'abord). 
Il est susceptible dans certains cas de
trouver la solution en explorant moins de noeuds. 
C'est ce qui motive l'extension de cet algorithme connue sous le nom d'heuristique \kw{A$\star$}.

\subsection{Algorithme A$\star$}

L'algorithme $A\star$ est un algorithme de recherche du plus court
chemin qui est à voir comme une extension de l'algorithme de Dijkstra.
L'invariant de l'algorithme de
Dijkstra est conservé~: \`a chaque itération c'est le noeud $s$ qui a
le coût $\delta(s)$ le plus faible qui est sélectionné pour la suite de l'exploration.

Par contre l'algorithme $A\star$ change la méthode d'évaluation du
coût. Ce n'est plus uniquement $\delta(s)$ qui représente le coût mais la
combinaison~:
\begin{displaymath}
\phi(s) = \delta(s)+h(s)
\end{displaymath}
Cette fois-ci, le coût $c(s)$ est la somme du coût $\delta(s)$ du
chemin déjà parcouru et d'une heuristique $h(n)$ qui estime le coût du
chemin qui reste à parcourir.  Ainsi l'algorithme de Dijkstra classique est un algorithme $A\star$
pour lequel $h(s) = 0\, (\forall s \in S)$. 


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{A-star}{$S$,$E$,source,but}
\State $ \phi(s) \gets +\infty$\qquad$(\forall s \in S)$ 
\State $ \phi(\text{source}) \gets \bar{1}$ 
\State $Q \gets \text{source}$
\State $V \gets \emptyset$
\While {$Q \not = \emptyset$}
    \State $s \gets$ \Call{Extraire-Min}{$Q$} 
    \State $V \gets V \cup s$
    \If{$s =$ but}
        \State\Return $\delta(s)$
    \EndIf
    \ForAll{$(s,s') \in AS(s)$}
      \If{$s' \not \in V$}
        \State localscore $\gets \delta(s) \otimes \psi(s,s') \otimes h(s')$        
        \If{localscore $<\phi(s')$}
              \State $\phi(s') \gets$ localscore
              \State $\delta(s') \gets \delta(s) \otimes \psi(s,s')$ 
              \State \Call{ReordonnerClé}{Q,s'}
        \EndIf
        \EndIf
    \EndFor
\EndWhile
\EndFunction
\end{algorithmic}
\caption{\label{algo-astar-general}Algorithme A$\star$}
\end{algorithm}


\paragraph{Conception de l'heuristique} La difficulté lors de la
conception d'un algorithme $A\star$ consiste à définir une heuristique
qui permette d'obtenir une \kw{solution optimale}. 
Un algorithme de recherche de court chemin qui renvoie une solution
optimale est un algorithme qui renvoie effectivement comme résultat la
valeur du plus court chemin entre deux points. C'est ce que garantit
l'algorithme de Dijkstra.

Si l'heuristique $h(s)$ est mal définie l'algorithme $A\star$ n'est
pas garanti de renvoyer la solution optimale. On propose d'illustrer
ce point par l'exemple de la recherche du court chemin entre {\sl Place
d'Italie} et {\sl Saint Lazare} à partir du graphe \ref{fig-ratp}.
en comparant l'effet des heuristiques $h_1(s)$ et $h_2(s)$ suivantes
sur la procédure de recherche~:
\begin{center}
\begin{tabular}{lll}\\\toprule
  $s$ & $h_1(s)$&$h_2(s)$\\\midrule
Châtelet& 1&11\\
Bastille&5&12\\
Opéra & 1&1\\
Montparnasse&4&4\\
Nation & 12&12\\
Etoile & 1&1\\
Autres & 0&0\\\bottomrule
\end{tabular}
\end{center}
\begin{center}
\scalebox{0.65}{
\begin{tabular}{cl}\toprule
Itération&File de priorité ($Q$) pour l'heuristique $h_1$\\\midrule
1& Italie(0)\\
2 & Chatelet(7) $\prec$ Bastille(10)  $\prec$ Montparnasse(11) $\prec$ Nation(21)\\
3 & Bastille(10)  $\prec$ Montparnasse(11) $\prec$ Nation(21)\\
4 & {\bf Saint Lazare(9)} $\prec$ Opéra(10) $\prec$ Republique(10) $\prec$
Montparnasse(11) $\prec$ Etoile(13) $\prec$  Nation(21)\\\bottomrule
\end{tabular}}
\end{center}

\begin{center}
\scalebox{0.8}{
\begin{tabular}{cl}\toprule
Itération&File de priorité ($Q$) pour l'heuristique $h_2$\\\midrule
1& Italie(0)\\
2&Montparnasse(11) $\prec$ Bastille(17) $\prec$ Chatelet(17) $\prec$ Nation(21)\\ 
3&{\bf Saint-Lazare(16)} $\prec$ Etoile(17) $\prec$  Bastille(17) $\prec$ Chatelet(17) $\prec$ Nation(21)\\\bottomrule
\end{tabular}}
\end{center}
On peut constater que l'heuristique $h_1$ renvoie effectivement la solution
optimale en moins d'itérations que l'algorithme de Dijkstra
classique. 
Par contre l'heuristique $h_2$ renvoie une solution non
optimale (en peu d'itérations également).
La cause de la non optimalité de $h_2$ vient essentiellement du fait que l'algorithme
fait -- à tort -- l'hypothèse qu'il est très couteux de rejoindre la
destination en passant par Châtelet~: l'heuristique $h_2$ indique un coût de
11 pour rejoindre la destination alors que le coût réel est de 3.

Une heuristique $h$ est dite \kw{admissible} si pour tout $s\in S$ 
la distance estimée $h(s)$ n'est jamais strictement supérieure à la distance
minimale réelle qu'il reste à parcourir pour atteindre la destination
depuis $s$.

La seconde condition que l'heuristique $h$ doit 
satisfaire pour garantir l'optimalité de l'algorithme est la condition
de \kw{monotonie} (ou de consistance)~:
\begin{displaymath} 
h(s) \leq \psi(s,s') + h(s') \qquad \forall (s,s') \in AS(s) 
\end{displaymath}
Ce qui revient à dire que l'estimation du coût pour arriver à
destination depuis $n$ doit être inférieur au coût pour arriver à
destination à partir de chacun de ses successeurs dans le graphe. C'est une
généralisation de la condition excluant les chemins de poids négatif
pour l'algorithme de Dijkstra. On peut alternativement reformuler
cette condition en incluant le terme $\delta(s)$~:
\begin{displaymath} 
\delta(s) + h(s) \leq \delta(s) + \psi(s,s') + h(s') \qquad \forall (s,s') \in AS(s) 
\end{displaymath}
pour exprimer explicitement que la longueur d'un chemin ne peut pas
raccourcir.
En général satisfaire l'une des deux conditions permet de satisfaire
l'autre. Mais ce n'est pas toujours vrai.

En \ac{tal} la recherche $A\star$ a surtout été utilisée dans des
contextes d'analyse syntaxique automatique (comme extensions de
l'algorithme de Knuth).

En résumé, la conception d'une bonne heuristique $A\star$ est non
triviale. L'heuristique évidente $h(s) = 0$ n'aide pas à réaliser une
meilleure recherche que l'algorithme de Dijkstra. Une heuristique plus informative qui préserve
l'optimalité demande de vérifier des propriétés qui ne sont pas
triviales à satisfaire en pratique. Pour cette raison, on trouve
souvent dans la littérature des heuristiques approximatives qui sacrifient l'optimalité de la solution.


\subsection{Recherche en largeur et en profondeur}
mettre commentaires sur complexité -> depth first plus haute
complexité pire des cas mais espoir d'atteindre la solution plus rapidement.

\section{Les méthodes de recherche approximatives}

Tant l'algorithme de Viterbi que l'algorithme de Dijsktra (et
A$\star$) sont conçus pour donner une solution optimale au problème de
recherche du chemin de poids maximal (resp. minimal).

Bien que ces algorithmes ont une complexité polynomiale --~considérée
comme acceptable~-- ces algorithmes sont potentiellement lents lorsque
les phrases sont longues où lorsque l'espace des états est de taille
considérables. Par exemple, Viterbi a une complexité en ${\cal
  O}(NK^2)$, lorsque la taille du jeu de tags $K$ est importante (ce
qui est notamment le cas pour des modèles dont l'historique est très riche)
les temps de calcul deviennent potentiellement prohibitifs.

Dans ce type de situation, on peut faire le choix d'utiliser des
méthodes de recherche de solutions qui ne garantissent pas
l'optimalité, comme la recherche gloutonne ou la recherche par
faisceau. Il s'agit de méthodes qui n'explorent qu'une petite partie
de l'espace de solutions et qui sont en général très efficaces.

Comme il s'agit de méthodes qui n'explorent qu'une toute petite
partie de l'espace des solutions (séquences de tags possibles)
celle-ci sont généralement utilisées en combinaison avec une fonction
de score très bien informée sur le problème à traiter de telle sorte que la
partie de l'espace explorée a, par hypothèse, de grandes chances de contenir la
solution optimale. 

On présente ici deux méthodes couramment utilisées~:  la recherche
gloutonne et la recherche par faisceau (beam) comme des variantes de
la méthode de recherche dans un arbre de solutions (Algorithme
\ref{algo-searchtree}) pour des systèmes de transitions. 
Mais ces méthodes pourraient également se formuler dans un contexte où l'espace de
recherche est représenté par un graphe.

\subsection{Recherche gloutonne}

La méthode de recherche gloutonne est le cas dégénéré de la méthode de
recherche du meilleur d'abord. \`A chaque itération, l'algorithme évalue
le score de tous les successeurs d'un état. C'est l'unique successeur
de meilleur score qui est sélectionné pour la suite de la recherche
(Algorithme \ref{algo-greedy-tree}).
\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{GreedySearch}{S,B,$\sigma$}
\If{$B \not = \epsilon$}
\State maxscore $\gets \bar{0}$
\ForAll{$t \in T$}
	\State localscore $\gets \sigma \otimes \psi(S,B,t)$
        \State maxscore $\gets$ \Call{$\oplus$}{maxscore,localscore}
\EndFor
\State\Return \Call{GreedySearch}{$S|t$,$_{\ominus}$B, maxscore}
\Else
  \State\Return $\sigma$
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-greedy-tree}Algorithme de recherche glouton}
\end{algorithm}
Il est évident que cet algorithme donne des solutions approximatives
et sans garantie d'optimalité. Par contre la complexité de cet
algorithme, en ${\cal O}(n K)$,  est linéaire en temps. Autrement dit,
cet algorithme est très efficace à l'usage.

L'aspect approximatif de cet algorithme peut être contrebalancé
en utilisant des scores locaux  très bien choisis pour guider la recherche vers une solution proche de
l'optimum global. Ce
scénario est très utilisé à l'heure actuelle par les systèmes pondérés
par des réseaux de neurones profonds. Ceux-ci  obtiennent
empiriquement de très
bons résultats.

\begin{exo}
Augmenter l'algorithme \ref{algo-greedy-tree} pour qu'il renvoie
non seulement le score du chemin de poids maximal, mais aussi
la séquence de tags de ce chemin.
\end{exo}
\begin{exo}
Comparer le meilleur chemin renvoyé par l'algorithme glouton avec
celui 
renvoyé par l'algorithme de Viterbi à partir de l'exemple \ref{fig-viterbi-general-dag}.
\end{exo}

\subsection{Recherche par faisceau}

La recherche par faisceau est une extension de la méthode par recherche gloutonne.
La recherche par faisceau est un algorithme qui progresse
essentiellement en largeur dans l'arbre de recherche. \`A chaque itération il avance en
profondeur dans $|\mathcal{B}|$ branches de l'arbre jusqu'à atteindre les
feuilles, et ce sans jamais faire marche arrière.

Les $|\mathcal{B}|$ branches sélectionnées pour continuer l'exploration à l'étape
suivante constituent le faisceau. 
Le choix des branches destinées à continuer l'exploration 
est heuristique. Généralement on choisit les $|\mathcal{B}|$ branches qui ont le
plus haut score. 

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{BeamSearch}{$\mathcal{B}$}
\State $\mathcal{B}' \gets \emptyset$
\ForAll {$\langle S,B,\sigma\rangle \in \mathcal{B}$}
\If {$B = \epsilon$}
\State \Return $\sigma$
\EndIf
\ForAll{$t \in T$}
	\State localscore $\gets \sigma \otimes \psi(S,B,t)$
        \State $\mathcal{B'} \gets \mathcal{B}' \cup \{\langle
        S|t,_\ominus B,\text{localscore}\rangle\}$
\EndFor
\EndFor
\State $\mathcal{B} \gets$ \Call{$\mathcal{B}$-Select}{$\mathcal{B'}$}
\State \Return \Call{BeamSearch}{$\mathcal{B}$}
\EndFunction
\end{algorithmic}
\caption{\label{algo-beam-tree}Algorithme de recherche en faisceau}
\end{algorithm}
L' algorithme est donné en Algorithme \ref{algo-beam-tree}.
Notons que la fonction \ac{$\mathcal{B}$-Select} est chargée de sélectionner $|\mathcal{B}|$ éléments dans un
ensemble. Il s'agit dans la très grande généralité des cas
 de sélectionner les $|\mathcal{B}|$ éléments de scores les plus élevés (ou plus faibles)
 mais des variantes sont envisageables. Par exemple la recherche par faisceau
 stochastique consiste à sélectionner $|\mathcal{B}|$ éléments aléatoirement
 proportionnellement à leur score. 

L'intérêt de cette méthode est son efficacité~: la complexité reste faible~:
${\cal O}(n K |\mathcal{B}|)$, c'est-à-dire essentiellement linéaire.

On peut penser que le faisceau peut corriger les faiblesses de la méthode
gloutonne mais en pratique on observe souvent que les faisceaux
contiennet des hypothèses très similaires.
Comme la méthode gloutonne, l'algorithme de recherche en faisceau ne
garantit pas de renvoyer une solution optimale. 
En effet, une solution optimale qui a un mauvais score préfixe lors
des premières itérations ne sera plus jamais considérée. 

Il faut bien garder à l'esprit que cette méthode renvoie un
pseudo-résultat maximal, ce qui peut avoir des conséquences non
négligeables dans certains contextes d'utilisation
(comme illustré en chapitre XX)

\begin{exo}
Augmenter l'algorithme \ref{algo-beam-tree} pour qu'il renvoie
non seulement le score du chemin de poids maximal, mais aussi
la séquence de tags de ce chemin.
\end{exo}

\chapter{Rappels de classification non structurée}

= modèles + descente de (sous-) gradient.

\section{Minimum d'une fonction strictement convexe}

%$f(\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N)$

\subsection{Fonctions monovariées}


Si on sait que la fonction est strictement convexe (resp. concave) ---~
 ce qui est le cas pour tous les modèles d'apprentissage décrits dans
 ce cours~--- (à l'exception des réseaux de neurones), alors il existe
 un minimum (resp. maximum) global unique.
On trouve ce minimum en résolvant :
\begin{equation}
\label{eq-derivative}
\frac{\delta f(x)}{\delta x} = 0 
\end{equation}
Par exemple si $f(x) = (x-3)^2$, on a que $\frac{\delta f(x)}{\delta
  x} = 2(x-3)$. En résolvant $2(x-3) = 0$, on trouve $x=3$. Comme la
fonction est convexe, on sait que $x=3$ est le minimum unique.
Cette méthode de résolution est appelée méthode analytique.

\begin{figure}[htbp]
\begin{center}
\scalebox{0.5}{
\begin{tabular}{cc}
\begin{tikzpicture}
\foreach \x in {-1,0,1,2,3,4,5,6}
    {        
      \coordinate (A\x) at ($(0,0)+(\x*0.5cm,0)$) {};
      \draw ($(A\x)+(0,5pt)$) -- ($(A\x)-(0,5pt)$);
      \node at ($(A\x)+(0,-3ex)$) {\x};
    }
    \draw[->] (-1,0) -- (5,0) node[right] {$x$};
    \draw[->] (0,-0.25) -- (0,6) node[above] {$f(x)$};
    \draw[scale=0.5,domain=-0.3:6.3,smooth,variable=\x,blue] plot({\x},{(\x -3) * (\x -3)});
\end{tikzpicture}
&
\begin{tikzpicture}
\foreach \x in {-1,0,1,2,3,4,5,6}
    {        
      \coordinate (A\x) at ($(0,0)+(\x*0.5cm,0)$) {};
      \draw ($(A\x)+(0,5pt)$) -- ($(A\x)-(0,5pt)$);
      \node at ($(A\x)+(0,-3ex)$) {\x};
    }
    \draw[->] (-1,0) -- (5,0) node[right] {$x$};
    \draw[->] (0,-0.25) -- (0,6) node[above] {$f(x)$};
    \draw[scale=0.5,domain=-0.3:6.3,smooth,variable=\x,blue] plot({\x},{10+-(\x -3) * (\x -3)});
\end{tikzpicture}\\
$f(x) = (x-3)^2$&$f(x) = -(x-3)^2 + 10$
\end{tabular}
}
\end{center}
\caption {Fonctions strictement convexe (gauche) et concave (droite)}
\end{figure}

Pour la très grande majorité  des fonctions utilisées par les modèles
d'apprentissage utilisés en \ac{tal},
résoudre (\ref{eq-derivative}) n'est pas possible analytiquement. On
utilise plutôt une méthode de résolution numérique appelée \kw{descente de gradient}.
\'Etant donnée une première hypothèse $x_0 = c$, la méthode de
descente de gradient consiste à calculer une suite d'hypothèses
$x_0,x_1,\ldots x_k$ qui approchent progressivement la solution.
La dérivée en un point $x_i$, $\frac{\delta f(x_i)}{\delta x}$ nous donne
la pente de la tangente en $x_i$. On sait que pour se rapprocher de la
solution, il faut choisir un point $x_{i+1} = x_i - \frac{\delta
  f(x_i)}{\delta x}$. Pour se déplacer plus ou moins vite dans une
direction, on utilise généralement un pas de gradient noté $\alpha$ de
telle sorte qu'on choisit $x_{i+1}$ comme suit~:
\begin{displaymath}
x_{i+1} = x_i - \alpha   \frac{\delta
  f(x_i)}{\delta x}
\end{displaymath}
Prenons l'exemple  de la fonction $f(x) = (x-3)^2$ et supposons $x_0
= 0$ et $\alpha =  0.1$, le début de la suite $x_0,x_1,x_2\ldots$ prend la forme suivante~:
\begin{center}
\begin{tabular}{cc}\toprule
$x_i$& $\alpha\,  2(x-3)$\\\midrule
0&$0.1\times 2\times (0-3) = -0.6$\\
0.6&$0.1\times 2\times (0.6-3) = -0.48$\\
1.08&$0.1\times 2\times  (1.08-3) = -0.384$\\
1.464&\ldots\\\bottomrule
\end{tabular}
\end{center}

\subsection{Fonctions de plusieurs variables}

La méthode de descente de gradient se généralise au cas de fonctions de plusieurs variables, 
de la forme $f(\mathbf{w})$, où $\mathbf{w}$ est un vecteur de
variables ($\mathbf{w}\in \mathbb{R}^d$).
\begin{displaymath}
\mathbf{w}_{i+1} = \mathbf{w}_i - \alpha   \nabla f(\mathbf{w})
\end{displaymath}
où $\nabla f(\mathbf{w})$ est le \kw{vecteur gradient} au point $\mathbf{w}$. 
Un vecteur gradient est un vecteur de dérivées
partielles tel que $\nabla f(\mathbf{w}) = \frac{\partial f}{\partial
  w_1}(\mathbf{w}) \ldots \frac{\partial f}{\partial w_d}(\mathbf{w})$. 
Pour trouver le minimum d'une fonction strictement convexe $f(\mathbf{w})$, il faut alors
résoudre $\nabla f(\mathbf{w})= \mathbf{0}$, c'est-à-dire un système
d'équations de la forme~:
\begin{displaymath}
\left[\begin{array}{lll}
 \frac{\partial f}{\partial
  w_1}(\mathbf{w})&=&0\\
\vdots&\vdots&\vdots\\
 \frac{\partial f}{\partial
  w_d}(\mathbf{w})&=&0
\end{array}\right]
\end{displaymath}
Prenons l'exemple de la fonction de deux variables $f(w_1,w_2) =
w_1^2+w_2^2+2w_1+8w_2$ dont le graphe est représenté en figure \ref{fig-bivariate}.
On a que  $\frac{\partial f}{\partial w_1}(\mathbf{w}) = 2w_1+2$ et que  $\frac{\partial f}{\partial
  w_2}(\mathbf{w}) = 2w_2+ 8$. Pour annuler le gradient, il faut donc résoudre
analytiquement
le système d'équations~:
\begin{displaymath}
\left[\begin{array}{lll}
2w_1+ 2&=&0\\
2w_2+ 8&=&0
\end{array}\right]
\end{displaymath}
ce qui donne $(w_1,w_2) = (-1,-4)$ et ce qui nous permet de déterminer
que sa valeur au minimum est $-1^2-4^2-2-32 =-17$. 
Par la suite on utilisera la notation suivante pour référencer ces deux valeurs~:
\begin{eqnarray*}
(-1,-4)&=&\mathop{\text{argmin}}_{\mathbf{w}\in\mathbb{R}^2} f(\mathbf{w})\\
-17 &=&\text{min} f(\mathbf{w})
\end{eqnarray*}
La résolution par la méthode
numérique suit le même principe que précédemment. Pour le déroulé de
l'exemple, on suppose que
$\mathbf{w}_0=(0,0)$ et $\alpha=0.1$.
\begin{center}
\scalebox{0.9}{
\begin{tabular}{lll}\toprule
$\mathbf{w}_i$& $\alpha\,  (2w_1+2))$&$\alpha\,  (2w_2+8))$\\\midrule
(0,0)&$0.1\times (2\times 0 + 2) = 0.2$&$0.1\times (2\times 0+8) = 0.8$\\
(-0.2,-0.8)&$0.1\times (2\times -0.2 + 2) = 0.16$&$0.1\times (2\times -0.8+8) = 0.64$\\
(-0.36,-1.44)&$0.1\times (2\times -0.36 + 2) = 0.128$&$0.1\times (2\times -1.44+8) = 0.512$ \\
(-0.488,-1.952)&\ldots&\ldots\\\bottomrule
\end{tabular}
}
\end{center}

La méthode de résolution numérique pour fonctions strictement convexes
de plusieurs variables se résume par un algorithme dit de descente de
gradient qui est explicité en Algorithme \ref{algo-GD}. Le critère
d'arrêt est en général un test de convergence de la forme
$f(\mathbf{w}_{i+1}) \approx f(\mathbf{w}_{i})$. On peut
également donner une borne sur le nombre maximal d'itérations si la
précision de la solution n'est pas essentielle.


\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}
\begin{axis}
[
    %title={$f(w_1,w_2) = w_1^2+w_2^2+2w_1+8w_2$},
    view={0}{90}
]
\addplot3[
    contour gnuplot={levels={0,-5,-10, -15, -16.5}}
]
{x^2+y^2+2*x+8*y};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{\label{fig-bivariate}Contour de la fonction $f(w_1,w_2)= w_1^2+w_2^2+2w_1+8w_2$}
\end{figure}

\begin{algorithm}
\begin{algorithmic}
\Function{GradientDescent}{$\alpha$,$f(\mathbf{w})$}
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State $\mathbf{w} \gets \mathbf{w} - \alpha \nabla f(\mathbf{w})$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-GD}Algorithme de descente de gradient}
\end{algorithm}


Un des points difficile concerne le choix du pas de gradient $\alpha$.
Trop petit, l'algorithme progresse trop lentement vers la solution,
trop grand, l'algorithme risque de diverger. Il existe un très grand
nombre de méthodes de descente de gradient qui traitent les problèmes
mentionnés ici et qui ont fait l'objet d'études considérables en
calcul numérique et en optimisation. 
Les méthodes utilisées en \ac{tal}, et abordées dans ce cours restent en général particulièrement
simples et approximatices. Celles-ci sont adaptées au traitement de jeux de données (1) de très
grande dimensionalité et (2) comportant un très grand nombre d'exemples.
Ceci dit, dans certains cas, il peut être utile de s'appuyer sur des librairies de
calcul numérique comme {\tt scipy.optimize}.

\begin{exo}[Montée de gradient]
La fonction $f(w_1,w_2)= -(w_1^2+w_2^2+2w_1+8w_2)$ est
strictement concave. Calculer son gradient et définissez un algorithme de montée de gradient
qui permet de déterminer numériquement son maximum.
\end{exo}


\section{Régression logistique}

Les modèles logistiques sont des modèles qui permettent de prédire une
variable binaire $Y =  \{0,1\}$ à partir d'un certain nombre de
prédicteurs notés $\mathbf{x}\in \mathbb{R}^d$ et de paramètres $\mathbf{w}\in \mathbb{R}^d$.
Il s'agit d'une brique de base pour plusieurs modèles de classification plus complexes.

\paragraph{Modèle} Supposons que l'on ait observé les résultats de
deux tests d'un étudiant au contrôle continu. 
Celui-ci obtient la note $x_1 = 6$ et la note $x_2 = 7$, ce qui
constitue le vecteur d'observations $\mathbf{x}$.
Un modèle logistique permet par exemple de donner une probabilité de succès (de réussite à l'examen)
$P(Y=1| \mathbf{x};\mathbf{w})$ à l'aide de la formule suivante~:
\begin{equation}
 P(Y=1|\mathbf{x}; \mathbf{w}) =\frac{e^{\mathbf{w}^T
     \mathbf{x}}}{1+e^{\mathbf{w}^T \mathbf{x}}}
\end{equation}
où le vecteur de poids $\mathbf{w}$ est supposé estimé depuis un jeu
de données. Comme $Y =  \{0,1\}$, on peut remarquer que~:
\begin{displaymath}
P(Y=0|\mathbf{x};\mathbf{w}) = 1 - P(Y=1| \mathbf{x};\mathbf{w})
\end{displaymath}
ce qu'il est utile de développer analytiquement pour la suite~:
\begin{eqnarray}
P(1|\mathbf{x};\mathbf{w}) &=&\frac{\text{exp}(\mathbf{w}^T
     \mathbf{x})}{1+\text{exp}(\mathbf{w}^T
     \mathbf{x})}\label{eq-logistic-positive}\\
P(0|\mathbf{x};\mathbf{w}) &=& 1 - \frac{\text{exp}(\mathbf{w}^T
     \mathbf{x})}{1+\text{exp}(\mathbf{w}^T \mathbf{x})}\\
&=&\frac{1+\text{exp}(\mathbf{w}^T \mathbf{x})}{1+\text{exp}(\mathbf{w}^T \mathbf{x})} - \frac{\text{exp}(\mathbf{w}^T
     \mathbf{x})}{1+\text{exp}(\mathbf{w}^T \mathbf{x})}\\
&=&\frac{1}{1+\text{exp}(\mathbf{w}^T \mathbf{x})}\label{eq-logistic-negative}
\end{eqnarray}

\paragraph{Estimation des paramètres}
Un mini jeu de données pour estimer des paramètres d'un modèle de
régression logistique aura par exemple l'allure suivante~:
\begin{center}
\begin{tabular}{llll}\toprule
$y$&$x_0$&$x_1$&$x_2$\\\midrule
1   & 1       &    7   &  9 \\
1   &    1    &    6    &8\\
0   & 1       &    4    & 5\\
0  & 1        &   3      &   4\\
1  &  1       &  9    &6\\\bottomrule
\end{tabular}
\end{center}
où $y$ dénote le résultat binaire observé (comme la réussite à
l'examen pour un étudiant donné), la colonne $x_0$ dénote le biais 
et chacune des autres colonnes $x_i$ dénotera par exemple le résultat
de chaque étudiant aux tests intermédiaires. On note un jeu de données 
comme suit~: $D= \mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$ pour dire que le
jeu de données comporte $N$ lignes qui apparient chacune un vecteur de données
$\mathbf{x}_i$ et une prédiction observée $y_i$.

L'objectif de la méthode d'estimation des paramètres par \kw{maximum
  de vraisemblance} consiste à trouver la valeur du vecteur
$\mathbf{w}$ telle que~:
\begin{displaymath}
\mathbf{w} = \mathop{\text{argmax}}_{\mathbf{w} \in \mathbb{R}^d} \prod_{i=1}^N P(y_i|\mathbf{x}_i; \mathbf{w}) 
\end{displaymath}
où la fonction de vraisemblance $f(\mathbf{w}) =  \prod_{i=1}^N P(y_i|\mathbf{x}_i; \mathbf{w})$
est ce qu'on appelle la \kw{fonction objective} du problème d'optimisation.
Le facteur $P(y_i|\mathbf{x}_i; \mathbf{w})$ dénote la probabilité que
le modèle donne à la ligne de donnée $i$ avec une certaine valeur de
paramètres $\mathbf{w}$. Cette probabilité prendra la forme
$P(1|\mathbf{x}_i;\mathbf{w})$ si $y_i$ vaut 1 et la forme 
$P(0|\mathbf{x}_i;\mathbf{w})$ si $y_i$ vaut 0. Pour éviter de
manipuler les deux formules (\ref{eq-logistic-positive}) et (\ref{eq-logistic-negative}) dans ce qui suit,
on utilise la formule synthétique (et équivalente) suivante~:
\begin{displaymath}
P(y_i |\mathbf{x}_i;\mathbf{w}) = \frac{\text{exp}(y_i(\mathbf{w}^T\mathbf{x}_i))}{1+\text{exp}(\mathbf{w}^T\mathbf{x}_i)}
\end{displaymath}
où $y_i\in \{1,0\}$ prend la valeur de la ligne qui lui correspond dans le jeu de données.

Comme la fonction de (log-)vraisemblance est une fonction strictement
concave, il ne reste
plus qu'à obtenir une forme analytique du gradient de cette fonction
pour réaliser la maximisation par montée de gradient.
Pour simplifier les calculs, on commence par utiliser la version
logarithmique de la fonction objective~:
\begin{eqnarray}
\hat{\mathbf{w}} &=& \mathop{\text{argmax}}_{\mathbf{w} \in
  \mathbb{R}^d} \prod_{i=1}^N P(y_i|\mathbf{x}_i; \mathbf{w})\\
&=&\mathop{\text{argmax}}_{\mathbf{w} \in  \mathbb{R}^d} \sum_{i=1}^N
\log P(y_i|\mathbf{x}_i; \mathbf{w})\\
&=&\mathop{\text{argmax}}_{\mathbf{w} \in  \mathbb{R}^d} \sum_{i=1}^N
y_i ( \mathbf{w}^T \mathbf{x}_i )- \log ( 1+e^{\mathbf{w}^T
  \mathbf{x}_i} )
\end{eqnarray}
Dont chacune des dérivées partielles $\frac{\partial f}{\partial w_j}(\mathbf{w})$ au point $\mathbf{w}$
s'obtient comme suit~:
\begin{eqnarray}
\frac{\partial f(\mathbf{w})}{\partial w_j}&=&\frac{\partial \sum_{i=1}^N
y_i ( \mathbf{w}^T \mathbf{x}_i ) - \log ( 1+e^{\mathbf{w}^T
  \mathbf{x}_i} )}{\partial w_j}\\
&=&\sum_{i=1}^N y_i  x_{ij} - \frac{\partial \log [ 1+e^{\mathbf{w}^T
  \mathbf{x}_i} ] }{\partial w_j}\\
&=&\sum_{i=1}^N y_i  x_{ij} - 
\frac{\frac{\partial e^{\mathbf{w}^T  \mathbf{x}_i} }{\partial
    w_j}}{1+ e^{\mathbf{w}^T  \mathbf{x}_i}}\\
&=&\sum_{i=1}^N y_i  x_{ij} - 
\frac{e^{\mathbf{w}^T  \mathbf{x}_i} x_{ij}} {1+ e^{\mathbf{w}^T  \mathbf{x}_i}}\\
&=&\sum_{i=1}^N y_i  x_{ij} - [ P( 1 | \mathbf{x}_i,\mathbf{w}) \, x_{ij} ]\\
&=&\sum_{i=1}^N x_{ij} \, [ y_i  - P( 1 | \mathbf{x}_i,\mathbf{w}) ]
\end{eqnarray}
Autrement dit, le gradient $\nabla f(\mathbf{w})$ au point
$\mathbf{w}$ correspond au vecteur $(\frac{\partial f}{\partial w_1}(\mathbf{w}) \ldots
\frac{\partial f}{\partial w_d}(\mathbf{w}))$ qui prend la forme suivante~:
\begin{displaymath}
\nabla f(\mathbf{w}) = \sum_{i=1}^n  \mathbf{x}_{i} \, [ y_i  - P( 1 | \mathbf{x}_i,\mathbf{w}) ]
\end{displaymath}
Dans ce contexte l'algorithme de descente de gradient  (ici de montée)  prend la forme
donnée en algorithme \ref{algo-logistic-gradient}.
\begin{algorithm}
\begin{algorithmic}
\Function{BatchGradientAscent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State $\mathbf{w} \gets \mathbf{w} + \alpha \sum_{i=1}^N \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-logistic-gradient}Algorithme de montée  de gradient (batch)}
\end{algorithm}
Le cas de la régression logistique n'est pas isolé. En fait dans la
plupart des modèles d'apprentissage, le gradient prend la forme
générale suivante~:
\begin{equation}
\label{eq-sgd-gradient}
\nabla f(\mathbf{w}) = \sum_{i=1}^n  \ell(y_i, \mathbf{x}_{i} ,\mathbf{w})
\end{equation}
où $\ell(y_i, \mathbf{x}_{i} ,\mathbf{w})$ représente une fonction qui
compare la prédiction du modèle étant donné la valeur courante de $\mathbf{w}$
pour un exemple $i$ à la valeur de référence observée dans les données $y_i$.

\subsection{Descente de gradient stochastique}

Dans un contexte d'apprentissage artificiel pour le \ac{tal}, la
taille $N$ du jeu de données est en général considérable.
De telle sorte que l'algorithme de descente (ou de montée) de gradient
peut devenir un processus très coûteux en temps de par la nécessité à
chaque itération de parcourir tout le jeu de données pour évaluer le
gradient.


La méthode de \kw{descente de gradient stochastique} (\ac{sgd}) cherche à
corriger ce problème en posant l'hypothèse simplificatrice suivante~:
\begin{displaymath}
\nabla f(\mathbf{w}) \approx \ell(y_i,\mathbf{x}_i; \mathbf{w}) \qquad
({i \sim \text{\sc Uniform}(1,N)})
\end{displaymath} 
Celle-ci consiste à approximer le gradient, en principe calculé à
partir de tout le jeu de données par  un gradient tiré au sort sur un
seul exemple. L'idée est qu'après un nombre suffisant d'itérations, la
très grande majorité des exemples du jeu de données auront été tirés
au sort. On donne la variante \ac{sgd} de l'algorithme de
descente\footnote{Pour la régression logistique il faut utiliser la montée.} de
gradient en algorithme \ref{algo-gradient-sgd}.
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{StochasticGradientDescent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State $i \sim$ \Call{Uniform}{1,N}
\State $\mathbf{w} \gets \mathbf{w} - \alpha\, \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-gradient-sgd}Algorithme de descente de gradient stochastique}
\end{algorithm}
Vu que les mises à jour du gradient sont dans ce nouveau contexte
beaucoup plus fréquentes, on espère que le processus global convergera
plus rapidement vers une solution.
Notons également, que dans la pratique, on trouve couramment la
variante donnée en algorithme \ref{algo-gradient-sgd-epoch}.
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{StochasticGradientDescent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State\Call{Shuffle}{$\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$}
\For{$1\leq i\leq N$}
    \State $\mathbf{w} \gets \mathbf{w} - \alpha\, \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\EndFor
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-gradient-sgd-epoch}Variante de l'algorithme de descente de gradient stochastique}
\end{algorithm}


Cet algorithme, très utilisé en \ac{tal}, connaît de nombreuses
variantes, une des plus importantes est la variante dite en minibatch.
Celle-ci consiste à sélectionner aléatoirement un nombre d'exemple $k$
($1 < k \ll N)$ pour évaluer le gradient. Cette variante est
particulièrement utilisée  pour paralléliser les calculs sur plusieurs
processeurs. L'idée est que chaque processeur calcule indépendamment 
un gradient approximé pour le minibatch qui lui est assigné. La mise à
jour des poids est ensuite réalisée séquentiellement.

La force de la méthode \ac{sgd} est aussi son problème principal.
Le problème essentiel de la méthode c'est l'aspect aléatoire.
Il est possible que certains exemples aberrants dans les données
créent des estimations approximatives de gradients bruitées, ce qui
peut perturber l'estimation des poids, surtout si ces exemples sont
tirés en fin de procédure.

Pour corriger ce problème, on utilise couramment la version moyennée
qui est appelée \kw{descente de gradient stochastique moyennée} (\ac{asgd}).
L'idée de ce dernier algorithme est de maintenir une somme cumulée des
différents vecteurs $\mathbf{w}$ obtenus au cours des itérations et de
renvoyer la moyenne. Ce type de méthode peut être vue comme une
application de la loi des grands nombres dans le contexte de la descente
de gradient (Algorithme \ref{algo-asgd}).  
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{AveragedStochasticGradientDescent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\State $\bar{\mathbf{w}} \gets \mathbf{0}$
\State $C \gets 0$
\While{non convergence}
\State $i \sim$ \Call{Uniform}{1,N}
\State $\mathbf{w} \gets \mathbf{w} - \alpha\, \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\State $\bar{\mathbf{w}} \gets \bar{\mathbf{w}} + \mathbf{w}$
\State $C \gets C+1$
\EndWhile
\State\Return $\bar{\mathbf{w}}/C$
\EndFunction
\end{algorithmic}
\caption{\label{algo-asgd}Algorithme de descente de gradient moyennée (ASGD)}
\end{algorithm}


\subsection{Instabilités numériques}

$\text{exp}(x)$ peut créer un overflow si $x$ trop grand.
Or on a l'équivalence suivante
\begin{eqnarray}
\frac{e^x}{1+e^x} &= &\frac{e^x}{1+e^x} \frac{e^{-x}}{e^{-x}}\\
&=&\frac{1}{(1+e^x)e^{-x}}\\
\label{eq-logisitic-positive}&=&\frac{1}{e^{-x}+1}
\end{eqnarray}
Utiliser (\ref{eq-logisitic-positive}) lorsque $x$ est positif permet
d'éviter l'overflow. Utiliser $\frac{e^x}{1+e^x}$ lorsque $x$ est
négatif permet d'éviter l'overflow (dans l'autre sens).


\section{Régression logistique multinomiale}

Le modèle de régression logistique multinomiale est une généralisation
du modèle de régression logistique au cas où $Y$ est un ensemble de deux valeurs
discrètes ou plus. Un tel modèle prédit une probabilité
$P(y|\mathbf{x};\mathbf{w})$ pour chaque classe $y\in Y$ étant donné
un vecteur d'observations $\mathbf{x}\in \mathbb{R}^d$ et une matrice
de poids $\mathbf{w}\in \mathbb{R}^{d\times|Y|}$.

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}

 \matrix (mat) at (0,0) [matrix of nodes,ampersand replacement=\&,
    nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $z_{y_1}$\\
      $z_{y_2}$\\
      $z_{y_3}$\\
    };

    \node (A) at (1,0){=};
    \matrix (mat) at (4,0) [matrix of nodes,ampersand replacement=\&,
    nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $w_{11}$ \& $w_{12}$ \& $w_{13}$ \& $w_{14}$ \&  $w_{15}$\\
      $w_{21}$ \& $w_{22}$ \& $w_{23}$ \& $w_{24}$ \&  $w_{25}$\\
      $w_{31}$ \& $w_{32}$ \& $w_{33}$ \& $w_{34}$ \&  $w_{35}$\\    
    };

  \matrix (mat) at (8,0) [matrix of nodes,ampersand replacement=\&,
    nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $x_{1}$ \\
      $x_{2}$ \\
      $x_{3}$ \\
      $x_{4}$ \\
      $x_{5}$ \\
    };

  \end{tikzpicture}
\caption{\label{fig-logistic-multinomial-schema}Représentation
schématique d'un modèle de régression
  logistique multinomiale ($\mathbf{w}\in\mathbb{R}^{5\times 3}$, $\mathbf{x}\in\mathbb{R}^5$)}
\end{center}
\end{figure}

En première approximation, on peut considérer qu'
un vecteur de poids $\mathbf{w}_y \in \mathbb{R}^d$ (une ligne de la
matrice) correspond à chaque classe $y\in Y$.
Le score $z_y$ de la classe $y$  se calcule par le produit scalaire $\mathbf{w}^T\mathbf{x}$.
On peut ainsi calculer le score de l'ensemble des classes par le
produit de la matrice $\mathbf{w}$ et du vecteur $\mathbf{x}$, ce qu'on illustre
schématiquement en figure \ref{fig-logistic-multinomial-schema}.

Pour obtenir des probabilités à partir du vecteur de scores --
positifs ou négatifs --  on les transforme d'abord en nombres positifs à l'aide de la
fonction exponentielle (exp) puis en divisant chacun de ces nombres
par le total des scores $(\sum_y z_y )$, ce qui donne le modèle de
régression logistique multinomiale\footnote{Cette fonction de
  normalisation de scores en probabilités est également appelée fonction softmax.}~:
\begin{equation}
\label{eq-multinomial-logistic-numeric}
P(y|\mathbf{x};\mathbf{w}) =  \frac{\text{exp}(\mathbf{w}_y^T
    \mathbf{x}) }{\sum_{y'\in Y} \text{exp}(\mathbf{w}_{y'}^T
    \mathbf{x})}
\end{equation}
\paragraph{Codage des symboles par des vecteurs creux}
Pour utiliser un tel modèle
en \ac{tal}, il reste un problème à
traiter~: le modèle suppose naturellement des données $\mathbf{x}$ réelles alors
que les données langagières sont le plus souvent représentées par des
symboles discrets (à l'exception des données audio).

Supposons que $\mathbf{x}$ est un vecteur de symboles
discrets de dimension $k$ comme par exemple les familles du jeu de
cartes~: $\{\diamondsuit ,\spadesuit ,\heartsuit , \clubsuit \}$. La
manière classique de coder numériquement ce type de symboles consiste
à les coder sur des vecteurs à $|F|$ dimensions, tel que chaque
symbole value à 1 une dimension et à 0 les autres. Par exemple pour les
familles du jeu de cartes~:
\begin{eqnarray*}
\diamondsuit &=& [1,0,0,0]\\
\spadesuit &=& [0,1,0,0]\\
\heartsuit &=& [0,0,1,0]\\
\clubsuit &=& [0,0,0,1]
\end{eqnarray*}
On peut formaliser cette méthode de codage, appelée \kw{one hot
  coding}, à l'aide de \kw{fonctions features}. \`A chaque dimension $i$
du vecteur codé $\boldsymbol\Phi(x) = \phi_1(x),\phi_2(x),\phi_3(x),\phi_4(x)$ on fait correspondre une
fonction feature $\phi_i(x)$ à valuation booléenne, par
exemple si on a tiré une carte $x$, on pourra la coder à l'aide des
features suivantes~:
\begin{center}
\vspace{-0.75cm}\scalebox{0.7}{
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_1(x) = 
\left\{
\begin{array}{ll}
1&\text{si } x = \diamondsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_2(x) = 
\left\{
\begin{array}{ll}
1&\text{si } x = \spadesuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_3(x) = 
\left\{
\begin{array}{ll}
1&\text{si } x = \heartsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_4(x) = 
\left\{
\begin{array}{ll}
1&\text{si } x = \clubsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
}
\end{center}
Supposons maintenant qu'on ait tiré un vecteur $\mathbf{x} = x_1,x_2$
de deux cartes. On peut toujours utiliser un vecteur de features $\boldsymbol\Phi(\mathbf{x})$ pour coder la
séquence $\mathbf{x}$ de cartes tirées~:
\begin{center}
\vspace{-0.75cm}\scalebox{0.7}{
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_1(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \diamondsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\begin{displaymath}
\phi_5(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_2 = \diamondsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_2(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \spadesuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\begin{displaymath}
\phi_6(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_2 = \spadesuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_3(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \heartsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\begin{displaymath}
\phi_7(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_2 = \heartsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_4(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \clubsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\begin{displaymath}
\phi_8(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_2 = \clubsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
}
\end{center}
mais on peut aussi envisager coder les information qui portent sur les
\kw{interactions} entre variables. Si on veut indiquer explicitement qu'on a tiré
deux cartes de la famille pique, on pourra utiliser par exemple une
feature telle que~:
\begin{displaymath}
\phi_9(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \spadesuit \quad \&\quad  x_2 = \spadesuit\\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
de telle sorte que les vecteurs de features
$\boldsymbol\Phi(\mathbf{x})$ ont généralement une dimensionnalité
considérable en pratique. 
Notons que cette première méthode de codage permet d'utiliser le
modèle logistique multinomial avec des symboles discrets comme données.
En explicitant le codage, le modèle (\ref{eq-multinomial-logistic-numeric}) prend ainsi la forme suivante~:
\begin{equation}
\label{eq-multinomial-logistic-sparse1}
P(y|\mathbf{x};\mathbf{w}) =  \frac{\text{exp}(\mathbf{w}_y^T
    \boldsymbol\Phi(\mathbf{x})) }{\sum_{y'\in Y} \text{exp}(\mathbf{w}_{y'}^T
   \boldsymbol\Phi( \mathbf{x}))}
\end{equation}

Un tel modèle fait encore l'hypothèse implicite que les poids sont
organisés en matrice~: chaque ligne $\mathbf{w}_y$ de la matrice de
poids correspond aux poids destinés à scorer la classe $y\in Y$. 
Lorsque le nombre de classes est grand (voire infini) ou lorsqu'on ne
souhaite pas utiliser une matrice de poids, on peut généraliser la méthode
de codage par interactions en spécialisant les features à une classe
donnée, c'est-à-dire en spécifiant des features qui ont la forme générale suivante~:
\begin{displaymath}
\phi_i(\mathbf{x}, y) = 
\left\{
\begin{array}{ll}
1&\text{si } Y=y \quad\&\quad  x_k = \text{valeur}\quad (\&\, x_l = \text{valeur})*\\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
Cette représentation alternative --~qui est le plus souvent utilisée dans
ce cours~-- permet de représenter les poids comme un simple vecteur
$\mathbf{w}$. Le score d'une classe est obtenu par un produit scalaire 
$z_y = \mathbf{w}^T\boldsymbol\Phi(\mathbf{x},y)$ qui ne fait intervenir
que les features qui sont pertinentes pour scorer cette classe.
Lorsqu'on utilise ce codage, on notera que le modèle (\ref{eq-multinomial-logistic-sparse1}) 
prend alors la forme suivante~:
\begin{equation}
\label{eq-multinomial-logistic-sparse2}
P(y|\mathbf{x};\mathbf{w}) =  \frac{\text{exp}(\mathbf{w}^T
    \boldsymbol\Phi(\mathbf{x},y)) }{\sum_{y'\in Y} \text{exp}(\mathbf{w}^T
   \boldsymbol\Phi( \mathbf{x},y'))}
\end{equation}


\paragraph{Estimation des paramètres} L'entraînement d'un modèle de
régression logistique multinomiale est la procédure qui consiste à
estimer un vecteur $\mathbf{w}$ de poids à partir  de  données annotées.
Un jeu de données aura en général une allure du type~:
\begin{center}
\begin{tabular}{llll}\toprule
$y$ &$x_0$&$x_1$&$x_2$\\\midrule
Animé&la&	souris&	grise\\
Inanimé&	la&	souris&	apple\\
Inanimé&	une&	souris&	cassée\\
Animé&	une&	souris&	affamée\\
Groupe	&un&	troupeau&	errant\\\bottomrule
\end{tabular}
\end{center}
Cet exemple pourrait constituer le début d'un jeu de données destiné à
classer les occurrences de noms en classes d'animacité ($Y = \{\text{Animé,Inanimé,Groupe}\}$)
en fonction de leur contexte. 

Dans ce qui suit, on note le jeu de
données $\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$, et comme dans le cas de
la régression logistique, l'objectif est de trouver une valeur des
paramètres qui maximise l'objectif de maximum de vraisemblance~:
\begin{equation}
f(\mathbf{w}) =  \prod_{i=1}^N P(y_i|\mathbf{x}_i;\mathbf{w})
\end{equation}
La fonction de log-vraisemblance est en général celle qui est
maximisée car elle est strictement concave et la version logarithmique
facilite les calculs~:
\begin{align}
\nonumber
\hat{\mathbf{w}} &=\mathop{\text{argmax}}_{\mathbf{w} \in
  \mathbb{R}^d} \prod_{i=1}^N P(y_i|\mathbf{x}_i;\mathbf{w})\\
\nonumber
&= \mathop{\text{argmax}}_{\mathbf{w} \in \mathbb{R}^d} \sum_{i=1}^N
\log P(y_i|\mathbf{x}_i;\mathbf{w})\\
\nonumber
&= \mathop{\text{argmax}}_{\mathbf{w} \in \mathbb{R}^d} 
\sum_{i=1}^N \log \frac{\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y_i)) } 
{\sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y')) }\\
&=\mathop{\text{argmax}}_{\mathbf{w} \in \mathbb{R}^d} 
\sum_{i=1}^N \left[\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y_i)  
-\log\left(\sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y')) \right)\right]
\end{align}
On obtient les dérivées partielles de manière analogue au cas de la régression logistique~:
\begin{align}
\nonumber
\frac{\partial f(\mathbf{w})}{\partial w_j} &=\frac{\partial
  f}{\partial w_j} \sum_{i=1}^N \left[\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y_i)  
-\log\left(\sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y'))\right) \right] \\
\nonumber
&= \sum_{i=1}^N 
\left[  \phi_j(\mathbf{x}_i,y_i)  
- \frac{\partial
  f}{\partial w_j}\log\left(\sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y')) \right)\right] \\
\nonumber
&=\sum_{i=1}^N 
\left[  \phi_j(\mathbf{x}_i,y_i)  
-\frac{\frac{\partial f}{\partial w_j}\sum_{y'\in Y} 
  \text{exp}(\mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,y'))  }{\sum_{y'\in Y}\text{exp}(\mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,y')) }
\right]\\
\label{eq-triptrap}
&=\sum_{i=1}^N 
\left[  \phi_j(\mathbf{x}_i,y_i)  
-\frac{ \sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y')) \phi_j(\mathbf{x}_i,y')  }{\sum_{y'\in
    Y}\text{exp}(\mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,y')) } 
\right] \\
\label{eq-multinomial-derivative}
&=\sum_{i=1}^N 
( \phi_j(\mathbf{x}_i,y_i)  
- \sum_{y'\in Y} P(y' | \mathbf{x}_i;\mathbf{w})  \phi_j(\mathbf{x}_i,y'))
\end{align}
La dérivation qui précède applique essentiellement des règles de
dérivation classiques (log et exp). Par contre il faut voir que le facteur 
$\phi_j(\mathbf{x},y')$ qui apparaît en  (\ref{eq-triptrap})
n'est valué à 1 que pour le seul $y'$ où la feature est effectivement
valuée à 1. 
Intuitivement, la mise à jour consiste à donner un bonus à $\phi_j$
lorsqu'elle
contribue à prédire la bonne hypothèse et un malus lorsqu'elle
contribue à prédire une mauvaise hypothèse. 
Le bonus sera d'autant plus important que le modèle aura mal prédit la
bonne solution, et le malus est proportionnel à la
probabilité que le modèle donne à  cette mauvais hypothèse.

Autrement dit, la montée de gradient consiste à compter le nombre
d'occurrences de la feature observées dans les données (premier terme)
et à lui soustraire un pseudo-compte d'occurrences de la feature tel
que prédit par le modèle (second terme).
Le gradient sera nul lorsque ces deux nombres seront égaux pour toutes
les features (et la procédure d'estimation aura convergé). 

Pour le calcul de l'ensemble du gradient, on peut ainsi formuler une contrepartie de la fonction $\ell(y_i,\mathbf{x}_i;\mathbf{w})$,
donnée en équation \ref{eq-sgd-gradient}, pour le cas multinomial~:
\begin{displaymath}
\ell(y_i,\mathbf{x}_i,\mathbf{w}) = \boldsymbol\Phi(\mathbf{x}_{i},y)
-  \sum_{y'\in Y} P(y'|\mathbf{x}_i;\mathbf{w}) \boldsymbol\Phi(\mathbf{x}_i,y')
\end{displaymath}
On peut ainsi réutiliser des algorithmes de montée de gradient
standard ou stochastiques pour réaliser l'entrainement. On donne un
exemple d'algorithme de montée de gradient en batch en Algorithme 
\ref{algo-batch-multi-logistic}.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{MultinomialLogisticGradientAscent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
    \State $\mathbf{w} \gets \mathbf{w} + 
\alpha\, \left(\sum_{i=1}^N\boldsymbol\Phi(\mathbf{x}_i,y_i) -  \sum_{y'\in Y} P(y'|\mathbf{x}_i;\mathbf{w}) \boldsymbol\Phi(\mathbf{x}_i,y')\right)$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-batch-multi-logistic}Algorithme de
  montée de gradient pour la régression logistique multinomiale}
\end{algorithm}

\begin{exo}[Régularisation]
On utilise parfois une version régularisée du modèle logistique
multinomial. La fonction objective de ce modèle s'exprime comme suit~:
\begin{equation}
\label{eq-multi-logistic-L2}
f(\mathbf{w}) =  \frac{\lambda}{2}||\mathbf{w}||_2^2+ \sum_{i=1}^N
\log P(y_i|\mathbf{x}_i;\mathbf{w})
\end{equation}
où $\lambda \in \mathbb{R}^+$ est un paramètre fixé par l'utilisateur.  
Donner une explication intuitive de l'intérêt que peut avoir le terme
de régularisation. 
Donner le gradient de la version régularisée du modèle logistique (pas
besoin de refaire tous les calculs). Quel effet a $\lambda$ ? 
\end{exo}
\begin{exo}[\ac{sgd}]
Donner une reformulation de l'algorithme
\ref{algo-batch-multi-logistic} qui utilise \ac{sgd}
\end{exo}
\begin{exo}[\ac{sgd}]
Donner une reformulation de l'algorithme
\ref{algo-batch-multi-logistic} pour la fonction
objective régularisée (\ref{eq-multi-logistic-L2}) et en utilisant \ac{sgd}.
\end{exo}

\section{Large marge multiclasse}

Si les modèles logistiques cherchent à maximiser la probabilité que le
modèle donne aux données, les modèles à large marge cherchent à
produire un modèle qui non seulement minimise les erreurs sur les
données d'entrainement mais également essaye de donner une marge de
confiance aux décisions qu'il va prendre. Deux modèles très connus
font partie de cette famille~: l'algorithme du perceptron et le modèle
des machines à vecteurs support linéaires (\ac{svm}).

Les modèles à large marge, présentés ici, sont des modèles linéaires, chaque classe
$y\in Y$ est associée à un vecteur de poids qui lui correspond et le
score d'une classe est déterminé par un produit scalaire~:
\begin{equation}
\text{score}(y,\mathbf{x};\mathbf{w}) =  \mathbf{w}_y^T \,
    \boldsymbol\Phi(\mathbf{x})
\end{equation}
On peut utiliser les modèles à large marge avec le même système de
codage que les modèles logistiques. On utilisera ici la version du modèle avec le 
codage en $\phi(\mathbf{x},y)$, c'est-à-dire~:
\begin{equation}
\text{score}(y,\mathbf{x};\mathbf{w}) =  \mathbf{w}^T \,
    \boldsymbol\Phi(\mathbf{x},y)
\end{equation}
Contrairement aux modèles logistiques, les modèles à large marge
produisent des scores qui couvrent toute l'intervalle réelle. La
procédure de décision sous-jacente consiste à choisir la classe de
score maximal. Donc plus un score est élevé, plus la classe a de
chances d'être choisie par la procédure de décision.

On voit donc que les modèles à large marge ont un fonctionnement
général qui est très similaire aux modèles logistiques. La différence
principale provient du fait que les prédictions ne s'interprètent pas
comme des probabilités.



\paragraph{Estimation des paramètres} L'originalité des modèles à
large marge tient dans le procédé d'apprentissage des poids. Les
données utilisées ont la même allure que les données utilisées par les
modèles logistiques. Ainsi on note un jeu de données $D = \mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$.

La fonction objective d'un modèle à large marge multiclasse est la suivante~:
\begin{equation}
\label{eq-largemargin-objective}
f(\mathbf{w}) = \frac{1}{N}\sum_{i=1}^N \text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))
\end{equation}
où $y^* = 
\mathop{\text{argmax}}_{y'\in Y\backslash\{y\}} \mathbf{w}^T \,
    \boldsymbol\Phi(\mathbf{x},y')$ représente l'hypothèse incorrecte
    qui a le meilleur le score (le plus sérieux concurrent de
    l'hypothèse correcte).  La fonction $\text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))$
est appelée \kw{hinge loss multiclasse}, on peut remarquer que plus
le score du plus sérieux concurrent est élevé plus la valeur de la
fonction de coût augmente.
Par conséquent, l'objectif d'un modèle à large marge est de minimiser la fonction
objective (on utilisera cette fois l'algorithme de descente de gradient).
Pour le dire encore autrement,  il faut voir que pour un exemple donné, le
coût augmente lorsque~:
\begin{displaymath}
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i)  -
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) \leq 1
\end{displaymath}
c'est-à-dire tant que le score de la prédiction de référence n'est pas supérieur à
la somme score du meilleur concurrent avec une marge de 1. La marge a
en général la valeur conventionnelle 1.  Certains modèles utilisent
une marge nulle, comme typiquement  l'algorithme du perceptron.

\paragraph{Notion de sous-gradient d'une fonction convexe}La procédure d'estimation des paramètres consiste à minimiser
(\ref{eq-largemargin-objective}).  Bien que convexe, cette fonction n'est pas
différentiable sur l'intégralité de son domaine car elle fait intervenir
un maximum. On illustre cet aspect en figure \ref{fig-maxfun} où la
fonction $f(x) = \text{max}(0,1-x)$ n'est pas différenciable en
$x_0=1$~: visuellement on peut constater qu'un nombre infini de droites
sont tangentes à la fonction en $x_0=1$.

On appelle \kw{sous-dérivée} d'une fonction convexe $f(x)$ en $x_0$
tout nombre réel $s\in\mathbb{R}$ tel que~:
\begin{displaymath}
f(x) \geq f(x_0) + s(x-x_0)
\end{displaymath}
intuitivement $s$ est l'ensemble des coefficients de pente des droites
qui passent en $(x_0,f(x_0))$ et qui sont situées sous la fonction
$f(x)$. Sur l'exemple en figure \ref{fig-maxfun}, $s\in [-1,0]$.
L'ensemble $S$ de toutes les sous-dérivées de $f(x)$ en $x_0$ est appelé
\kw{sous-différentiel} de $f$ en $x_0$.  Le calcul des bornes de $S$ est donné dans le cas de la fonction max
par les dérivées des fonctions linéaires $f(x) = 0$ et $f(x) =
1-x$. 
\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}
\foreach \x in {-4,-3,-2,-1,0,1,2,3,4}
    {        
      \coordinate (A\x) at ($(0,0)+(\x*0.5cm,0)$) {};
      \draw [gray!75]($(A\x)+(0,5pt)$) -- ($(A\x)-(0,5pt)$);
      \node[gray!75] at ($(A\x)+(0,-3ex)$) {\x};
    }
    \draw[->,gray!75] (-5,0) -- (5,0) node[right] {$x$};
    \draw[->,gray!75] (0,-1.5) -- (0,4) node[above] {$f(x)$};
    \draw[scale=0.5,domain=-4:4,smooth,thick,variable=\x,blue] plot({\x},{-(\x-1)});
    \draw[scale=0.5,domain=-5:5,smooth,thick,variable=\x,red] plot({\x},{0});
    \draw[scale=0.5,domain=-5:5,samples=400,dashed,variable=\x,ultra thick,black] plot({\x},{max(0,-(\x-1))});
%\addlegendentry{$f_1(x) = 1-x$}
%\addlegendentry{$f_2(x) = 0$}
%\addlegendentry{$f_3(x) = max(0,1-x)$}
\end{tikzpicture}
\end{center}
\caption{\label{fig-maxfun}Maximum de deux fonctions $f(x) = \text{max}(0,1-x)$}
\end{figure}

De manière générale la dérivée d'une fonction $f(x) = \text{max}(f_1(x),f_2(x))$
s'obtient en divisant le domaine en deux sous-intervalles réparties autour du point de non
différentiabilité ($x_0=1$ sur l'exemple). On utilisera la dérivée
correspondant à l'intervalle dans lequel on se trouve.
On peut déterminer facilement cet intervalle en comparant $f_1$ et $f_2$ de telle
sorte que~:
\begin{displaymath}
\frac{\partial f}{\partial x}\text{max}(f_1(x),f_2(x)) = \left\{
\begin{array}{ll}
\frac{\partial f_1}{\partial x}(x) & \text{si } f_1(x) > f_2(x)\\\\
\frac{\partial f_2}{\partial x}(x) & \text{si } f_2(x) > f_1(x)
\end{array}\right.
\end{displaymath}
Lors de la descente de sous-gradient, au point non différentiable, on
peut choisir tout $s\in S$ comme valeur de la dérivée. En pratique on
prendra arbitrairement la dérivée de $f_1$ ou de $f_2$. 

Ce qui précède se généralise aux cas des fonctions de plusieurs variables.
En ce qui concerne la fonction objective des
modèles à large marge (\ref{eq-largemargin-objective}), on obtient les
dérivées partielles suivantes~:
\begin{eqnarray}
\hat{\mathbf{w}}&=&\mathop{\text{argmin}}_{\mathbf{w} \in \mathbb{R}^d}\sum_{i=1}^N
\text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))\\
\nonumber
\frac{\partial f}{\partial w_j} &=&\sum_{i=1}^N
\frac{\partial}{\partial w_j} \text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) -
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))\\
\nonumber
&=&\sum_{i=1}^N
\left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_i,y*) - \phi_j(\mathbf{x}_i,y_i) & \text{si }  1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) -
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i)  \geq 0\\
0&\text{sinon}
\end{array}\right.\\
%\nonumber
&=&\sum_{i=1}^N
\left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_i,y*) - \phi_j(\mathbf{x}_i,y_i) & \text{si }  
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i)   - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) \leq 1\\
0&\text{sinon}
\end{array}\right.
\end{eqnarray}
Au final, on peut formuler une fonction $\ell$ qui représente 
la contribution de chaque exemple dans les données au gradient~:
\begin{displaymath}
\ell(y_i,\mathbf{x}_i,\mathbf{w}) = 
\left\{
\begin{array}{ll}
 \boldsymbol\Phi(\mathbf{x}_i,{y}^*_i)-
\boldsymbol\Phi(\mathbf{x}_{i},y_i)&\text{si }
[ \text{score}(y_i) - \text{score}(y^*_i)  ]\leq 1\\
 \mathbf{0}& \text{sinon}
\end{array}\right.
\end{displaymath}
L'algorithme de descente de gradient s'instancie de manière
habituelle,
ce qui donne la version présentée en algorithme \ref{algo-grad-LM}.
On peut noter qu'on a procédé à une légère réorganisation des signes, ce
qui facilite notamment la comparaison avec les algorithmes
d'optimisation pour le cas logistique.
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{BatchLargeMarge}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State
\scalebox{0.8}{$\mathbf{w} \gets \mathbf{w} + \alpha \left(  
\frac{1}{N}\sum_{i=1}^N
\left\{
\begin{array}{ll}
\boldsymbol\Phi(\mathbf{x}_{i},y_i) - \boldsymbol\Phi(\mathbf{x}_i,{y}^*_i)
&\text{si }
[ \text{score}(y_i) - \text{score}(y^*_i)  ]\leq 1\\
 \mathbf{0}& \text{sinon}
\end{array}\right. \right)$}
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-grad-LM}Descente de gradient pour modèle à large marge linéaire}
\end{algorithm}
On peut remarquer que l'algorithme d'optimisation met à jour les poids
uniquement lorsque la classe correcte n'est pas prédite avec une marge
supérieure à 1 sur sa plus sérieuse concurrente.
Dans ce cas l'algorithme donne un bonus au poids associés aux features
de la référence et un malus aux poids associés aux features de la
prédiction concurrente.

L'algorithme de descente de gradient à large marge peut être utilisé
tel quel, mais on va maintenant montrer que deux algorithmes très connus peuvent être
vus comme des cas particuliers de la famille des modèles à large
marge~: l'algorithme du perceptron et les \ac{svm} linéaires.


\subsection{Algorithme du perceptron}

L'algorithme du \kw{perceptron} est un algorithme très populaire en \ac{tal}
car il est particulièrement simple à implémenter. On peut le voir
comme un cas particulier des modèles à large marge dont la procédure
d'optimisation est \ac{sgd}. Ainsi en posant que la marge est nulle, l'objectif à
large marge devient~:
\begin{equation}
f(\mathbf{w}) = \frac{1}{N}\sum_{i=1}^N \text{max}(0,
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))
\end{equation}
et le sous-gradient devient~:
\begin{equation}
\label{eq-perceptron-grad}
\frac{\partial f(\mathbf{w})}{\partial w_j} =  
\sum_{i=1}^N \left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_{i},y^*_i) -\phi_j(\mathbf{x}_{i},y_i) &\text{si }
[ \text{score}(y_i) - \text{score}(y^*_i)  ]\leq 0\\
0&\text{sinon}
\end{array}\right.
\end{equation}
Si l'algorithme utilisé pour réaliser la descente de gradient est \ac{sgd}
structuré en itérations sur les données (Algorithme \ref{algo-gradient-sgd-epoch}),
on peut observer que ce cas d'utilisation correspond exactement
à l'algorithme du \kw{perceptron multiclasse} traditionnel que l'on
reproduit en algorithme \ref{algo-perceptron-sgd}.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Perceptron}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State\Call{Shuffle}{$\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$}
\For{$1\leq i\leq N$}
    \State $\hat{y} \gets \mathop{\text{argmax}}_{{y\in Y}}
    \mathbf{w}^T \, \boldsymbol\Phi(\mathbf{x}_i,y)$
    \If{$\hat{y} \not = y_i$}
       \State $\mathbf{w} \gets \mathbf{w} + \alpha\, (\phi_j(\mathbf{x}_{i},y_i)-\phi_j(\mathbf{x}_{i},\hat{y})) $
    \EndIf
\EndFor
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-sgd}Algorithme du perceptron}
\end{algorithm}
\begin{exo}[Vérification]
Pour vous convaincre que l'algorithme \ref{algo-perceptron-sgd} est
bien une variante notationnelle d'un modèle à large marge. Ecrivez
l'algorithme de descente de gradient stochastique qui utilise
directement (\ref{eq-perceptron-grad}) et procédez à la comparaison.
\end{exo}

Notons finalement que l'algorithme du perceptron est très utilisé dans
sa version moyennée ce qui permet de lui donner une certaine stabilité
et de réduire les effets de surentrainement (Algorithme \ref{algo-perceptron-asgd})
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{AveragedPerceptron}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\State $\bar{\mathbf{w}} \gets \mathbf{0}$
\State $e\gets 0$
\While{non convergence}
\State\Call{Shuffle}{$\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$}
\For{$1\leq i\leq N$}
    \State $\hat{y} \gets \mathop{\text{argmax}}_{{y\in Y}}
    \mathbf{w}^T \, \boldsymbol\Phi(\mathbf{x}_i,y)$
    \If{$\hat{y} \not = y_i$}
       \State $\mathbf{w} \gets \mathbf{w} + \alpha\, (\phi_j(\mathbf{x}_{i},y_i)-\phi_j(\mathbf{x}_{i},\hat{y})) $
    \EndIf
       \State $\bar{\mathbf{w}} \gets  \bar{\mathbf{w}}+ \mathbf{w} $
\EndFor
\State $e \gets e + 1$
\EndWhile
\State\Return $\bar{\mathbf{w}}/(N\times e)$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-asgd}Algorithme du perceptron moyenné}
\end{algorithm}


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{BatchSVM}{$\alpha,\lambda, \mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State
\scalebox{0.8}{$\mathbf{w} \gets \mathbf{w} + \alpha \left( 
\frac{1}{N}\sum_{i=1}^N
\left\{
\begin{array}{ll}
\boldsymbol\Phi(\mathbf{x}_{i},y_i) - \boldsymbol\Phi(\mathbf{x}_i,{y}^*_i)
&\text{si }
[ \text{score}(y_i) - \text{score}(y^*_i)  ]\leq 1\\
 \mathbf{0}& \text{sinon}
\end{array}\right. - \lambda
  \mathbf{w} \right)$}
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-linear-svm}Descente de gradient de \ac{svm}
  linéaire (batch)}
\end{algorithm}





\subsection{\ac{Svm} linéaire multiclasse}
Si maintenant on ajoute un terme de régularisation à l'objectif (\ref{eq-largemargin-objective}), celui-ci prend la forme suivante~:
\begin{equation}
f(\mathbf{w}) = \frac{\lambda}{2}||\mathbf{w}||_2^2 +
\frac{1}{N}\sum_{i=1}^N \text{max}(0, 1 + 
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))
\end{equation}
Cet objectif correspond à celui d'une \kw{machine à vecteurs de support}
(\ac{svm}) linéaire. On peut indiquer que les modèles à large marge
ont pour origine les travaux sur \ac{svm}, même si ceux-ci ont été
initialement formulés de manière très différente (en apparence). 

On peut optimiser cet objectif avec les
algorithmes de descente de gradient et de descente de gradient
stochastique moyennée présentés dans ce chapitre. Ainsi le problème
d'optimisation consiste à minimiser~:
\begin{equation}
\hat{\mathbf{w}}=\mathop{\text{argmin}}_{\mathbf{w} \in \mathbb{R}^d}
\frac{\lambda}{2}||\mathbf{w}||_2^2+\sum_{i=1}^N
\text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))
\end{equation}
dont on obtient les dérivées partielles suivantes en procédant à un
développement analogue aux précédents~:
\begin{equation}
\frac{\partial f}{\partial w_j} = \lambda w_j+\sum_{i=1}^N
\left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_i,y*) - \phi_j(\mathbf{x}_i,y_i) & \text{si }  
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i)   - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) \leq 1\\
0&\text{sinon}
\end{array}\right.
\end{equation}
Contrairement au perceptron, la résolution du problème d'optimisation
de \ac{svm} en forme primale est
habituellement présenté comme un  algorithme de descente de gradient en batch
(Algorithme \ref{algo-linear-svm}). Mais rappelons que \ac{svm} est
habituellement présenté à partir de sa forme duale.  Celle-ci est
toutefois inadaptée
aux problèmes de \ac{tal}. 


\section{Réseaux de neurones}
    word vectors
    SGD


\chapter{Perceptron structuré}

Le modèle du perceptron structuré est initialement dû à \cite{collins-2002}.

\section{Généralisation du modèle du perceptron}

Le perceptron structuré est un modèle qui généralise le modèle du
perceptron au cas des données structurées. 
Dans ce chapitre, on donne une présentation pour la modélisation de
séquences. On généralisera ce cas à la prédiction d'arbres dans les
chapitres suivants.

Un perceptron multiclasse est un modèle statistique qui prédit le
score $\psi(y)$ d'une donnée $y\in Y$ de manière linéaire~:
\begin{equation}
\psi(y) = \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y)
\end{equation}
Comme $\mathbf{w} \in \mathbb{R}^d$ et $\boldsymbol\Phi(\mathbf{x},y)
\in \{0,1\}^d$, on a que $\psi(y) \in \mathbb{R}$. 
Ce modèle est habituellement utilisé dans un contexte de prise de
décision, il s'agit de sélectionner parmi un ensemble $Y$ d'hypothèses, 
l'hypothèse $y\in Y$ de score maximal~:
\begin{equation}
\hat{y} =   \mathop{\text{argmax}}_{y\in Y} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y)
\end{equation}

Dans le cas où $Y$ est un ensemble de structures, comme un ensemble de
séquences, la taille de cet ensemble croît exponentiellement en
fonction de la longueur de la phrase. 
L'idée d'un modèle de perceptron structuré est de permettre la
décomposition du calcul du score des séquences de telle sorte qu'il
soit possible de partager des sous-calculs entre des sous-séquences communes.
Ainsi une séquence de tags $\mathbf{y} = y_1,y_2\ldots y_m\ldots $
sera évaluée par la fonction de score suivante~:
\begin{equation}
\Psi(\mathbf{y}) = \sum_{i=1}^m \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)
\end{equation}
Autrement dit, le score d'une séquence est la somme des scores
attribués à tous les couples de tags qui la composent. Lorsqu'il
s'agit de donner un score à un ensemble de séquences, il est ainsi
possible de représenter le problème dans un \ac{dag} de programmation
dynamique et de réutiliser l'algorithmique décrite dans les chapitres précédents.


\section{Recherche de la meilleure analyse}

\subsection{Fonctions features}


\begin{exo}[Algorithme de Dijkstra ?]
Est-il possible d'adapter l'algorithme de Dijkstra pour prédire la
meilleure séquence de tags avec un modèle de perceptron structuré ?
si oui comment ? si non, justifiez.
\end{exo}

\section{Estimation des paramètres}

On suppose qu’un corpus annoté $C = \mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$ est un
exemplaire de $N$ phrases. 
Chaque exemple annoté est un couple $(x_i , y_i )$ qui représente une
séquence de mots $x = x_1 \ldots x_m$ et une séquence de tags de
référence $y = y_1 \ldots y_m$ de même longueur.

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{train-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{\mathbf{y}} \gets \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,\mathbf{y})$
\Comment{Tagging}
\label{algoline-pseudoargmax}
\If{$\hat{\mathbf{y}} \not = \mathbf{y}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[\boldsymbol\Phi(\mathbf{x}_i,\mathbf{y}_i) 
       - \boldsymbol\Phi(\mathbf{x}_i,\hat{\mathbf{y}})  \right]$ 
     \label{algoline-update}
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-train}Estimation des paramètres d'un
  perceptron}
\end{algorithm}


\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{train-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \mathbf{0}$
\State $\bar{\mathbf{w}} \gets \mathbf{0}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State $\hat{\mathbf{y}} \gets \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,\mathbf{y})$
\Comment{Tagging}
\If{$\hat{\mathbf{y}} \not = \mathbf{y}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[\boldsymbol\Phi(\mathbf{x}_i,\mathbf{y}_i) 
       - \boldsymbol\Phi(\mathbf{x}_i,\hat{\mathbf{y}})  \right]$ 
\EndIf
\State $\bar{\mathbf{w}} \gets \bar{\mathbf{w}}+\mathbf{w}$
\EndFor
\EndFor
\State \Return $\bar{\mathbf{w}}/N$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-train-avg}Estimation des paramètres d'un
  perceptron moyenné}
\end{algorithm}

SGD + ASGD
ASGD

\section{Estimation des paramètres et approximations}

TODO: cette section, introduire la décomposition du score partout, y
compris dans le pseudo code.

Pour certains types de problèmes ou de représentations, il n'est pas
possible d'évaluer un \ac{dag} de programmation dynamique exhaustivement.
En pratique, les temps de calcul deviennent prohibitifs.
Pour cette raison, on peut souhaiter utiliser une méthode de recherche
approximative en faisceau, y compris lors de l'apprentissage.

Dans le contexte d'un problème d'estimation des paramètres,
l'utilisation d'un faisceau pose un problème au niveau de la procédure
de prédiction (Algorithme  \ref{algo-perceptron-train}, ligne \ref{algoline-pseudoargmax})
Le problème posé par ce type de méthode est que les méthodes en
faisceau renvoient un {\sl pseudo-argmax} qui a pour origine
l'inexactitude de l'algorithme de recherche de solutions.
Cela signifie que $\hat{\mathbf{y}}$ est potentiellement sous-optimal,
ce qui fausse la mise à jour (ligne \ref{algoline-update}) et peut
causer la divergence de la procédure d'estimation.

\paragraph{Mise à jour d'un modèle à large marge}
Pour comprendre le problème, on commence par reformuler la procédure 
de mise à jour dans le cas exact (sans utiliser un faisceau). Notons  $\mathbf{y}^*$ la séquence
incorrecte à laquelle le modèle attribue le meilleur score, c'est-à-dire~:
\begin{displaymath}
\mathbf{y}^* = \mathop{\text{argmax}}_{\mathbf{y} \in
  \mathbf{Y}\backslash \{\mathbf{y}\}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},\mathbf{y})
\end{displaymath}
Il y a nécessairement mise à jour lorsque le score de la meilleure séquence
incorrecte est supérieur au score de la séquence correcte~: $\Psi(\mathbf{y}^*) \geq \Psi(\mathbf{y})$.
Lorsque $\Psi(\mathbf{y}^*) <\Psi(\mathbf{y})$ il n'y a pas de mise à
jour. Cette reformulation se jsutifie par le fait que le perceptron
peut être vu comme un cas particulier de modèle à large marge
(Chapitre XXX). 

\paragraph{Généralisation aux méthodes en faisceau}
Dans un contexte où on utilise un faisceau ($\mathbf{Y}' \subsetneqq \mathbf{Y}$), la meilleure prédiction dans le
beam $\tilde{\mathbf{y}} = \text{argmax}_{\mathbf{y} \in \mathbf{Y'}}
\mathbf{w}^T \boldsymbol\Phi(\mathbf{x},\mathbf{y})$ ne correspond pas nécessairement à
la meilleure séquence optimale $\hat{\mathbf{y}} = \text{argmax}_{\mathbf{y} \in \mathbf{Y}}
\mathbf{w}^T \boldsymbol\Phi(\mathbf{x},\mathbf{y})$ qui a pu être écartée du faisceau prématurément.  
Le cas suivant devient désormais possible~:
\begin{displaymath}
\Psi(\tilde{\mathbf{y}}) < \Psi(\mathbf{y}) \text{ alors que } \hat{\mathbf{y}} = \mathbf{y}
\end{displaymath}
Une telle configuration entraine la mise à jour des paramètres du perceptron. Dans
ce cas on parle de mise à jour invalide. Il a été démontré
\cite{huang-2012} qu'une mise à jour valide respecte nécessairement la
condition suivante~: 
\begin{displaymath}
\Psi(\tilde{\mathbf{y}}_{1\ldots k}^*) > \Psi(\mathbf{y}_{1\ldots k})
\end{displaymath}
où $\tilde{\mathbf{y}}_{1\ldots k}^*$ dénote la sous séquence préfixe
de tags incorrecte de meilleur score dans le beam et  $\mathbf{y}_{1\ldots k}$
dénote une sous séquence préfixe de tags de référence.
Si cette condition est respectée, la convergence de la procédure d'estimation des paramètres
est garantie. On peut remarquer que cette condition revient à
généraliser le déclenchement de la mise à jour pour les modèles à
large marge au cas des sous-séquences.

Dans la pratique, il est courant depuis \cite{collins-2004} 
de réaliser la mise à jour dès que la séquence de référence sort du
beam pendant l'étape de parsing.
C'est ce qu'on appelle la mise à jour rapide (\kw{early update}).
D'autres méthodes sont possibles. Par exemple, en définissant la marge d'erreur
$\Delta_k =  \Psi(\tilde{\mathbf{y}}_{1\ldots k}^*) -
\Psi(\mathbf{y}_{1\ldots k})$, et en sélectionnant l'indice $k =
\text{argmax}_{1\leq k \leq m} \Delta_k$ on obtient la mise à jour
dite à \kw{violation maximale}. 

{\bf Dire que c'est utilisé par les systèmes de transitions qui
  utilisent un historique très riche}



\chapter{Champs conditionnels aléatoires}

\section{Généralisation des modèles logistiques}

Les modèles de champs conditionnels aléatoires \ac{crf}
sont des modèle qui généralisent les modèles de régression logistique multinomiale au cas des données structurées.
Dans ce cours, on  donne une présentation pour la modélisation de séquences, ce qui est le cas d'usage le plus courant.

On se rappelle qu'un modèle de régression logistique multinomiale prédit une donnée $y$ à partir de variables observées $\mathbf{x}$ de la manière suivante~:
\begin{equation}
\label{eq-logistic-base}
P(Y = y \,|\, \mathbf{x},\mathbf{w}) = \frac{\text{exp}(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y))}{\sum_{y'\in Y}\text{exp}(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y'))}
\end{equation}
Le numérateur représente un score $\psi(y) \geq 0$~: la fonction exponentielle transforme toute valeur réelle en  réel positif. 

Comme chaque classe $y\in Y$ reçoit un score $\psi(y)$,
le dénominateur ne dit rien d'autre qu'un score se transforme en probabilité en le divisant par la somme totale des scores pour toutes les classes. Le dénominateur est parfois appelé constante de normalisation.

Un \ac{crf} linéaire n'est rien d'autre qu'un modèle de régression logistique multinomiale dont la variable $Y$ à prédire est un ensemble de séquences. Dans ce contexte, la difficulté est que le nombre de séquences possibles de tags (ou plus généralement de symboles) croit exponentiellement en fonction de la longueur de la séquence à prédire.
Ainsi il devient rapidement très difficile de réutiliser naïvement le modèle de régression logistique multinomiale (équation \ref{eq-logistic-base}), car le calcul de la constante de normalisation devient très vite ingérable.

Toute l'idée de \ac{crf} c'est de permettre la décomposition du calcul du score d'une séquence de telle sorte que l'on puisse réutiliser les méthodes de programmation dynamique notamment introduites dans les cours précédents pour réaliser les calculs dans des temps raisonnables (complexité polynomiale).  Ainsi une séquence de tags $\mathbf{y} = y_1 \ldots y_m$ sera prédite par un \ac{crf} à l'aide de la formule suivante~:
\begin{equation}
\label{eq-crf-predict}
P(\mathbf{Y} = \mathbf{y} \,|\, \mathbf{x},\mathbf{w}) = \frac{\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)}
{\sum_{\mathbf{y}'\in \mathbf{Y}}
\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y^{'}_{i-1},y^{'}_i)\right)}
\end{equation}
On voit que dans cette formulation le score global d'une séquence se décompose en une somme de scores locaux.  Il ne s'agit de rien d'autre que d'imposer une décomposition du calcul d'un produit scalaire destiné à évaluer une séquence (un produit scalaire est une grosse addition de toute façon).

<DESSIN QUI ILLUSTRE QU'UNE SEQUENCE EST UNE SOMME DE SCORES>

On va évidemment tirer parti de cette propriété pour exprimer des algorithmes qui partagent des sous parties de calculs efficacement\ldots  On traite en priorité l'algorithmique des deux problèmes d'inférence suivants~:
\begin{itemize}
\item Prédire la séquence de tags la plus probable $\hat{\mathbf{y}}$ pour une séquence de mots $\mathbf{x}$, c'est-à-dire résoudre le problème suivant~:
\begin{equation}
\label{eq-crf-argmax}
\hat{\mathbf{y}} =  \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}}
\, P(\mathbf{Y}=\mathbf{y} | \mathbf{x},\mathbf{w})
\end{equation}
\item Estimation par maximum de vraisemblance conditionnelle des paramètres d'un modèle dans un contexte d'apprentissage supervisé.
La résolution de ce problème nous fera résoudre par effet de bord le sous-problème de calcul de la probabilité d'une assignation de tags $P(\mathbf{Y}=\mathbf{y} | \mathbf{x},\mathbf{w})$.
\end{itemize}

\begin{exo}[fonction exponentielle]
Faire un graphique avec la librairie graphique de votre choix de la fonction $x\mapsto e^x $ sur l'intervalle réelle $]-\infty,+\infty[$
\end{exo}

\section{Recherche de la séquence de tags la plus probable}

\paragraph{La solution du paresseux}
La solution la plus efficace (et à utiliser en pratique) au problème (\ref{eq-crf-argmax}) est celle du paresseux.  Il suffit de remarquer que les fonctions exponentielles utilisées en (\ref{eq-crf-predict})  n'ont pas d'autre fonction que de normaliser les scores de produits scalaires pour obtenir des probabilités et que la normalisation
ne change pas la valeur du maximum. Par conséquent, chercher la solution de~:
\begin{equation}
\hat{\mathbf{y}} =  \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}}
\, \sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)
\end{equation}
à la place de (\ref{eq-crf-argmax}) résoud le problème. La solution du paresseux revient donc à réutiliser la méthode de résolution déjà présentée pour le modèle du perceptron global (algorithme de Viterbi). 

\paragraph{La solution par décomposition explicite du score}
Le détail de l'autre solution présentée ici (à ne pas utiliser en pratique) permet de mieux comprendre comment le score d'un \ac{crf} se décompose.
L'idée est de reformuler le score non normalisé d'une séquence par un produit comme suit~: 
\begin{displaymath}
\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)
\end{displaymath}
devient~:
\begin{displaymath}
\prod_{i=1}^m \text{exp}\left(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)
\end{displaymath}
On peut donc remarquer qu'on peut reformuler le score d'une séquence par un produit de réels strictement positifs appelés potentiels (et notés $\psi(\mathbf{x},y_{i-1},y_i)$). La conséquence est que l'algorithme de Viterbi pour \ac{crf} a exactement la même forme que pour \ac{hmm}~:
les scores de séquences sont des produits de potentiels et les séquences sont comparées par la fonction maximum. Plus généralement, la reformulation de (\ref{eq-crf-predict}) par 
\begin{equation}
P(\mathbf{Y} = \mathbf{y} \,|\, \mathbf{x},\mathbf{w}) = \frac{\prod_{i=1}^m\text{exp}\left( \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)}
{\sum_{\mathbf{y}'\in \mathbf{Y}}
\prod_{i=1}^m \text{exp}\left(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y^{'}_{i-1},y^{'}_i)\right)}
\end{equation}
permet de tirer parti de toute l'algorithmique de programmation dynamique déjà développée pour \ac{hmm}.

\section{\`A la découverte des \ac{dag}s de programmation dynamique}

On se propose dans cette section d'étudier par l'exemple quelques propriétés des \ac{dags}
de programmation dynamique qui seront déterminantes pour résoudre le problème d'estimation des paramètres d'un \ac{crf}. 
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (3,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](4) -- (E) node[midway,fill=white]{3};
\end{tikzpicture}
\end{center}
Le \ac{dag} ci-dessus va nous servir d'exemple de départ. Il encode un problème qui correspond à  probabiliser toutes les séquences possibles de 2 tags, pris dans le jeu de tags $Y=\{A,B\}$, pour une séquence de deux mots. On ajoute un état source unique $S$ et un état de but à atteindre $E$. La pondération des arcs correspond à des valeurs possibles pour des potentiels $\psi(\mathbf{x},y_{i-1},y_{i})$ strictement positifs.
 
En termes de notations, on notera $s_i$ un noeud du \ac{dag} où $s\in Y$ est un tag et $i$ sa position. Chaque chemin $\pi = s_1,s_2\ldots s_{k-1},s_k$ dans le \ac{dag} a un score noté $\sigma(\pi)$.  

%\item On a $\sigma(\pi)$, score d'un chemin.
%\item On a $\alpha(s_i)$, somme des scores de tous les chemins qui mènent à $s_i$ depuis l'origine.
%\item On a $\beta(s_i)$, somme des scores de tous les chemins qui mènent à $s_i$ depuis le but.
%\item $\psi(s_i,s_{i+1})$, score d'un arc


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\delta(s) \gets 1$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\delta(s) \gets 0$
\ForAll {$(s',s) \in AE(s)$}
\State  $\delta(s) \gets \Call{Max}{\delta(s) , \delta(s')  \times \psi(\mathbf{x},s',s) $}
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-crf}Algorithme de Viterbi pour \ac{crf}}
\end{algorithm}
 
\begin{exo}[Viterbi]
Simuler l'exécution de l'algorithme de Viterbi (Algorithme \ref{algo-viterbi-crf}) sur l'exemple illustratif. Quel est le poids du meilleur chemin ? Quel est ce chemin ? 
\end{exo}

\begin{exo}[Viterbi]
Dans la section précédente, on suggère une "solution du paresseux" pour trouver le meilleur chemin dans un \ac{crf}.  L'algorithme \ref{algo-viterbi-crf} est-il directement utilisable dans ce contexte ? Si la réponse est négative, quelles modifications faudrait-il lui apporter ?
\end{exo}




\subsubsection{Algorithme avant} Quelle est la somme des scores qui mènent à un état $s_i$ depuis la source ? C'est la question à laquelle répond l'algorithme avant.
Notons $\alpha(s_i)$ la quantité qui correspond à la somme des scores de tous les chemins qui mènent à $s_i$ depuis la source. Par exemple $\alpha(B_2) = (2\times 4) + (5\times 4) = 28$.


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Forward}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\alpha(s) \gets 1$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\alpha(s) \gets 0$
\ForAll {$(s',s) \in AE(s)$}
\State  $\alpha(s) \gets \alpha(s) + (\alpha(s')  \times \psi(\mathbf{x},s',s) ) $
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-forward}Algorithme Avant}
\end{algorithm}

On peut automatiser ce type de calcul à l'aide de l'algorithme avant qui est une variante, à demi-anneau près, de l'algorithme de Viterbi. Celle-ci est donnée en algorithme \ref{algo-forward}. La récurrence de cet algorithme est la suivante~: 
\begin{equation}
\label{eq-forward}
\alpha(s_i) = \left\{ 
\begin{array}{ll}
1 & \text{si }  i = 0\\
\sum_{(s',s_i)\in AE(s_i)}  \alpha(s') \times \psi(\mathbf{x},s',s_i)&\text{sinon}
\end{array}
\right.
\end{equation}
On peut remarquer que la quantité $\alpha(E)$ correspond au facteur de normalisation $Z$, c'est-à-dire la somme des scores de tous les chemins qui mènent de la source jusqu'à la destination (toutes les séquences de tags possibles). Autrement dit, l'algorithme avant permet de résoudre en temps polynomial le problème de sommation de scores pour un nombre exponentiel de séquences de tags. Formellement on a donc que~: 
\begin{displaymath}
\alpha(s_i) = \sum_{y_1\ldots y_i \in \mathbf{Y^i}}\prod_{j=1}^{j=i} \psi(\mathbf{x},y_{j-1},y_j)
\end{displaymath}
et pour la cas spécifique des séquences complètes~: 
\begin{displaymath}
\alpha(s_{m+1}) = Z = \sum_{\mathbf{y}\in \mathbf{Y}}\prod_{j=1}^{j=m} \psi(\mathbf{x},y_{j-1},y_j)
\end{displaymath}


\begin{exo}[Probabilité d'une séquence]
Utiliser les propriétés de l'algorithme avant pour 
calculer $P(S_0,B_1,A_2,E_3)$ la probabilité de la séquence $S,B,A,E$ dans le \ac{dag} exemple.
\end{exo}

\begin{exo}[Probabilité de toutes les séquences]
Calculer la probabilité de tous les chemins qui mènent de la source à la destination dans le \ac{dag} exemple. Vérifier que ces probabilités somment à 1 et que la séquence qui a la plus haute probabilité correspond à celle que vous avez trouvé avec l'algorithme de Viterbi.
\end{exo}

\subsubsection{Algorithme arrière} Quelle est la somme des scores qui mènent à un état $s_i$ depuis la destination ?
C'est la question à laquelle répond l'algorithme arrière.
On notera $\beta(s_i)$ la quantité qui correspond à la somme des scores de tous les chemins qui mènent à $s_i$ depuis la destination. Par exemple $\beta(B_1) = (2\times 3) + (3\times 4) = 18$. Il s'agit essentiellement d'une variante miroir de l'algorithme avant. La récurrence est la suivante~:
\begin{equation}
\label{eq-backward}
\beta(s_i) = \left\{ 
\begin{array}{ll}
1 & \text{si }  i = m+1\\
\sum_{(s_i,s')\in AS(s_i)}  \beta(s') \times \psi(\mathbf{x},s_i,s')&\text{sinon}
\end{array}
\right.
\end{equation}
En tant que tel cet algorithme arrière n'a pas beaucoup d'intérêt. C'est en combinaison avec l'algorithme avant que l'on peut faire émerger son utilité.

\begin{exo}[Pseudo-code]
Donner un pseudo code pour l'algorithme arrière.
\end{exo}

\subsubsection{Combiner les quantités avant et arrière}
Utilisées en combinaison, les quantités $\alpha(s_i)$ et $\beta(s_i)$ permettent de donner des probabilités à des sous-chemins dans un \ac{dag}.

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%alphas
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){573};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){29};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){28};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){114};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){115};
%betas
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (0+\x,0.5-\y){573};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (4+\x,0.5-\y){1};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,0-\y){67};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,1-\y){119};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,0-\y){13};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,1-\y){7};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,0-\y){2};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,1-\y){3};
\end{tikzpicture}
\end{center}
\caption{\label{fig-fb-trellis}Treillis de programmation dynamique annoté par $\alpha$ et $\beta$}
\end{figure}

L'exemple donné en figure \ref{fig-fb-trellis} illustre les quantités $\alpha(s_i)$, notées en bleu sur chaque noeud, et les quantités $\beta(s_i)$ sont notées en rouge.
On peut commencer par observer que la  quantité $\alpha(E_4) = 573$ correspond au facteur $Z$. 
On obtient la probabilité d'un chemin (d'une séquence de tags) comme par exemple le chemin $S_0,A_1,B_2,B_3,E_4$ en réalisant la division suivante~:
\begin{displaymath}
P(S_0,A_1,B_2,B_3,E_4) = \frac{5\times 4\times 1\times 3}{573} = \frac{60}{573}
\end{displaymath}
En utilisant la quantité $\alpha(s_i)$, on peut déterminer la probabilité d'un séquence de tags qui termine par $B,B,E$ de la manière suivante~:
\begin{displaymath}
P(\lhd,B_2,B_3,E_4) = \frac{\alpha(B_2)\times \psi(\mathbf{x},B_2,B_3)\times\psi(\mathbf{x},B_3,E_4)}{Z} = \frac{28\times 1\times 3}{573} = \frac{84}{573} 
\end{displaymath}
En continuant le raisonnement on peut calculer la probabilité de suivre une transition (par exemple $A_1,B_2$ représente la probabilité de tagguer le premier mot $A$ et le second mot $B$) en utilisant les quantités $\alpha(s_i)$ et $\beta(s_i)$~:
\begin{displaymath}
P(\lhd,A_1,B_2,\rhd) = \frac{\alpha(A_1)\times \psi(\mathbf{x},A_1,B_2)\times \beta(B_2)}{Z} = \frac{5\times 4 \times 7}{543}=\frac{140}{543}
\end{displaymath}
En résumé, et comme illustré dans les exercices qui suivent, on peut en réalité transformer un graphe de programmation dynamique en calculette.

Ce dernier exemple introduit une quantité clé qui est réutilisée par la méthode d'estimation des paramètres par descente de gradient qui est~:
\begin{equation}
P(\lhd,s_i,s_{i+1},\rhd | \mathbf{x};\mathbf{w}) = 
\frac{\alpha(s_i)\times \psi(\mathbf{x},s_i,s_{i+1}) \times \beta(s_{i+1})}
{Z}
\end{equation}
Celle-ci correspond à la probabilité de suivre une transition entre deux tags consécutifs. Utiliser les quantités avant et arrière pour calculer ces probabilités de transition, c'est utiliser l'\kw{algorithme avant/arrière}. Formellement, on peut remarquer que $P(\lhd,s_i,s_{i+1},\rhd | \mathbf{x})$ correspond à :
\begin{eqnarray}
P(\lhd,s_i,s_{i+1},\rhd | \mathbf{x})&=& \frac{1}{Z} \sum_{y_1\ldots y_{i-1}}\prod_{j=1}^{j={i-1}} \psi(\mathbf{x},y_{i-1},y_{i})\\
&\times &\psi(\mathbf{x},y_{i-1},y_i)\\
&\times &\sum_{y_i\ldots y_m}\prod_{j={i+1}}^{j=m} \psi(\mathbf{x},y_{j-1},y_{j})
\end{eqnarray}


\begin{exo}
\`A partir de la figure \ref{fig-fb-trellis},
donner la probabilité que le second mot soit taggué $B$, c'est-à-dire, $P(\lhd,B_2,\rhd)$.
\end{exo}

\begin{exo}
Observer que $P(\lhd,B_2,\rhd) + P(\lhd,A_2,\rhd) = 1$
à partir de la figure \ref{fig-fb-trellis}.
Expliquer informellement pourquoi.
\end{exo}

\section{Estimation des paramètres}

L'estimation des paramètres d'un \ac{crf} consiste à déterminer les valeurs du vecteur de paramètres $\mathbf{w}$ à partir d'un corpus annoté.

On suppose qu'un corpus annoté $C =\mathop{(\mathbf{x}_i,\mathbf{y}_i)\}}_{i=1}^N$ est un exemplaire de $N$ phrases. Chaque exemple annoté est un couple $(\mathbf{x}_i,\mathbf{y}_i)$ qui représente une séquence de mots $\mathbf{x}=x_1\ldots x_m$ et une séquence de tags de référence $\mathbf{y} = y_1\ldots y_m$ de même longueur.

Comme pour la régression logistique multinomiale,
on présente ici l'estimation des paramètres par maximum de (log-) vraisemblance conditionnelle. 
\begin{equation}
L(\mathbf{w}) = \sum_{i=1}^N \log P(\mathbf{y}_i | \mathbf{x}_i;\mathbf{w})
\end{equation}
Autrement dit on cherche à résoudre le problème d'optimisation suivant~:
\begin{equation}
\hat{\mathbf{w}} =  \mathop{\text{argmax}}_{\mathbf{w}\in\mathbb{R}^d} \sum_{i=1}^N \log P(\mathbf{y}_i | \mathbf{x}_i;\mathbf{w})
\end{equation}
En substituant la probabilité $P(\mathbf{y}_i | \mathbf{x}_i;\mathbf{w})$ par sa définition en équation (\ref{eq-crf-predict}), on optimise~:
\begin{equation}
\hat{\mathbf{w}} =  \mathop{\text{argmax}}_{\mathbf{w}\in\mathbb{R}^d} \sum_{i=1}^N \log\frac{\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)}
{\sum_{\mathbf{y}'\in \mathbf{Y}}
\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y^{'}_{i-1},y^{'}_i)\right)}
\end{equation}
Les dérivées partielles ont la même allure que pour la régression logistique multinomiale~:
\begin{equation}
\label{eq-crf-derivative}
\frac{\partial L(\mathbf{w})}{\partial w_k} 
= \sum_{i=1}^N C_k(\mathbf{x}_i,\mathbf{y}_i)
- \sum_{i=1}^N \sum_{\mathbf{y}\in \mathbf{Y}} P(\mathbf{y}|\mathbf{x}_i,\mathbf{w}) C_k(\mathbf{x}_i,\mathbf{y})
\end{equation}
où l'abbréviation $C_k(\mathbf{x},\mathbf{y})$
représente le comptage de la feature $\phi_k$
dans une séquence de référence, c'est-à-dire~:
\begin{displaymath}
C_k(\mathbf{x}_i,\mathbf{y}_i) = \sum_{j=1}^m \phi_k(\mathbf{x}_i,y_{j-1}^i,y_j^i)
\end{displaymath}
Le calcul du premier terme en (\ref{eq-crf-derivative}) consiste à compter les occurrences de $\phi_k$ dans l'ensemble des séquences du corpus de référence.

En ce qui concerne le second terme en (\ref{eq-crf-derivative}), il faut compter les occurrences de $\phi_k$ 
--~dans toutes les séquence de tags possibles~-- en pondérant chaque occurrence par la probabilité de la séquence de tags dans laquelle elle apparait. 
Naïvement, ce calcul demande d'énumérer
l'ensemble exponentiel $\mathbf{Y}$ 
de toutes les séquences de tags $\mathbf{y}\in\mathbf{Y}$ possibles pour chaque exemple du jeu de données.

Le développement qui suit consiste à montrer comment utiliser les techniques de programmation dynamique présentées précédemment pour réaliser ce calcul de manière efficace.  Le second terme de la formule (\ref{eq-crf-derivative}) nous dit que pour chaque exemple dans les données il faut calculer~:
\begin{align}
&\sum_{\mathbf{y}\in \mathbf{Y}} P(\mathbf{y}|\mathbf{x},\mathbf{w}) \sum_{j=1}^m \phi_k(\mathbf{x},y_{j-1},y_j)\\
&=\sum_{\mathbf{y}\in \mathbf{Y}} \sum_{j=1}^m P(\mathbf{y}|\mathbf{x},\mathbf{w})  \phi_k(\mathbf{x},y_{j-1},y_j)\\
&= \sum_{j=1}^m \sum_{\mathbf{y}\in \mathbf{Y}} P(\mathbf{y}|\mathbf{x},\mathbf{w})  \phi_k(\mathbf{x},y_{j-1},y_j)\\
&=  \sum_{j=1}^m \sum_{y_{j-1}}\sum_{y_j} P(\lhd,y_{j-1},y_j,\rhd|\mathbf{x},\mathbf{w})  \phi_k(\mathbf{x},y_{j-1},y_j)
\end{align}
Au terme de cette reformulation, l'évaluation du second terme revient à compter les occurrences de la feature $\phi_k$ --~pondérées par les probabilités de transitions où elles apparaissent~-- dans le \ac{dag} de programmation dynamique, et ce pour l'ensemble des exemples du jeu de données.




{\color{red} Développement un peu sloppy en l'état, voir par ex.
\url{http://perso.telecom-paristech.fr/~essid/teach/CRF_tutorial_ISMIR-2013.pdf}
pour des détails supplémentaires.}


\section{Fonctions features et potentiels}

\chapter{Analyse syntaxique en dépendances}

\section{Arbres de dépendances}

Un graphe de dépendances est un graphe $G = \langle V,E \rangle $
où :
\begin{itemize}
\item $W$ est un ensemble de noeuds muni d'une relation d'ordre $\prec$
\item $E \subseteq V\times V$  est un ensemble d'arcs 
\end{itemize}

La relation d'ordre sur les noeuds est la relation d'ordre sur les
entiers qui indicent les noeuds.
$E^*$ dénote la fermeture réflexive transitive de $E$. Cette relation
permet de capturer les relations de dominance entre noeuds qui sont indirectes.

Un arc $(i,j) \in E$ représente une relation de dépendance non typée entre
deux noeuds. Celle-ci est
également notée $i \rightarrow j$. 
On note $i\stackrel{*}{\rightarrow} j$ un élément de $E^*$

En pratique, les noeuds $w_i \in W$ sont étiquetés par des mots et les
arcs $(i,j) \in E$ sont étiquetés par des types qui représentent les
fonctions syntaxiques. Ces aspects pratiques sont secondaires pour les
problèmes algorithmiques et seront largement ignorés dans la suite de ce chapitre.


\paragraph{Propriétés}
Les arbres de dépendances sont des graphes $G = \langle W,E \rangle$ qui satisfont les
contraintes suivantes~:
\begin{enumerate}
\item $G$ est connexe. 
\begin{displaymath}
 i\in W \quad\Rightarrow\quad \exists_j (i \rightarrow j) \in E \lor
  (j\rightarrow i) \in E
\end{displaymath}
\item $G$ est acyclique. 
\begin{displaymath}
i \rightarrow j\in E \quad\Rightarrow\quad 
  j \stackrel{*}{\rightarrow} i \not \in E^*
\end{displaymath}
\item Chaque  noeud de $G$  a au plus un arc entrant~: 
\begin{displaymath}
i\rightarrow j  \in E \quad\Rightarrow\quad \lnot \exists k  (k\rightarrow j)\in E
\end{displaymath}
\item\label{it:projectif} $G$ est projectif~: 
\begin{displaymath}
 i\rightarrow j \in E \quad\Rightarrow\quad 
\forall_{k:i \prec k \prec j}  (i\stackrel{*}{\rightarrow} k)
\end{displaymath}
\end{enumerate}
La condition (\ref{it:projectif}) est parfois relâchée pour traiter
les langues à ordre des mots libre.



\section{Analyse par transitions}

Les méthodes d'analyse en dépendances par transitions sont dérivées
des méthodes d'analyse par décalage réduction utilisées pour l'analyse
en constituants et des formalisations d'algorithmes de planification
et de démonstration automatique.

L'ensemble de ces algorithmes travaille avec une structure de donnée
appelée {\bf configuration} (ou état) et qui est essentiellement un couple $\langle
\mathbf{S} , \mathbf{B}\rangle$ fait d'une pile et d'une file (ou
buffer). L'ensemble des configurations possibles est en général très
vaste de telle sorte que mener une procédure exacte de recherche de
solutions d'analyse est en général infaisable. Par conséquent les
algorithmes présentés dans cette section sont en général associés à
des méthodes de recherche inexactes de solution. Le caractère inexact
de la méthode de recherche de solution est compensé par la richesse de
l'information stockée dans les configurations, ce qui permet de
prendre des décisions très bien informées localement.

\subsection{Modèle Arc-standard}

Le modèle arc-standard est un modèle d'analyse dont les configurations
sont des triplets $\langle \mathbf{S},\mathbf{B} ,  A\rangle$ où
$\mathbf{S}$ est une pile, $\mathbf{B}$ une file et $A$ un ensemble d'arcs.
La donnée à analyser $\mathbf{x} = w_0\ldots w_n$ est une séquence de mots
dont le mot $w_0$ est par convention un mot artificiel qui représente
la racine de l'arbre.

L'algorithme (Figure \ref{fig-AS}) commence avec un état initial où la
pile est vide et la file remplie de la séquence de mots. Il termine
lorsque la pile ne contient plus que la racine de l'arbre et que le
buffer est vide. Les actions arc gauche ({\bf left-arc}) et ({\bf
  right-arc}) sont des contreparties de l'action de réduction d'un
analyseur à décalage réduction. L'action de décalage est la
contrepartie fidèle d'une action de décalage traditionnelle.



\begin{figure}[htbp]
\begin{displaymath}
\begin{array}{rccll}
\mathbf{init}  &\langle \epsilon , w_0 \ldots w_n ,\emptyset \rangle\\
\mathbf{but}  & \langle w_0 ,\epsilon , A \rangle\\
\mathbf{shift} & \langle \mathbf{S} ,  w_i | \mathbf{B} , A   \rangle
&\Rightarrow &\langle \mathbf{S} | w_i ,  \mathbf{B} , A   \rangle\\
\mathbf{left-arc} &\langle \mathbf{S}|w_i | w_j , \mathbf{B} , A
\rangle &\Rightarrow& \langle \mathbf{S}| w_j , \mathbf{B} , A \cup \{
j\rightarrow i \}   \rangle & (i\not = w_0)\\
\mathbf{right-arc }  &\langle \mathbf{S}|w_i | w_j , \mathbf{B} , A   \rangle
&\Rightarrow & 
\langle \mathbf{S}| w_i , \mathbf{B} , A \cup \{
i \rightarrow j \}   \rangle
\end{array}
\end{displaymath}
\caption{\label{fig-AS}Le système de transitions arc standard}
\end{figure}


Les actions arc-gauche et arc-droit sont augmentées d'une procédure
qui collecte les arcs créés en cours d'analyse (représentés par
l'ensemble $A$) ce qui permet d'extraire trivialement l'arbre de
dépendance en fin d'analyse.

L'algorithme est fondamentalement non déterministe. Il est par
conséquent habituel de l'augmenter (1) d'une méthode de pondération des
hypothèses et (2) d'une méthode de recherche de solutions
approximative (en général non exhaustive en faisceau).

\paragraph{Dérivations et pondérations} 
Un pas de dérivation est le passage d'une configuration $c_i$ à une
configuration $c_{i+1}$ en utilisant une transition (ou action) $t\in
\{shift, left-arc,right-arc, stop\}$. L'action {\bf stop} est exécutée
uniquement pour terminer l'analyse lorsque le buffer est vide et que
la pile ne peut plus être réduite.

Une séquence de dérivation, ou {\bf dérivation}, est une séquence de la
forme $\mathbf{d} = (c_0, t_0) \ldots (c_m,t_m)$. On pondère une dérivation en
faisant l'hypothèse que son score se décompose par la somme~:
\begin{equation}
\Psi(\mathbf{d}) = \sum_{i=0}^m  \psi(c_i,t_i,\mathbf{x})
\end{equation}
où $\mathbf{x}$ représente la séquence de mots à analyser.
Le problème d'analyse syntaxique consiste en général à résoudre~:
\begin{equation}
{\mathbf{\hat{d}}} = \mathop{\text{argmax}}_{\mathbf{d} \in \mathbf{D}(\mathbf{x})} \Psi(\mathbf{d}) 
\end{equation}
où $\mathbf{D}(\mathbf{x})$ représente l'ensemble des dérivations possibles pour
la phrase à analyser.

Les dérivations complètes du système de transition arc-standard ont comme
propriété que leur longueur est de $2n-1$ pas de dérivation pour une
phrase de $w_0\ldots w_n$ mots~:  pour obtenir une analyse complète,
il faut réaliser $n$ décalages et $n-1$ opérations d'arcs (gauche ou
droite).
Lorsqu'on ajoute une action {\bf stop} la longueur de la dérivation
vaut $2n$.

Cette propriété facilite l'usage du système arc-standard en
combinaison avec une méthode de recherche de solutions en faisceau.
En effet, on observe empriquement que le score d'une dérivation tel
que donné par un modèle discriminant est à peu près linéairement
corrélé à sa longueur~: plus une dérivation est longue, plus son score
est élevé. Ici, comme toutes les dérivations concurrentes ont la même
longueur, ce problème de biais lié à la longueur ne se manifeste pas
(contrairement à la plupart des systèmes de transitions présentés par la suite).

\begin{algorithm}[htbp]
\begin{algorithmic}[0]
\Function{ArcStandardBeamParse}{$\mathbf{x}$,K}
\State ${\cal B} \gets \langle \epsilon, w_0\ldots w_n,\emptyset\rangle$
\For  {$0\leq i < 2n-1$}
\For {$c \in \mathop{\text{K-argmax}}_{c \in {\cal B}} \delta(c)$}
\For{$t \in T$}\Comment{$T$ est l' ensemble des actions}
\State $c' \gets t(c)$
\State $\delta(c') \gets \delta(c) + \psi(c,t,\mathbf{x})$
\State ${\cal B}' \gets {\cal B}\cup c'$
\EndFor
\EndFor
\State ${\cal B} \gets {\cal B}'$
\EndFor
\State \Return $\mathop{\text{argmax}}_{c\in \cal B} \delta(c)$
\EndFunction
\end{algorithmic}
\caption{\label{algo-arc-standard}Algorithme d'analyse Arc Standard en
faisceau}
\end{algorithm}


\paragraph{Estimation des paramètres}
L'estimation des paramètres se réalise à partir d'un 
corpus annoté $C = \mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$ qui est un
exemplaire de $N$ phrases où chaque séquence de mots $\mathbf{x}_i$
est associée à un arbre de référence $\mathbf{y}_i$.

La procédure d'apprentissage consiste à estimer un vecteur de
paramètres $\mathbf{w}$ de telle sorte que les dérivations prédites par
l'algorithme sont les plus similaires aux dérivations de référence.
Comme les données sont naturellement des couples
$(\mathbf{x}_i,\mathbf{y}_i)$, il faut transformer les arbres de
référence $\mathbf{y}_i$ en dérivations.
On réalise cette opération à l'aide d'un {\bf oracle} statique
(Algorithme \ref{algo-AS-oracle}) qui permet de simuler l'analyse de référence en utilisant
comme donnée $A$ l'ensemble des arcs de l'arbre de référence. L'oracle
permet également de mettre en évidence l'idée bottom-up du système arc-standard~: la
création d'un arc vers un noeud $i$ exige que tous les dépendants 
de $i$ soient déjà identifiés.

\begin{algorithm}
\scriptsize
\begin{algorithmic}[0]
\Function{ArcStandardStaticOracle}{$\mathbf{S},\mathbf{B},A, A_{ref}$}
\If{ $\mathbf{S} | i | j $} \Comment{Il y a au moins 2 éléments sur la
pile}
\If{$i\rightarrow j \in A_{ref}$ {\bf and} $j\not = 0$ {\bf and}
  $\forall k (j \rightarrow k \in A_{ref} \Rightarrow  j \rightarrow k \in A)$}
\State \Return $\mathbf{right-arc}$
\ElsIf{$j\rightarrow i \in A_{ref}$ {\bf and} $i\not = 0$ {\bf and} 
 $\forall k (i \rightarrow k \in A_{ref} \Rightarrow  i \rightarrow k \in A)$}
\State \Return $\mathbf{left-arc}$
\EndIf
\EndIf
\If{$\mathbf{B} \not = \epsilon$} \Comment{Il y a au moins un élément
  dans la file}
\State\Return $\mathbf{shift}$
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-AS-oracle} Oracle statique pour le système arc
  standard}
%http://demo.clab.cs.cmu.edu/fa2015-11711/images/b/b1/TbparsingSmallCorrection.pdf
\end{algorithm}
Le jeu de données transformé où les arbres $\mathbf{y}_i$ sont
transformés en dérivation $\mathbf{d}_i$ prend alors la forme suivante.
$C = \mathop{(\mathbf{x}_i,\mathbf{d}_i)}^N_{i=1}$. L'estimation des
paramètres se fait en général avec un modèle à large marge car
l'utilisation d'un {\sc crf} exige un facteur de
normalisation qui demande de calculer l'ensemble des dérivations
possibles pour une phrase donnée, ce qui est trop coûteux en temps de calcul.
On donne ici une méthode d'estimation à l'aide de l'algorithme du
perceptron (Algorithme \ref{perceptron-AS}).

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{arc-standard-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{d}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{\mathbf{d}} \gets \mathop{\text{argmax}}_{\mathbf{d}\in
  \mathbf{D}(\mathbf{x})} 
\sum_{j = 0}^m \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,c_j,t_j)$
\Comment{Parsing}
\If{$\hat{\mathbf{d}} \not = \mathbf{d}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[ \sum_{j=0}^m \boldsymbol\Phi(\mathbf{x}_i,c_j,t_j) 
       - \sum_{j=0}^m \boldsymbol\Phi(\mathbf{x}_i,\hat{c}_j,\hat{t}_j)   \right]$ 
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{perceptron-AS}Perceptron pour un système d'analyse
  en dépendances par transitions}
\end{algorithm}


\paragraph{Unicité de l'oracle (move elsewhere)}
L'analyse par transitions suppose que chaque arbre de dépendance de
référence $\mathbf{y}_i$ peut être transformé en une dérivation de
référence $\mathbf{d}_i$. Autrement dit, on suppose une fonction $o :
A \mapsto D$. 

On peut remarquer que cette fonction n'est pas déterministe pour le
système de transitions arc-standard~: plusieurs dérivations peuvent
représenter le même arbre de dépendances.

\begin{dependency}
\begin{deptext}[column sep=.5cm]
$w_0$ \& $w_1$ \& $w_2$ \& $w_3$\\
\end{deptext}
\depedge[hide label]{1}{3}{ }
\depedge[hide label]{3}{2}{ }
 \depedge[hide label]{3}{4}{ }
\end{dependency}
\begin{tabular}{cccccc}
S&S&LA&S&RA&RA\\
S&S&S&RA&LA&RA\\
\end{tabular}

 \paragraph{Problème d'approximation par recherche en faisceau}
L' algorithme \ref{perceptron-AS} est en général utilisé avec un
algorithme de recherche en faisceau, ce qui a pour conséquence que la
meilleure analyse prédite n'est pas nécessairement celle qui a le meilleur
poids pour le modèle (celle-ci peut avoir été sortie prématurément du faisceau).

Dans ce cas de figure, il est donc possible que l'algorithme
d'estimation réalise une mise à jour des poids alors que sans
l'approximation introduite par le faisceau
le modèle aurait prédit la bonne analyse. Ce comportement peut
perturber la descente de gradient jusqu'à causer une divergence.

Pour garantir que la descente de gradient converge il faut garantir
que la mise à jour a lieu lorsqu'il y a bien une violation effective de la marge
et que celle-ci ne provient pas de l'approximation en faisceau.

Pour cette raison on s'autorise dans la pratique à réaliser la mise à
jour sur des sous-séquences de dérivation pour lesquelles on a la
garantie que la marge est effectivement violée indépendamment des
approximations introduites par le faisceau. Autrement dit une mise à
jour valide respecte la condition suivante\footnote{
La mise à jour invalide qui consiste à comparer la meilleure analyse complète
dans le faisceau en fin d'analyse avec la référence ne vérifie pas cette condition dans tous les cas. 
}~:
\begin{equation}
\Psi(\tilde{\mathbf{y}}^*_{0\ldots k}) > \Psi(\mathbf{y}_{0\ldots k})
\end{equation}
La méthode la plus utilisée en pratique est la mise à jour rapide
({\bf early update}) où la mise à jour est réalisée sur des
sous-dérivations dont le préfixe $0\ldots k$ correspond à l'étape de
dérivation où la dérivation de référence sort du faisceau. Une méthode
alternative est la mise à jour à violation maximale de la marge ({\bf max violation update}). 
Dans ce cas on choisit $k$ tel que 
\begin{displaymath}
k = \mathop{\text{argmax}}_{0 \leq k
 < 2n-1}\Psi(\tilde{\mathbf{y}}^*_{0\ldots k}) -
\Psi(\mathbf{y}_{0\ldots k})
\end{displaymath}

\subsection{Modèle Arc-eager}

Le modèle arc-eager est un modèle d'analyse dont les configurations
sont des triplets $\langle \mathbf{S},\mathbf{B} ,  A\rangle$ où
$\mathbf{S}$ est une pile, $\mathbf{B}$ une file et $A$ un ensemble d'arcs.
La donnée à analyser $\mathbf{x} = w_0\ldots w_n$ est une séquence de mots
dont le mot $w_0$ est par convention un mot artificiel qui représente
la racine de l'arbre.

L'algorithme (Figure \ref{fig-AE}) commence avec un état initial où la
pile est vide et la file remplie de la séquence de mots. Il termine
lorsque le buffer est vide. Contrairement au système arc-standard, ici
le système essaye d'attacher les nouveaux mots le plus rapidement possible dans
la structure~: les transitions left-arc et right-arc attachent le
premier mot du buffer à la structure avant même qu'il ait été placé
sur la pile. La transition de réduction qui supprime la tête de pile
indique que le mot ne fera plus partie d'une relation de dépendance
par la suite.  Quant à la transition de décalage, elle est plus classique. 
\begin{figure}[htbp]
\begin{displaymath}
\begin{array}{rccll}
\mathbf{init}  &\langle w_0 ,  w_1 \ldots w_n ,\emptyset \rangle\\
\mathbf{but}  & \langle \mathbf{S} ,\epsilon , A \rangle\\
\mathbf{shift} & \langle \mathbf{S} ,  w_i | \mathbf{B} , A   \rangle
&\Rightarrow &\langle \mathbf{S} | w_i ,  \mathbf{B} , A   \rangle\\
\mathbf{left-arc} &\langle \mathbf{S}| w_i , w_j|\mathbf{B} , A
\rangle &\Rightarrow& \langle \mathbf{S}, w_j | \mathbf{B} , A \cup \{
j\rightarrow i \}   \rangle & (i\not = w_0 \text{ et } \lnot \exists k
(k\rightarrow i \in A) )\\
\mathbf{right-arc }  &\langle \mathbf{S}|w_i , w_j | \mathbf{B} , A   \rangle
&\Rightarrow & 
\langle \mathbf{S}| w_i | w_j , \mathbf{B} , A \cup \{
i \rightarrow j \}   \rangle
&\lnot\exists k (k\rightarrow j \in A)\\
\mathbf{reduce}&\langle \mathbf{S}|w_i , \mathbf{B} , A   \rangle
&\Rightarrow & 
\langle \mathbf{S} , \mathbf{B} , A   \rangle & 
\exists k (k\rightarrow i \in A)
\end{array}
\end{displaymath}
\caption{\label{fig-AE}Le système de transitions arc eager}
\end{figure}

Le système arc-eager offre des garanties plus faibles que
arc-standard~: le but est satisfait dès que le buffer est vide. 
En particulier il ne garantit pas que l'analyse renvoie
un arbre de dépendances unique. Il renvoie en général une forêt~:
plusieurs racines sont possibles. Il est par conséquent classique
d'ajouter une étape de finalisation dans les implémentations qui
relie l'ensemble des racines résultantes à $w_0$.


\paragraph{Dérivations et pondérations} 
Un pas de dérivation est le passage d'une configuration $c_i$ à une
configuration $c_{i+1}$ en utilisant une transition (ou action) $t\in
\{shift, left-arc,right-arc, reduce,stop\}$. L'action {\bf stop} est exécutée
uniquement pour terminer l'analyse lorsque le buffer est vide.

Une séquence de dérivation, ou {\bf dérivation}, est une séquence de la
forme $\mathbf{d} = (c_0, t_0) \ldots (c_m,t_m)$. On pondère une dérivation en
faisant l'hypothèse que son score se décompose par la somme~:
\begin{equation}
\Psi(\mathbf{d}) = \sum_{i=0}^m  \psi(c_i,t_i,\mathbf{x})
\end{equation}
où $\mathbf{x}$ représente la séquence de mots à analyser.
Le problème d'analyse syntaxique consiste en général à résoudre~:
\begin{equation}
{\mathbf{\hat{d}}} = \mathop{\text{argmax}}_{\mathbf{d} \in \mathbf{D}(\mathbf{x})} \Psi(\mathbf{d}) 
\end{equation}
où $\mathbf{D}(\mathbf{x})$ représente l'ensemble des dérivations possibles pour
la phrase à analyser.

Les dérivations complètes du système de transition arc-eager ont comme
propriété que leur longueur vaut {\bf au plus} $2n-1$ pas de dérivation pour une
phrase de $w_0\ldots w_n$ mots~: il est en effet possible de terminer
une analyse en $n$ étapes (après $n$ décalages tous les mots sont
racines d'un arbre différent et l'analyse est potentiellement terminée). 

Cette propriété complique l'usage du système arc-eager en
combinaison avec une méthode de recherche de solutions en faisceau.
En effet il faut pouvoir comparer des dérivations de longueurs
différentes, ce qui est généralement problématique tant pour la 
gestion du faisceau que de la gestion de la corrélation entre longueur
de la séquence et score de la dérivation.
Pour ces raisons, le système arc-eager est habituellement utilisé avec
un modèle de recherche de solutions qui est glouton et une
approximation par des modèles statistiques locaux.
Il faut finalement remarquer que dans le contexte où le modèle est glouton, la
procédure d'analyse syntaxique est particulièrement simple (Algorithme
\ref{algo-arceager}).
\begin{algorithm}[htbp]
\begin{algorithmic}[0]
\Function{ArcEagerGreedyParse}{$\mathbf{x}$}
\State $c \gets \langle w_0, w_1\ldots w_n,\emptyset\rangle$
\While {$c_{buffer} \not = \emptyset$}
\State $t \gets \mathop{\text{argmax}}_{t\in T} \psi(c,t,\mathbf{x})$
\Comment{$T$ est l'ensemble des actions}
\State $c \gets t(c)$
\EndWhile
\State \Return $c$
\EndFunction
\end{algorithmic}
\caption{\label{algo-arceager}Algorithme d'analyse Arc Eager glouton}
\end{algorithm}




\paragraph{Estimation des paramètres par modèle local}
L'estimation des paramètres se réalise à partir d'un 
corpus annoté $C = \mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$ qui est un
exemplaire de $N$ phrases où chaque séquence de mots $\mathbf{x}_i$
est associée à un arbre de référence $\mathbf{y}_i$.

Dans le contexte d'un modèle local, la procédure d'apprentissage consiste à estimer un vecteur de
paramètres $\mathbf{w}$ de telle sorte que pour chaque configuration
d'analyse identifiable dans les données de référence, la prédiction de
l'algorithme soit la plus similaire à l'action de référence trouvée
dans les données. Cette procédure suppose de transformer un treebank
$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$
en une séquence de couples $\mathop{(x_i,y_i)}_{i=1}^{N'}$
de configurations $x_i$ et d'actions $y_i$ à prédire.

On réalise cette opération à l'aide d'un {\bf oracle} statique
(Algorithme \ref{algo-AE-oracle}) qui permet de simuler l'analyse de référence en utilisant
comme donnée $A$ l'ensemble des arcs de l'arbre de référence. 

\begin{algorithm}
\scriptsize
\begin{algorithmic}[0]
\Function{ArcEagerStaticOracle}{$\mathbf{S},\mathbf{B},A, A_{ref}$}
\If{ $\mathbf{S} | i  $ {\bf and} $j | \mathbf{B}$} \Comment{Il y a au moins 1 élément sur la
pile et 1 sur la file}
\If{$j\rightarrow i \in A_{ref}$ {\bf and} $i\not = 0$}
\State \Return $\mathbf{left-arc}$
\ElsIf{$i\rightarrow j \in A_{ref}$}
\State \Return $\mathbf{right-arc}$
\EndIf
\EndIf
\If {$\mathbf{S} | i$}\Comment{Il y a au moins 1 élément sur la pile}\
\If{$\exists k (k\rightarrow i \in A)$ {\bf and} $\forall
  k' (i\rightarrow k') \in A_{ref} \Rightarrow (i\rightarrow k') \in A$}
\State \Return $\mathbf{reduce}$
\EndIf
\EndIf
\If {$j | \mathbf{B}$}\Comment{Il y a au moins 1 élément dans le
  buffer}\State\Return $\mathbf{shift}$
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-AE-oracle} Oracle statique pour le système arc
  eager}
\end{algorithm}
Le jeu de données transformé où les arbres $\mathbf{y}_i$ sont
transformés en une séquence de couples $\mathop{(x_i,t_i)}_{i=1}^N$
est utilisé pour entraîner tout modèle d'apprentissage approprié~:
modèle à large marge local, modèle de régression logistique
multinomiale ou réseau de neurones. Contrairement aux modèles
structurés présentés précédemment, calculer le facteur de
normalisation pour les modèles logistiques ne pose pas de problème
particulier dans le cas des modèles locaux. On donne ici un exemple
d'algorithme d'estimation
de paramètres  à l'aide de l'algorithme du
perceptron (Algorithme \ref{perceptron-AE}).

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{arc-eager-local-perceptron}{$\mathop{(x_i,t_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{t} \gets \mathop{\text{argmax}}_{t\in
  T}  \mathbf{w}^T \boldsymbol\Phi(c_i,t)$
\If{$\hat{t} \not = t_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[ \boldsymbol\Phi(c_j,t_j) 
       - \boldsymbol\Phi(c_j,\hat{t})   \right]$ 
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{perceptron-AE}Perceptron pour un système à
  apprentissage local}
\end{algorithm}

\paragraph{Unicité de la dérivation et oracles dynamiques}
TODO

\subsection{Modèle de Covington}

Idée : $\mathbf{S}_1$ = mots déjà traités
$\mathbf{S}_2$ = liste qui contient successivement les candidats à
attacher à $w_j$


\begin{figure}[htbp]
\begin{displaymath}
\begin{array}{rccll}
\mathbf{init}  &\langle \epsilon , \epsilon , w_0 \ldots w_n ,\emptyset \rangle\\
\mathbf{but}  & \langle \epsilon , w_0|\mathbf{S}_2 , w_n, A \rangle && (to check)\\
\mathbf{shift} & \langle \mathbf{S}_1, \mathbf{S}_2 ,  w_i | \mathbf{B} , A   \rangle
&\Rightarrow &\langle  \mathbf{S}_1\mathbf{S}_2 | w_i , \epsilon ,
\mathbf{B} , A   \rangle\\

\mathbf{no-arc}& \langle \mathbf{S}_1 | w_i , \mathbf{S}_2 , \mathbf{B} , A \rangle 
&\Rightarrow &\langle \mathbf{S}_1 ,  w_i |\mathbf{S}_2 ,\mathbf{B} , A\rangle \\

\mathbf{left-arc}& \langle \mathbf{S}_1 | w_i , \mathbf{S}_2 , w_j | \mathbf{B} , A \rangle 
&\Rightarrow &\langle \mathbf{S}_1 ,  w_i |\mathbf{S}_2 ,w_j|\mathbf{B} ,
A \cup \{j\rightarrow i\}\rangle  
(\lnot\exists k (k\rightarrow i  \in A) \land i \stackrel{*}{\rightarrow } j \not\in A*) \\

\mathbf{right-arc}& \langle \mathbf{S}_1 | w_i , \mathbf{S}_2 , w_j | \mathbf{B} , A \rangle 
&\Rightarrow &\langle \mathbf{S}_1 ,  w_i |\mathbf{S}_2 ,w_j|\mathbf{B} ,
A \cup \{i\rightarrow j\}\rangle 
(\lnot\exists k (k\rightarrow j  \in A) \land j \stackrel{*}{\rightarrow } i \not\in A*)
\end{array}
\end{displaymath}
\caption{\label{fig-covington}Le système de transitions à pile partagée}
\end{figure}


\section{Analyse CKY}
\subsection{La version naïve}

On peut envisager adapter l'algorithme {\sc cky} au cas de l'analyse
en dépendances de manière directe et naïve. C'est ce que nous
présentons dans ce qui suit. Cette première solution pose toutefois un
problème de complexité car les analyses sont produites en ${\cal O}(n^5)$. On donne en section
\ref{sec-arc-factored} une version moins naïve qui produit des
analyses projectives en ${\cal O}(n^3)$ et qui est la version
utilisée dans les implémentations habituelles.

Sous forme déductive, les items de l'algorithme sont des triplets 
de la forme $\langle i,j,h \rangle$ où $i$ est l'indice de l'extrémité
gauche de l'empan, $j$ l'indice de l'extrémité droite de l'empan et
$h \, (i\leq h \leq j)$ est la position de la tête dans la séquence de
mots $\mathbf{x} = w_1\ldots w_n$ à analyser. 
En suivant le principe classique de l'algorithme {\sc cky}, l'algorithme
donné ici commence en supposant que chaque mot définit son propre empan puis
essaye de combiner des empans contigus en empans de plus en plus
larges en utilisant deux actions de réductions qui se distinguent par
leur manière d'assigner la tête au nouvel empan. On résume cet
algorithme sous forme de système déductif en figure \ref{fig-cky-dep}.
\begin{figure}[htbp]

\begin{eqnarray*}
\mathbf{init}  &\frac{\, }{\langle i, i+1, w_i \rangle} & (0\leq i <
n)\\
\mathbf{but}  &\langle 0,n, h \rangle \\
\mathbf{reduce}(\curvearrowleft) &
\frac{\langle i,k,h \rangle\quad \langle k,j,h' \rangle}
{\langle i,j,h\rangle}\\
\mathbf{reduce}(\curvearrowright) &
\frac{\langle i,k,h \rangle\quad \langle k,j,h' \rangle}
{\langle i,j,h'\rangle} 
\end{eqnarray*}

\caption{\label{fig-cky-dep} Algorithme {\sc cky} pour l'analyse en dépendances}
\end{figure}
On peut remarquer que chacune des règles de réduction (gauche et droite) fait intervenir 5
indices libres ce qui suggère une complexité en ${\cal O}(n^5)$.


\paragraph{Estimation des poids}
Cet algorithme peut être pondéré par tout modèle discriminant.
L'estimation des poids pour un modèle {\sc crf} demande de déployer 
des récurrences dedans dehors ({\em inside-outside}) et est difficile à rendre efficace à l'usage. Les modèles à large marge sont en
principe plus faciles à utiliser mais cet algorithme naïf n'est en
général pas utilisé en pratique. C'est l'algorithme par factorisation
des arcs présenté ci-dessous qui est utilisé en pratique.

\subsection{Factorisation en arcs}
\label{sec-arc-factored}
L'algorithme d'analyse en dépendances par factorisation des arcs ({\em arc factored parser}, Algorithme \ref{algo-eisner})
peut-être vu comme une reformulation de l'algorithme {\sc cky} au cas des dépendances projectives.
L'algorithme cherche à construire itérativement des sous-arbres qui couvrent des empans de plus en plus grands
et s'arrête lorsqu'il a construit le meilleur sous-arbre pour  un empan qui couvre toute la phrase à analyser.

Pour un empan $(i,j)$ l'algorithme construit les {\bf sous-arbres incomplets} ($\bot$) qui couvrent cet empan, qu'ils commencent en $i$ ou en $j$
en créant les arcs correspondants. Cette première étape cherche à construire des arbres dont un arc $i\rightarrow j$ ou $j\rightarrow i$
couvre l'intégralité de l'empan. Dans un second temps, l'algorithme cherche à produire des {\bf sous-arbres complets} ($\top$) en combinant
 un arbre incomplet avec un arbre complet qui couvre un empan plus petit, ce qui permet de couvrir l'empan avec des relations de dépendances indirectes de la forme $i\stackrel{*}{\rightarrow} j$ ou
$j\stackrel{*}{\rightarrow} i$.

\begin{algorithm}[htbp]

\scriptsize
\begin{algorithmic}[0]
\Function{ArcFactored}{$\mathbf{x}$,n}
\State C[i][i][d][c] $\gets 0.0 \quad 0 \leq i \leq n, d\in
\{\curvearrowleft, \curvearrowright\}, c \in \{\top,\bot \}$ 

\For {$1 \leq span \leq n$}
  \For{$1\leq i \leq n-span$}
     \State $j \gets s + span$
     \State\Comment{Arbres incomplets}
     \State C[i][j][$\curvearrowleft$][$\bot$] $\gets
     \mathop{\text{max}}_{i\leq k < j}(C[i][k][\curvearrowright][\top]
     + C[k+1][j][\curvearrowleft][\top] + score(\mathbf{x},j,i))$
     \State C[i][j][$\curvearrowright$][$\bot$] $\gets \mathop{\text{max}}_{i\leq k < j}(C[i][k][\curvearrowright][\top] + C[k+1][j][\curvearrowleft][\top] + score(\mathbf{x},i,j))$ 
     \State\Comment{Arbres complets}
     \State C[i][j][$\curvearrowleft$][$\top$] $\gets \mathop{\text{max}}_{i\leq k < j}(C[i][k][\curvearrowleft][\top] + C[k][j][\curvearrowleft][\bot])$     
     \State C[i][j][$\curvearrowright$][$\top$] $\gets \mathop{\text{max}}_{i < k \leq j}(C[i][k][\curvearrowright][\bot] + C[k][j][\curvearrowright][\top])$     

 \EndFor
\EndFor
\EndFunction
\end{algorithmic}

\caption{\label{algo-eisner}Algorithme d'analyse à arcs factorisés (Eisner)}
\end{algorithm}



\paragraph{Arbres incomplets}
Pour un empan donné $(i,j)$ l'algorithme commence par créer les arcs
$i\rightarrow j$ et $j\rightarrow i$. On dit de ces arcs qu'ils
représentent des arbres incomplets car ils ne codent pas toute la
projection du gouverneur. Par exemple, si $i$ est choisi comme
gouverneur et que l'arc $i\rightarrow j$ est ajouté,
l'arbre incomplet va capturer toutes les relations 
$i \stackrel{*}{\rightarrow} k$ pour $i\leq k \leq j$. Par contre il
est possible que des relations $i \stackrel{*}{\rightarrow} l$
existent avec $l > j$. 

\begin{figure}[htbp]
\begin{minipage}[t]{.5\textwidth}
\begin{center}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
i \& j \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{2}{ } 
\end{dependency}
\hrule
\scalebox{0.65}{
\begin{tabular}{cc}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{4}{ } 
  \depedge[hide label]{1}{2}{ }
  \depedge[hide label]{4}{3}{ }
\end{dependency}
&
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{4}{ } 
  \depedge[hide label]{1}{2}{ }
  \depedge[hide label]{3}{4}{ }
\end{dependency}\\
ok & DAG \\
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{4}{ } 
  \depedge[hide label]{2}{1}{ }
  \depedge[hide label]{4}{3}{ }
\end{dependency}
&
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{4}{ } 
  \depedge[hide label]{2}{1}{ }
  \depedge[hide label]{3}{4}{ }
\end{dependency}\\
non projective & non projective + DAG \\
\end{tabular}}
\end{center}

\end{minipage}
\begin{minipage}[t]{.5\textwidth}
\begin{center}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
i \& j \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{2}{1}{ } 
\end{dependency}
\hrule
\scalebox{0.65}{
\begin{tabular}{cc}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
 \depedge[hide label,edge style={ultra thick,dotted}]{4}{1}{ } 
  \depedge[hide label]{1}{2}{ }
  \depedge[hide label]{4}{3}{ }
\end{dependency}
&
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{4}{1}{ } 
  \depedge[hide label]{1}{2}{ }
  \depedge[hide label]{3}{4}{ }
\end{dependency}\\
ok & non projective \\
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{4}{1}{ } 
  \depedge[hide label]{2}{1}{ }
  \depedge[hide label]{4}{3}{ }
\end{dependency}
&
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{4}{1}{ } 
  \depedge[hide label]{2}{1}{ }
  \depedge[hide label]{3}{4}{ }
\end{dependency}\\
DAG & non projective + DAG \\
\end{tabular}}

\end{center}
\end{minipage}
\caption{\label{fig-incomplete}Cas admissibles pour les arbres incomplets}
\end{figure}

On peut remarquer en Figure \ref{fig-incomplete} que 
l'ajout d'un arc  $i \rightarrow j$ (ou $j \rightarrow i$)
n'est autorisé que dans peu de configurations préexistantes. Les différents cas sont
illustrés sur la figure et motivent les lignes correspondantes de
l'algorithme \ref{algo-eisner}. Seul le cas où à la fois $i$ et $j$
ont des dépendants qui sont situés dans l'intervalle $i\ldots j$ autorise
la création de l'arc. Les cas alternatifs potentiels créent des
structures en graphe ou des structures non projectives et sont donc interdits par
l'algorithme.

\paragraph{Arbres complets}
La création des arbres incomplets par ajout de l'arc $i\rightarrow j$ permet de créer des sous-arbres de
dépendances tels que le gouverneur $i$ domine l'ensemble des
dépendants $k$ tels que $i\leq k \leq j$. Autrement dit, l'algorithme
garantit la projectivité de l'analyse sur l'empan $i\ldots j$. Par
contre $i$ peut potentiellement dominer des mots $l$ tels que $l > j$
et tels que $i\stackrel{*}{\rightarrow} l$. C'est pour capturer ce
manque qu'il y a une étape supplémentaire de création d'arbres complets. 
Celle-ci consiste à créer des liens de type
$i\stackrel{*}{\rightarrow} l$ en concaténant un arbre incomplet
$i\rightarrow j$ avec un arbre complet de la forme $j\stackrel{*}{\rightarrow} l$.

En résumé, les arbres incomplets relient directement $i\rightarrow j$
(ou $j\rightarrow i$)
sur un empan $i\ldots j$ alors que les arbres incomplets représentent
des liens potentiellement indirects $i\stackrel{*}{\rightarrow} j$ (ou
 $j\stackrel{*}{\rightarrow} i$) qui combinent plusieurs empans.

\paragraph{Complexité}L'intérêt de cet algorithme est qu'il permet d'obtenir un analyseur en
dépendances projectif en ${\cal O}(n^3)$ alors que l'adaptation naïve
de l'algorithme {\sc cky} a une complexité en ${\cal O}(n^5)$

Comparison with naive CYK

\paragraph{Arc factored}

\begin{eqnarray*}
\mathbf{init}&\langle i,i,d,c\rangle &
(0\leq i < n , d\in \{\curvearrowright , \curvearrowleft\}, c \in
\{\top ,\bot \})\\
\mathbf{reduce}(\curvearrowleft)&
\frac{\langle i,k,\curvearrowright,\top \rangle\quad \langle k+1,j,\curvearrowleft,\top \rangle}
{\langle i,j,\curvearrowleft,\bot \rangle} \\
\mathbf{reduce}(\curvearrowright)&\frac{\langle i,k,\curvearrowright,\top \rangle\quad \langle k+1,j,\curvearrowleft,\top \rangle}
{\langle i,j,\curvearrowright,\bot \rangle}\\
\end{eqnarray*}

\begin{displaymath}
\frac{\langle i,k,\curvearrowright,\top \rangle\quad \langle k,j,\curvearrowright,\bot \rangle}
{\langle i,j,\curvearrowright,\top \rangle} \quad complete(\curvearrowright) \, s.c. (k < j)
\end{displaymath}
\begin{displaymath}
\frac{\langle i,k,\curvearrowleft,\bot \rangle\quad \langle k,j,\curvearrowleft,\top \rangle}
{\langle i,j,\curvearrowleft,\top \rangle} \quad complete(\curvearrowleft) \, s.c. (k < j)
\end{displaymath}

\paragraph{Estimation des poids} L'analyse syntaxique par factorisation des
arcs ({\em arc factored parsing}) suppose que le score d'un arbre se
décompose comme la somme des scores de ses arcs~:
\begin{equation}
\label{eq-arc-factored}
\Psi({\mathbf{y}}) = \sum_{(i,j) \in \mathbf{y}} \psi(\mathbf{x},i,j)
\end{equation}
On peut en principe utiliser n'importe quelle méthode d'apprentissage 
structurée (perceptron, large marge ou {\sc crf}) 
pour réaliser l'estimation de poids à partir de données.

Comme pour la plupart des algorithmes d'analyse syntaxique, 
l'estimation des poids par un {\sc crf} est un processus relativement
lourd en pratique (mais pas impossible en théorie). Par conséquent, on présente ici une variante de
l'algorithme du perceptron qui permet d'estimer les poids à partir
d'un treebank de référence.

On suppose qu’un corpus annoté $C = \mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$ est un
exemplaire de $N$ phrases où chaque séquence de mots $\mathbf{x}_i$
est associée à un arbre de référence $\mathbf{y}_i$.
L'algorithme \ref{perceptron-eisner} est un variante de l'algorithme
du perceptron vu précédemment qui tire parti de la décomposition
en arcs de l'arbre de dépendances telle que posée en équation (\ref{eq-arc-factored}).

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{arc-factored-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{\mathbf{y}} \gets \mathop{\text{argmax}}_{\mathbf{y}\in
  \mathbf{Y}} 
\sum_{(i,j) \in \mathbf{y}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,i,j)$
\Comment{Parsing}
\If{$\hat{\mathbf{y}} \not = \mathbf{y}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[ \sum_{(i,j) \in \mathbf{y}_i} \boldsymbol\Phi(\mathbf{x}_i,i,j) 
       - \sum_{(i,j) \in
         \hat{\mathbf{y}}}\boldsymbol\Phi(\mathbf{x}_i,i,j)   \right]$ 
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{perceptron-eisner}Perceptron pour l'analyse factorisée
en arcs}
\end{algorithm}



\section{Exercices}
\begin{itemize}
\item Add I/O and eval functions
\item Add dependency Labels
\item Add bi-LSTM tagger input (and switch to feed forward scorer ?)
\item Error analysis
\end{itemize}




\chapter{Approximations par modèles locaux}

Motivation = réduire temps d'entrainement.

\section{Modèles markoviens à maximum d'entropie}
\section{Perceptrons locaux}
\section{Modèles à oracles dynamiques}


\appendix
\chapter{Représentations pour les modèles creux}
\section{Représentation des matrices de poids}

\subsection{Représentation explicite de la matrice de poids}

Pour des modèles multiclasses à features,
l'opération primitive consiste à scorer chaque classe de l'ensemble $\{a,b,c\ldots\}$ à l'aide du vecteur creux de features $\boldsymbol\Phi(x)$ et du vecteur de poids $\mathbf{w}_i$ correspondant à la classe $i$. Ainsi le score de la classe $i$ sera calculé comme suit~:
\begin{displaymath}
s_i =  \mathbf{w}_i \cdot \boldsymbol\Phi(x)
\end{displaymath}
Comme on souhaite en général donner un score à toutes les classes, on peut organiser les poids en matrice $\mathbf{W}$ dont chaque ligne représente les poids destinés à donner la pondération spécifique à une classe donnée, de telle sorte que le vecteur de scores $\mathbf{s} = \mathbf{W}\cdot \boldsymbol\Phi(x)$ se calcule en une opération.
On illustre cette représentation ci-dessous~:
\begin{center}
\begin{tikzpicture}
\matrix(S)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]} ] at (0,0)
{
	s_a\\s_b\\s_c\\
};
\node[shape=circle,draw=white] (X) at (1.25,0) {=};
\matrix(A)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]}] at (4,0)
{
 w_{a1} & w_{a2} & \ldots & w_{ap}\\
 w_{b1} & w_{b2} & \ldots & w_{bp}\\
 w_{c1} & w_{c2} & \ldots & w_{cp}\\
};
\matrix(V)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]}] at (8,0)
{
 \phi_{1}(x) \\ \phi_{2}(x) \\ \vdots \\ \phi_{p}(x)\\
};
\end{tikzpicture}
\end{center}
On aura alors que le score $s_i$ de la classe $i$ sera donné en position $i$ dans $\mathbf{s}$.

Il faut remarquer que le vecteur $\boldsymbol\Phi(x) = \phi_1(x) \ldots \phi_p(x)$ est valué par des fonctions features qui valent 0 dans la plupart des cas et 1 dans de rares cas. 
Par  conséquent $\boldsymbol\Phi(x)$ est un vecteur creux.



\subsection{Représentation de la matrice de poids par un vecteur}

{\bf dire que ce cas s'applique aux problèmes structurés où
  l'ensemble $Y$ est très large ou infini (récursivement énumérable)}


Dans un contexte ou le vecteur $\boldsymbol\Phi(x)$
est un vecteur creux de très grande dimensionnalité, 
on utilise couramment une représentation alternative qui consiste à coder la matrice $\mathbf{W}$ dans un vecteur $\mathbf{w}$ unique. Dans ce contexte le vecteur 
de features sera valué à 1 uniquement pour certaines features de la forme $\phi_{y1},\phi_{y2}\ldots \phi_{yp}$ qui correspondent aux poids de la classe $y$ pour la feature $i$. Dans ce contexte le vecteur de features est noté $\boldsymbol\Phi(x,y)$ où $y$ indique la classe pour laquelle on calcule le score.
Ainsi pour calculer le score $s_a$ de la classe $a$,  on réalisera un produit scalaire avec une représentation du type~:
\begin{center}
\begin{tikzpicture}
\matrix(W)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]}] at (-1,0)
{
 w_{a1} & w_{a2} & \ldots & w_{ap}& w_{b1} & w_{b2} & \ldots & w_{bp}&  w_{c1} & w_{c2} & \ldots & w_{cp}\\
};
\matrix(V)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]} ]at (5.5,0)
{
 \phi_{a1}(x) \\ \phi_{a2}(x) \\ \vdots \\ \phi_{ap}(x)\\
};
\end{tikzpicture}
\end{center}
où seules certaines features de la forme $\phi_{a\cdot}$ sont valuées à 1 alors que les features de la forme $\phi_{b\cdot}$ et $\phi_{c\cdot}$ sont implicitement valuées à 0.

\section{Exemple de structure de données}

Une large classe de modèles d'apprentissage utilisés en \ac{tal}
fait intervenir des modèles creux. Il s'agit de modèles où le vecteur 
$\boldsymbol\Phi(x,y) \in \{0,1\}^d$ est un vecteur booléen de très grande dimension.
Les scores calculés par ces modèles sont essentiellement des produits scalaires de la forme :
\begin{displaymath}
s = \mathbf{w}\cdot \boldsymbol\Phi(x,y)
\end{displaymath}
où $\mathbf{w} \in \mathbb{R}^d$ est un vecteur de poids de dimension identique à $\boldsymbol\Phi(x,y)$. Dans ce contexte l'évaluation d'un produit scalaire revient à sommer les poids des features actives (mises à 1). 

Les autres opérations importantes est la mise à jour des poids lors de la descente de gradient, ce qui demande d'additionner (ou de soustraire) le vecteur de poids courant avec le vecteur gradient.

La structure de données ci-dessous exprimée en python apporte une fonction de produit scalaire ({\sl dot}) à partir des valeurs discrètes de $(x,y)$. Pour les mises à jour, elle propose une fonction de codage {\sl code$\_$phi} qui code une liste de valeurs discrète $x$ et renvoie $\boldsymbol\Phi(x)$ ainsi que des opérateurs arithmétiques de vecteurs et de scalaires ($+,-,\times, / , +=$).
Celle-ci peut-être étendue à d'autres usages, par exemple la surcharge d'opérateurs arithmétiques pour vecteurs et scalaires peut être complétée.

La structure de donnée reste néanmoins exprimée dans le but pédagogique de rester facile à lire et à modifier mais réalise la plupart des opérations de manière peu efficace.  Pour privilégier l'efficacité, il est suggéré de s'appuyer sur des librairies numériques qui supportent les opérations creuses ou de réaliser des interfaces avec du code {\sl C} ou {\sl C++} spécialisé pour réaliser les opérations sur des vecteurs creux.


\begin{minted}{python}
from collections import defaultdict

class SparseWeightVector:

    def  __init__(self):
    
        self.weights = defaultdict(int)   

    def __call__(self,x_key,y_key):
        """
        This returns the weight of a feature couple (x,y)
        Enables an  x = w('a','b') syntax.
        
        @param x_key: a tuple of observed values
        @param y_key: a string being a class name
        @return : the weight of this feature
        """
        return self.weights[(x_key,y_key)]

    def dot(self,xvec_keys,y_key):
        """
        This computes the dot product : w . Phi(x,y).
        Phi(x,y) is implicitly  generated by the function given (x,y)
        @param xvec_keys: a list (vector) of x values
        @param y_key    : a y class name
        @return  w . Phi(x,y)
        """
        return sum([self.weights[(x_key,y_key)] for x_key in xvec_keys])
        
    @staticmethod
    def code_phi(xvec_keys,ykey):
        """
        Explictly generates a sparse boolean Phi(x,y) vector from (x,y) values
        @param xvec_keys:  a list of symbols
        @param ykey: a y class name
        """
        w = SparseWeightVector()
        for xkey in xvec_keys:
            w[(xkey,ykey)] = 1.0
        return w

    def __getitem__(self,key):
        """
        This returns the weight of feature couple (x,y) given as value.
        Enables the 'x = w[]' syntax.	
        
        @param key: a couple (x,y) of observed and class value
        @return : the weight of this feature
        """
        return self.weights[tuple(key)]

    def __setitem__(self,key,value):
        """
        This sets the weight of a feature couple (x,y) given as key.
        Enables the 'w[] = ' syntax.	
        @param key:   a couple (x,y) of observed value and class value
        @param value: a real
        """
        self.weights[key] = value

    def __add__(self,other):
	    """
        Vector addition
        """
        weights =  self.weights.copy() 
        for key,value in other.weights.items() :
            weights[key] += value
        w = SparseWeightVector()
        w.weights = weights
        return w
        
    def __sub__(self,other):
    	"""
        Vector substraction
        """
        weights =  self.weights.copy() 
        for key,value in other.weights.items() :
            weights[key] -= value
        w = SparseWeightVector()
        w.weights = weights
        return w
        
    def __mul__(self,scalar):
    	"""
        Scalar multiplication
        """
        weights =  self.weights.copy() 
        for key,value in self.weights.items() :
            weights[key] *= scalar
        w = SparseWeightVector()
        w.weights = weights
        return w

    def __rmul__(self,scalar):
    	"""
        commutativity of scalar multiplication
        """
        return self.__mul__(scalar)
        
        
    def __truediv__(self,scalar):
    	"""
        Python 3 division '/'
        """
        weights =  self.weights.copy() 
        for key,value in self.weights.items() :
            weights[key] /= scalar
        w = SparseWeightVector()
        w.weights = weights
        return w

    
    def __iadd__(self,other):    
        """
        Sparse Vector inplace addition. Enables the '+=' operator.	
        @param  other: a  SparseVectorModel object
        """
        for key,value in other.weights.items():
            self.weights[key] += value
        return self
    def __isub__(self,other):    
        """
        Sparse Vector inplace substraction. Enables the '-=' operator.	
        @param  other: a  SparseVectorModel object
        """
        for key,value in other.weights.items():
            self.weights[key] -= value
        return self
            
    def load(self,istream):
        """
        Loads a model parameters from a text stream
        @param istream: an opened text stream
        """
        self.weights =  defaultdictionary(int)
        for line in istream:
            fields = line.split() 	
            key,value = tuple(fields[:-1]),float(fields[-1])
            self.weights[key] =  value
        
    def save(self,ostream):
        """
        Saves model parameters to a text stream
        @param ostream: an opened text output stream
		"""
        for key,value in self.weights.items():
            print(' '.join(list(key)+[str(value)]),file=ostream)

    def __str__(self):
        """
        Pretty prints the weights vector on std output.
        May crash if vector is too wide/full
        """
        s = ''
        for key,value in self.weights.items():
            X,Y = key
            if isinstance(X,tuple):
                s += 'phi(%s,%s) = 1 : w = %f\n'%('&'.join(X),Y,value)
            else:
                s += 'phi(%s,%s) = 1 : w = %f\n'%(key,Y,value)
        return s
\end{minted}


\end{document}