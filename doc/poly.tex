%% The openany option is here just to remove the blank pages before a new chapter
\documentclass[11pt,openany]{book}

\title{Analyse syntaxique automatique du langage naturel}

\usepackage{pagenote}
%\usepackage[usenames]{xcolor}
\usepackage{booktabs}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{mathabx}
\usepackage{bbm}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{pgfplots}
\usetikzlibrary{snakes}
\usetikzlibrary{matrix}
\usetikzlibrary{shapes}
\usetikzlibrary{calc}
\usepackage{comment}
\usepackage{minted}
\usepackage{tikz-dependency}%dependency trees
\usepackage{forest}


\newtheorem{definition}{Définition}[chapter]
\newtheorem{exo}{Exercice}[chapter]
\includecomment{solution}
%\excludecomment{solution}


%%%%%%%%%%%%% For customising the endnote markers. Comment these out if you don't want them.
% To prefix each note number with the chapter number
\renewcommand{\thepagenote}{\thechapter-\arabic{pagenote}}

% To have a slightly different formatting for the endnote numbers in the text -- smaller text, sans-serif, square brackets
\renewcommand\notenumintext[1]{\space{\footnotesize\sffamily[FN-#1]}}

% To have a slightly different formatting for the endnote numbers in the notes section. Just the square brackets and sans-serif; normal size.
\renewcommand\notenuminnotes[1]{{\sffamily[FN-#1] }}

% If you want a different name/heading for the end notes
\renewcommand{\notesname}{End Notes}
%%%%%%%%%%%%% End customisation


%% THIS LINE IS MANDATORY
\makepagenote

\usepackage{hyperref}
\usepackage{tikz}

\newcommand{\ac}[1]{{\sc #1}} %acronym
\newcommand{\kw}[1]{{\bf #1}} %keyword

\begin{document}

\chapter*{Plan et Notations}

\paragraph{Plan}
\begin{enumerate}
\item Algorithmes de recherche de solutions (séquences ; arbres)
\item Méthodes de prédiction discriminante non structurées (rappels + descente de gradient)
\item Méthodes de prédiction de séquences (pos tagging)
\begin{enumerate}
\item Perceptron structuré
\item Champs conditionnels aléatoires
\item Prédiction stucturée avec des modèles locaux (MEMM, NN)
\end{enumerate}
\item Méthodes de prédiction d'arbres (analyse syntaxique)
\begin{enumerate}
\item Analyse en constituants
\item Analyse en dépendances
\end{enumerate}
\end{enumerate}

\paragraph{Support de cours}
\url{https://github.com/bencrabbe/parsing-at-diderot}


\paragraph{\'Evaluation}

TP Kaggle


\paragraph{Pseudo Code}

\begin{description}
\item $X|Y$ concatène les listes $X$ et $Y$
\item $x_i$ le $i$-ème élément de la liste $X$
\item $_{\ominus}X$ la liste $X$ sans son premier élément
\item $X_{\ominus}$ la liste $X$ sans son dernier élément
\end{description}
 

\url{http://www-users.cs.umn.edu/~karypis/parbook/Lectures/AG/chap12_slides.pdf}
\url{http://www.aclweb.org/anthology/C08-5001}
\url{http://www.cs.columbia.edu/~mcollins/}






\chapter{Aspects algorithmiques}

\section{Prédiction de séquences}
Un nombre important de problèmes de traitement automatique des langues (\ac{Tal}) peuvent se formaliser comme des problèmes de recherche de chemin le plus long (ou parfois le plus court) dans un graphe acyclique orienté (\ac{Dag}).

Un exemple intuitif est le problème d'étiquetage de séquences appelé étiquetage morphosyntaxique. \'{E}tant donnée une séquence de $n$ mots $w_1\ldots w_n$,  on se donne pour tâche de prédire leurs parties de discours $t_1\ldots t_n$. 

En première approche, on peut considérer deux méthodes pour  étiqueter des séquences de mots~: d'une part on peut envisager étiqueter chaque mot $w_i$ par une étiquette $t_i$ en fonction du contexte $C$ où il apparaît à l'aide d'une fonction $f: W, C \mapsto T$ (où $W$ dénote un ensemble de mots, $C$ un ensemble de contextes\footnote{Typiquement un élément de $C$ sera un tuple de mots qui sont situés à gauche et à droite de $w_i$} et $T$ un ensemble de parties de discours). La première approche met en jeu  un {\bf modèle local} qui prédit  chacune des étiquettes $t_i$ indépendamment de toute autre étiquette $t_j\, (i\not = j)$.

L'approche alternative, dite globale et qui fait intervenir un {\bf modèle structuré} cherche à prédire la séquence de tags $t_1\ldots t_n$ en une fois.  La fonction de prédiction est de la forme $f:W^n \mapsto T^n$, autrement dit elle envoie une séquence de $n$ mots sur des séquences d'étiquettes de $n$ tags.  Utiliser cette seconde alternative  revient à supposer que les séquences forment une structure intéressante pour la prédiction. Ainsi un modèle local
peut faire des erreurs pour prédire le tag $t_i$ qui sont liées à l'ignorance des prédictions 
faites pour les tags avoisinants (comme par exemple $t_{i-1},t_{i-2}$\ldots). 

\begin{center}
\begin{tabular}{ccc}\toprule
\multicolumn{3}{c}{Prédiction globale ?}\\\midrule
D & A & N\\
Le & grand & est\\\bottomrule
\end{tabular}
\begin{tabular}{ccc}\toprule
\multicolumn{3}{c}{Prédiction locale ?}\\\midrule
D & A & {\bf\color{red} V}\\
Le & grand & est\\\bottomrule
\end{tabular}
\end{center}

Le problème de prédiction globale ou structurée est plus complexe que le problème de prédiction locale. En effet pour un jeu de tags $T$ un modèle local doit choisir $n$ fois parmi $|T|$ alternatives pour étiqueter une phrase,  alors qu'un modèle global doit choisir parmi un ensemble de $|T|^n$ alternatives, ce qui a un coût~: réaliser ce choix naïvement demande d'enumérer un ensemble  exponentiel d'alternatives d'étiquetages de la phrase.

\paragraph{Fonction de pondération}
Réaliser le tagging d'une séquence de mots $\mathbf{w} =  w_1\ldots w_n$ demande de choisir une séquence de tags $\mathbf{t} = t_1\ldots t_n \in T^n$. 
Ce  choix s'appuie en général sur une \kw{fonction de pondération} $\sigma : T^n\times W^n \mapsto \mathbb{R}$ qui associe un score à toute séquence de tags.
La méthode de pondération permet alors d'ordonner les différentes séquences de tags en fonction du score qui leur est associé.  La \kw{fonction de décision} réalise le choix de la séquence à préférer en utilisant souvent une forme du type :
\begin{equation}
\label{eq-decision}
\hat{\mathbf{t}} = \mathop{\text{argmax}}_{\mathbf{t} \in T^n}\quad \sigma(\mathbf{t},\mathbf{w})
\end{equation}
Généralement la fonction de pondération est instanciée par une méthode d'apprentissage automatique. Indiquons également que le calcul de la solution de (\ref{eq-decision})  consiste essentiellement à résoudre un \kw{problème d'optimisation} de la forme :
\begin{equation}
\label{eq-combi-optim}
m = \mathop{\text{max}}_{\mathbf{t} \in T^n}\quad \sigma(\mathbf{t},\mathbf{w})
\end{equation}
à partir de là on tire généralement la solution de (\ref{eq-decision}) 
par effet de bord.

Ce qui distingue \ref{eq-combi-optim} d'un problème d'optimisation classique,
c'est qu'il s'agit de chercher une valeur optimale dans un ensemble énumérable de taille finie dont les valeurs sont structurées en séquences.
Bien que de taille finie, l'ensemble des solutions est en général de taille considérable de telle sorte qu'une méthode de recherche de solutions qui consiste à énumérer exhaustivement chacune des solutions est en général inutilisable.


\section{Arbre de recherche de solutions}

La recherche de solutions à des problèmes de type (\ref{eq-combi-optim}) 
peut s'exprimer sous la forme générale d'un problème de recherche~:
\begin{itemize}
\item Un espace de recherche qui est un ensemble $Q$ d'états
\item Un état initial $q_0 \in Q$ qui est l'état à partir duquel le tagger commence.    
\item Un ensemble $F\subseteq Q$ d'états finaux qui indique les états dans lequel le tagger a terminé.
\item Un ensemble $A$ d'actions, dans le cas d'un tagger la seule action possible est de tagguer le mot suivant. On définit un ensemble d'actions $A$ pour lequel chaque élément représente l'attribution d'un tag au mot suivant dans la phrase.
\item Un ensemble $T\subseteq Q\times Q \times A$ de transitions qui induit une structure d'arbre.
\item Une fonction de coût $\sigma$ ou de score qui représente le score d'une séquence d'états calculé depuis l'état initial. On suppose que toute transition  $(q_i,q_{i+1},a_i) \in T$ se voit attribuer un coût $\psi(q_i,q_{i+1},a_i)$ par une fonction $\psi: T \mapsto \mathbb{R}$. On pose par convention que le coût de la séquence de transitions qui mène à l'état $q_k$ est le produit des coûts des transitions qui la composent~: 
\begin{displaymath}
\sigma(q_k) = \prod_{0\leq i < k} \psi(q_i,q_{i+1},a_i)
\end{displaymath}
\end{itemize}
\begin{figure}[htbp]
\begin{tikzpicture}[xscale=2,yscale=2]

    \node[shape=circle,draw=black,double=red] (S) at (0,3) {S};
     \node[shape=circle,draw=black,double=red] (E) at (6,3) {E};


    \node[shape=circle,draw=black] (A1) at (1,1) {D};
    \node[shape=circle,draw=black] (B1) at (1,2) {N};
    \node[shape=circle,draw=black] (C1) at (1,3) {A};
    \node[shape=circle,draw=black] (D1) at (1,4) {P};
    \node[shape=circle,draw=black] (E1) at (1,5) {V};

 \draw [opacity=0.5](B1.east) -- (1.5,1.6) -- (1.5,2.4) -- cycle;
 \draw [opacity=0.5](C1.east) -- (1.5,3.4) -- (1.5,2.6) -- cycle;
 \draw [opacity=0.5](D1.east) -- (1.5,4.4) -- (1.5,3.6) -- cycle;
 \draw [opacity=0.5](E1.east) -- (1.5,5.4) -- (1.5,4.6) -- cycle;
 
    \node[shape=circle,draw=black] (A2) at (2,-1){D};
    \node[shape=circle,draw=black] (B2) at (2,0) {N};
    \node[shape=circle,draw=black] (C2) at (2,1) {A};
    \node[shape=circle,draw=black] (D2) at (2,2) {P};
    \node[shape=circle,draw=black] (E2) at (2,3) {V};

     \draw [opacity=0.5](A2.east) -- (2.5,-1.4) -- (2.5,-0.6) -- cycle;
     \draw [opacity=0.5](B2.east) -- (2.5,0.4) -- (2.5,-0.4) -- cycle;
     \draw [opacity=0.5](C2.east) -- (2.5,0.6) -- (2.5,1.4) -- cycle;
      \draw [opacity=0.5](D2.east) -- (2.5,2.4) -- (2.5,1.6) -- cycle;
       \draw [opacity=0.5](E2.east) -- (2.5,3.4) -- (2.5,2.6) -- cycle;
     
      \draw [->,decorate,decoration={snake,amplitude=.8mm,segment length=2mm,post length=1mm},opacity=0.5](2,5)  --  (E.west);
      \draw [->,decorate,decoration={snake,amplitude=.8mm,segment length=2mm,post length=1mm},opacity=0.5](3,3)  --  (E.west);
      \draw [->,decorate,decoration={snake,amplitude=.8mm,segment length=2mm,post length=1mm},opacity=0.5](3,-1)  --  (E.west);

	 \draw [->,ultra thick,opacity=0.5] (S) -- (A1);
	 \draw [->,opacity=0.5] (S) -- (B1);
	 \draw [->,opacity=0.5] (S) -- (C1);
	 \draw [->,opacity=0.5] (S) -- (D1);
	 \draw [->,opacity=0.5] (S) -- (E1);

     \draw [->,opacity=0.5] (A1) -- (A2);
	 \draw [->,opacity=0.5] (A1) -- (B2);
	 \draw [->,ultra thick,opacity=0.5] (A1) -- (C2);
	 \draw [->,opacity=0.5] (A1) -- (D2);
	 \draw [->,opacity=0.5] (A1) -- (E2);



 \node[draw=white,text depth=0.25ex,text height=1cm] (W1) at (1,-2) {La} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W2) at (2,-2) {belle} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W3) at (3,-2) {porte} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W4) at (4,-2) {le} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W5) at (5,-2) {cache} ;

\end{tikzpicture}
\caption{\label{fig-searchtree}Arbre de recherche de solutions}
\end{figure}
On peut illustrer la  structure d'un problème de recherche par un arbre comme en figure \ref{fig-searchtree} pour un problème d'étiquetage morphosyntaxique (les scores sont omis). En fait un nombre très important de problèmes de \ac{tal} peut s'analyser en termes de problème de recherche de solutions dans de grands ensembles à valeurs structurées. On verra qu'on peut ainsi définir des variantes quant à la nature des états, du système de transition, des actions et que la fonction de coût dépend en général de la méthode d'apprentissage utilisée. 
\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{MaxSearch}{$q$}
\If{$q \not\in F$}
\State maxscore $\gets 0$
\State hist $\gets \epsilon$
\ForAll{$(q,q',a) \in T$}
\State  (suffscore, hist) $\gets$ \Call{MaxSearch}{$q'$}
\State suffscore $\gets \psi(q,q',a) \,\times$ suffscore
\If{suffscore $>$ maxscore}
\State maxscore $\gets$ suffscore
\State hist $\gets$ a $|$ hist 
\EndIf
\EndFor
\State\Return (maxscore,hist)
\Else
  \State\Return ($1$,$\epsilon$)
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-searchtree}Algorithme de recherche structuré en arbre (cas du tagger)}
\end{algorithm}
En principe, quand l'arbre de recherche a une taille raisonnable, l'exploration des solutions peut se faire exhaustivement.  Mais en pratique cette première solution est en général utilisée rarement telle quelle~: on utilise plutôt des méthodes de programmation dynamique, de recherche approximative ou une combinaison des deux.

On  donne en algorithme \ref{algo-searchtree},
un exemple d'algorithme de recherche pour un problème structuré en arbre. On peut notamment constater que la structure d'arbre de recherche n'est pas exprimée par une structure de donnée explicite mais plutôt implicitement par la structure d'appels récursifs du programme. Comme exercice, il peut être intéressant de repérer les différentes composantes du problème de recherche dans le pseudo-code  (Algorithme \ref{algo-searchtree}).



\begin{exo}Réécrire l'algorithme de parcours d'arbre de recherche
pour que le résultat renvoyé soit maintenant un couple qui comporte la valeur de score maximale mais aussi la séquence de tags correspondante
\end{exo}






\section{Systèmes de transitions}

Pour spécifier explicitement un problème de recherche de solutions en \ac{tal}, on utilise fréquemment une spécification sous forme de système de transitions. Ce type de spécification a été popularisé par la tâche d'analyse syntaxique en dépendances.  Mais celle-ci est très générale, on trouve ce type de systèmes également pour spécifier des problèmes de planification en intelligence artificielle et (parfois) des méthodes de démonstration automatique. 

On propose de les introduire immédiatement par un premier exemple qui caractérise explicitement une tâche de tagging. Spécifier un système de transitions revient à spécifier chacun des éléments suivants~:
\begin{itemize}
\item L'ensemble $Q$ des états est structuré. Chaque état $q\in Q$ est un couple $(S,B)$ où $S$ est une séquence de tags déjà prédits et $B$ une séquence de mots encore à traiter dans la phrase. 
\item L'état initial $q_0$ est l'état $(\epsilon , B)$ où $B$ est la liste des mots de la phrase à étiqueter.
\item L'ensemble des états finaux est l'ensemble $F$ des états tels que $B$ est vide. 
\item L'ensemble $A$ des actions est l'ensemble qui représente le jeu de tags $t\in A$ utilisé par le tagger.
\item L'ensemble $T$ des transitions est la relation
entre états qui satisfait le critère suivant~: 
\begin{displaymath}
(S,b_0|B) \stackrel{t}{\Rightarrow}(S|t,B)\qquad (t \in A)
\end{displaymath}
Ce qui signifie que le premier mot de $B$ est enlevé; le tag qui correspond à l'action exécutée est ajouté à $S$.
\item Le coût local d'une transition $\psi(S,B,t)$ est calculé par un modèle d'apprentissage approprié. 
\end{itemize}

Notons que les systèmes de transitions peuvent servir à exprimer des automates et des transducteurs à nombre finis d'états ou des contreparties d'automates à pile. Mais il est commun en \ac{tal} de ne pas limiter l'usage des systèmes de transition au seul encodage de ce type de machines.

\begin{exo}
Définir une variante de ce système de transition qui permet à un tagger d'accéder également aux mots qui précèdent dans la phrase avec la fonction de score $\psi(S,B,t)$ ou une de ses variantes. 
\end{exo}
\begin{exo}
Réécrire l'algorithme de parcours d'un arbre de recherche pour qu'il renvoie le poids de la solution de poids maximal à l'aide du système de transitions donné ci-dessus.
\end{exo}
\begin{solution}
\begin{algorithmic}[1]
\Function{MaxSearch}{S,B}
\If{$B \not = \epsilon$}
\State maxscore $\gets 0$
\State hist $\gets \epsilon$
\ForAll{$t \in A$}
\State  (suffscore, hist) $\gets$ \Call{MaxSearch}{$S|t$,$_{\ominus}B$}
\State suffscore $\gets \psi(S,B,t) \,\times$ suffscore
\If{suffscore $>$ maxscore}
\State maxscore $\gets$ suffscore
\State hist $\gets$ t $|$ hist 
\EndIf
\EndFor
\State\Return (maxscore,hist)
\Else
  \State\Return ($1$,$\epsilon$)
\EndIf
\EndFunction
\end{algorithmic}
\end{solution}
\begin{exo}
Modifier la formulation de l'exercice précédent pour faire en sorte qu'il renvoie la séquence de tags ainsi que le poids de cette solution
\end{exo}

Lorsque l'espace des solutions est trop grand (ce qui est généralement le cas pour la plupart des problèmes de \ac{tal}) l'algorithme naïf de recherche vu jusqu'à présent, qui a une complexité exponentielle en $\mathcal{O}(A^n)$ est inutilisable. On se tourne alors vers des solutions qui s'appuient sur de la programmation dynamique (Section \ref{sec-DP}) ou des solutions  de recherche approximative ou une combinaison des deux.


\section{Les méthodes de recherche approximatives}

Si il existe des algorithmes comme Viterbi et Dijkstra (et
A$\star$, sections \ref{sec-DP}, \ref{sec-viterbi},\ref{sec-dijkstra}) qui sont conçus pour donner une solution optimale au problème de
recherche du chemin de poids maximal (resp. minimal)
et que ces algorithmes ont une complexité polynomiale --~considérée
comme acceptable~-- ces algorithmes sont potentiellement lents lorsque
les phrases sont longues où lorsque l'espace des états est de taille
considérable. Par exemple, Viterbi a une complexité en ${\cal
  O}(NK^2)$, lorsque la taille du jeu de tags $K$ est importante (ce
qui est notamment le cas pour des modèles dont l'historique est très riche)
les temps de calcul deviennent potentiellement prohibitifs.

Dans ce type de situation, on peut faire le choix d'utiliser des
méthodes de recherche de solutions qui ne garantissent pas
l'optimalité, comme la recherche gloutonne ou la recherche par
faisceau. Il s'agit de méthodes qui n'explorent qu'une petite partie
de l'espace de solutions et qui sont en général très efficaces.

Comme il s'agit de méthodes qui n'explorent qu'une toute petite
partie de l'espace des solutions (séquences de tags possibles)
celle-ci sont généralement utilisées en combinaison avec une fonction
de score très bien informée sur le problème à traiter de telle sorte que la
partie de l'espace explorée a, par hypothèse, de grandes chances de contenir la
solution optimale. 

On présente ici deux méthodes couramment utilisées~:  la recherche
gloutonne et la recherche par faisceau (beam) comme des variantes de
la méthode de recherche dans un arbre de solutions (Algorithme
\ref{algo-searchtree}) pour des systèmes de transitions. 
Mais ces méthodes pourraient également se formuler dans un contexte où l'espace de
recherche est représenté par un graphe.

\subsection{Recherche gloutonne}

La méthode de recherche gloutonne est le cas dégénéré de la méthode de
recherche du meilleur d'abord. \`A chaque itération, l'algorithme évalue
le score de tous les successeurs d'un état. C'est l'unique successeur
de meilleur score qui est sélectionné pour la suite de la recherche
(Algorithme \ref{algo-greedy-tree}).
\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{GreedySearch}{S,B,$\sigma$}
\If{$B \not = \epsilon$}
\State maxscore $\gets \bar{0}$
\State argmaxt $\gets \emptyset$ 
\ForAll{$t \in T$}
	\State localscore $\gets \sigma \times \psi(S,B,t)$
        \If {localscore $>$ maxscore} 
              \State maxscore $\gets$ localscore
              \State argmaxt $\gets$ t
        \EndIf
\EndFor
\State\Return \Call{GreedySearch}{$S|\text{argmaxt}$,$_{\ominus}$B, maxscore}
\Else
  \State\Return $\sigma$
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-greedy-tree}Algorithme de recherche glouton}
\end{algorithm}
Il est évident que cet algorithme donne des solutions approximatives
et sans garantie d'optimalité. Par contre la complexité de cet
algorithme, en ${\cal O}(n K)$,  est linéaire en temps. Autrement dit,
cet algorithme est très efficace à l'usage.

L'aspect approximatif de cet algorithme peut être contrebalancé
en utilisant des scores locaux  très bien choisis pour guider la recherche vers une solution proche de
l'optimum global. Ce
scénario est très utilisé à l'heure actuelle par les systèmes pondérés
par des réseaux de neurones profonds. Ceux-ci  obtiennent
empiriquement de très
bons résultats.

\begin{exo}
Augmenter l'algorithme \ref{algo-greedy-tree} pour qu'il renvoie
non seulement le score du chemin de poids maximal, mais aussi
la séquence de tags de ce chemin.
\end{exo}
\begin{exo}
Comparer le meilleur chemin renvoyé par l'algorithme glouton avec
celui 
renvoyé par l'algorithme de Viterbi à partir de l'exemple \ref{fig-viterbi-general-dag}.
\end{exo}

\subsection{Recherche par faisceau}

La recherche par faisceau est une extension de la méthode par recherche gloutonne.
La recherche par faisceau est un algorithme qui progresse
essentiellement en largeur dans l'arbre de recherche. \`A chaque itération il avance en
profondeur dans $|\mathcal{B}|$ branches de l'arbre jusqu'à atteindre les
feuilles, et ce sans jamais faire marche arrière.

Les $|\mathcal{B}|$ branches sélectionnées pour continuer l'exploration à l'étape
suivante constituent le faisceau. 
Le choix des branches destinées à continuer l'exploration 
est heuristique. Généralement on choisit les $|\mathcal{B}|$ branches qui ont le
plus haut score. 

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{BeamSearch}{$\mathcal{B}$}
\State $\mathcal{B}' \gets \emptyset$
\ForAll {$\langle S,B,\sigma\rangle \in \mathcal{B}$}
\If {$B = \epsilon$}\Comment{par hypothèse le faisceau est trié}
\State \Return $\sigma$
\EndIf
\ForAll{$t \in T$}
	\State localscore $\gets \sigma \times \psi(S,B,t)$
        \State $\mathcal{B'} \gets \mathcal{B}' \cup \{\langle
        S|t,_\ominus B,\text{localscore}\rangle\}$
\EndFor
\EndFor
\State $\mathcal{B} \gets$ \Call{$\mathcal{B}$-Select}{$\mathcal{B'}$}
\State \Return \Call{BeamSearch}{$\mathcal{B}$}
\EndFunction
\end{algorithmic}
\caption{\label{algo-beam-tree}Algorithme de recherche en faisceau}
\end{algorithm}
L'algorithme est donné en Algorithme \ref{algo-beam-tree}.
Notons que la fonction \ac{$\mathcal{B}$-Select} est chargée de sélectionner $|\mathcal{B}|$ éléments dans un
ensemble. Il s'agit dans la très grande généralité des cas
 de sélectionner les $|\mathcal{B}|$ éléments de scores les plus élevés 
 mais des variantes sont envisageables. Par exemple la recherche par faisceau
 stochastique consiste à sélectionner $|\mathcal{B}|$ éléments aléatoirement
 proportionnellement à leur score. 

L'intérêt de cette méthode est son efficacité~: la complexité reste faible~:
${\cal O}(n K |\mathcal{B}|)$, c'est-à-dire essentiellement linéaire.

On peut penser que le faisceau peut corriger les faiblesses de la méthode
gloutonne mais en pratique on observe souvent que les faisceaux
contiennet des hypothèses très similaires.
Comme la méthode gloutonne, l'algorithme de recherche en faisceau ne
garantit pas de renvoyer une solution optimale. 
En effet, une solution optimale qui a un mauvais score préfixe lors
des premières itérations ne sera plus jamais considérée. 

Il faut bien garder à l'esprit que cette méthode renvoie un
pseudo-résultat maximal, ce qui peut poser problème
 dans certains contextes d'utilisation (comme illustré en chapitre XX)

\begin{exo}
Augmenter l'algorithme \ref{algo-beam-tree} pour qu'il renvoie
non seulement le score du chemin de poids maximal, mais aussi
la séquence de tags de ce chemin.
\end{exo}


\section{Programmation dynamique}
\label{sec-DP}

Une des faiblesses de l'algorithme de recherche naïf de solutions
structuré en arbre (Algorithme \ref{algo-searchtree})  est qu'il
réplique une quantité très importante de calculs. 

Les solutions approximatives présentées jusqu'à présent
permettent d'éviter une reduplication outrancière des calculs
en limitant le nombre d'hypothèses explorées.
L'inconvénient est qu'elles ne garantissent pas l'optimalité de la
solution renvoyée. 

Les méthodes de programmation dynamique cherchent à renvoyer une
solution optimale au problème de recherche en évitant la reduplication
de calculs. On propose de motiver la technique par un exemple introductif
en considérant deux séquences de tags~:
\begin{center}
\begin{tabular}{ccccc}\toprule
D &A& N& Cl& V\\
D& N& N& Cl& V\\\midrule
La&belle&porte&le&cache\\\bottomrule
\end{tabular}
\end{center}
qui diffèrent par un élément.  On constate qu'une méthode de recherche
en arbre va recalculer au moins deux foix la valeur du suffixe {\sl N Cl V}. 
De manière générale la méthode de recherche de solutions en arbre reduplique une quantité considérable de calculs de suffixes, ce qui est largement inefficace.
\begin{center}
\begin{tikzpicture}[xscale=1.75,yscale=1.75]

\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
%\node[shape=circle,draw=black,double=red] (E) at (6,0) {E};
\node[shape=circle,draw=black] (A) at (1,0) {D};
\node[shape=circle,fill opacity=0.2,draw=black] (B2) at (2,-1) {N};
\node[shape=circle,fill opacity=0.2,draw=black] (B1) at (2,1){A};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (C2) at (3,-1) {N};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (C1) at (3,1){N};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (D2) at (4,-1) {Cl};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (D1) at (4,1){Cl};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (E2) at (5,-1) {V};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (E1) at (5,1){V};

\draw [->,opacity=0.5](S) -- (A);
\draw [->,opacity=0.5](A) -- (B1);
\draw [->,opacity=0.5](A) -- (B2);
\draw [->,opacity=0.5](B1) -- (C1);
\draw [->,opacity=0.5](B2) -- (C2);
\draw [->,opacity=0.5](C1) -- (D1);
\draw [->,opacity=0.5](C2) -- (D2);
\draw [->,opacity=0.5](D1) -- (E1);
\draw [->,opacity=0.5](D2) -- (E2);
\end{tikzpicture}
\end{center}
L'idée des méthodes de \kw{programmation dynamique}, c'est d'éviter les reduplications de calculs inutiles pour réutiliser des résultats intermédiaires (partage de calcul). Ainsi l'espace des états est organisé en  graphe (\ac{dag}) plutôt qu'en arbre. Cette nouvelle organisation permet de proposer des solutions algorithmiques en temps polynomial plutôt qu'en temps exponentiel aux problèmes de recherche qui nous concernent.

\begin{center}
\begin{tikzpicture}[xscale=1.75,yscale=1.75]

\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
%\node[shape=circle,draw=black,double=red] (E) at (6,0) {E};
\node[shape=circle,draw=black] (A) at (1,0) {D};
\node[shape=circle,fill opacity=0.2,draw=black] (B2) at (2,-1) {N};
\node[shape=circle,fill opacity=0.2,draw=black] (B1) at (2,1){A};
\node[shape=circle,fill=green,fill opacity=0.2,draw=black] (C) at (3,0) {N};
\node[shape=circle,fill=green,fill opacity=0.2,draw=black] (D) at (4,0) {Cl};
\node[shape=circle,fill=green,fill opacity=0.2,draw=black] (E) at (5,0) {V};

\draw [->,opacity=0.5](S) -- (A);
\draw [->,opacity=0.5](A) -- (B1);
\draw [->,opacity=0.5](A) -- (B2);
\draw [->,opacity=0.5](B1) -- (C);
\draw [->,opacity=0.5](B2) -- (C);
\draw [->,opacity=0.5](C) -- (D);
\draw [->,opacity=0.5](D) -- (E);
\end{tikzpicture}
\end{center}



\subsection{Graphe Acyclique orienté}

\begin{definition}[DAG] 
Un graphe acyclique orienté (\ac{dag}) est un graphe $G = \langle V,E \rangle$ où $V$ est un ensemble de noeuds et $E$ un ensemble d'arcs
($E \subseteq V\times V$) tel qu'il ne comporte pas de circuit.
Dans le cas pondéré, on  y ajoute une fonction $s: E \mapsto \mathbb{R}$
qui donne un score à chacun des arcs.
\end{definition}

\begin{definition}[Arc entrants] 
Soit un noeud $x\in V$, l'ensemble $AE(x) = \{(y,x) \,|\, (y,x) \in E , y \in V \}$ est l'ensemble des arcs entrants sur ce noeud. 
\end{definition}

\begin{definition}[Arc sortants] 
Soit un noeud $x\in V$, l'ensemble $AS(x) = \{(x,y) \,|\, (x,y) \in E , y \in V \}$ est l'ensemble des arcs sortants de ce noeud. 
\end{definition}

\begin{definition}[Chemin]
Un chemin de longeur $n$ est une séquence de noeuds $\pi \in V^n$ de la forme $\pi = v_1 v_2\ldots v_n$ tel que $(v_i,v_{i+1}) \in E$ pour tout $1\leq i < n$. Le score $\sigma(\pi)$ d'un chemin est le produit :
\begin{displaymath}
\sigma(\pi) = \prod_{i=1}^{n-1} \psi(v_i,v_{i+1}) 
\end{displaymath}
\end{definition}

\begin{definition}[Poids maximal depuis la source]
Soit un \ac{dag} dont un noeud distingué $s\in V$ est appelé noeud source. En notant $P(x)$ l'ensemble des chemins qui mènent de la source
à $x$, on définit le poids maximal de $x$ comme suit~: 
\begin{displaymath}
\delta(x)  = \left\{ 
\begin{array}{ll}
1 & \text{si } $x = s$ \\
\mathop{\text{max}}_{\pi \in P(x)} \sigma(\pi) &\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{definition}


\subsection{Mémorisation de résultats intermédiaires}
Un problème de programmation dynamique est typiquement formulé comme
un problème d'optimisation entre différentes alternatives~: il s'agit
par exemple de trouver un chemin de poids maximum parmi plusieurs
chemins pondérés. On illustre en figure \ref{fig-DP-dag-intro} un
exemple de structuration du problème de recherche en \ac{dag}.

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%deltas
% \node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
% \node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){135};
% \node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
% \node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
% \node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){15};
% \node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){20};
% \node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){40};
% \node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){45};
\end{tikzpicture}
\end{center}
\caption{\label{fig-DP-dag-intro}Exemple de \ac{dag} de programmation dynamique}
\end{figure}



Lorsque certains sous-problèmes sont à recalculer plusieurs fois, on  dit qu'il y a \kw{recouvrement de sous-problèmes}. Les techniques de programmation dynamique consistent à éviter l'évaluation multiple d'un même sous-problème en mémorisant les solutions intermédiaires.

Plusieurs techniques pour réaliser la mémorisation seront présentées
mais celles-ci font généralement appel à une table dite table de
programmation dynamique pour mémoriser les résultats
intermédiaires. Celle-ci mémorise les valeurs $\delta(x)$ des états
$x$ intermédiaires (noeuds du \ac{dag}) évalués lors de la résolution du problème.

Une solution directe pour exprimer cette idée est la technique dite de \kw{mémoisation}. Celle-ci repose sur l'usage de \kw{mémo-fonctions}. L'idée est de mémoriser la solution $\delta(x)$ dans une table dès que celle-ci est déterminée. Cette table est alors consultée dans les étapes ultérieures de l'algorithme de telle sorte que la valeur mémorisée est réutilisée au lieu de réexécuter l'appel récursif.

L'algorithme \ref{algo-searchMemo} illustre le principe de la mémoisation. On suppose que le \ac{dag} a un état final $q_f$, et que la table {\sl memo} est initialisée à $\delta(x) = 0$ pour tout  $x\in V$ (sauf $\delta(q_0) = 1$). La fonction est initialement appelée avec le paramètre $q_f$.  

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{MaxSearchMemo}{x}
\If{$\delta(x) \not = 0$}
\Comment{Score mémoisé}
\State\Return $\delta(x)$
\EndIf
\ForAll{$y \in AE(x)$}
\State $\delta(x)\gets$ \Call{Max}{}($\delta(x)$,\Call{MaxSearchMemo}{y} $\times \psi(y,x)$)
\EndFor
\State\Return $\delta(x)$
\EndFunction
\end{algorithmic}
\caption{\label{algo-searchMemo}Algorithme de recherche d'une valeur optimale mémoisé}
\end{algorithm}

On illustre en figure \ref{fig-viterbi-general-dag} le \ac{dag}
résultant de l'exécution de l'algorithme de mémoisation sur
le \ac{dag} donné en Figure \ref{fig-DP-dag-intro}. 

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%deltas
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){135};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){15};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){20};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){40};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){45};
\end{tikzpicture}
\end{center}
\caption{\label{fig-viterbi-general-dag}\ac{dag} annoté par $\delta(x)$}
\end{figure}


% \begin{center}
% \begin{tikzpicture}[xscale=2,yscale=2]
% \node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
% \node[shape=circle,draw=black,double=red] (E) at (4,0) {E};
% \node[shape=circle,draw=black] (1) at (1,1) {A};
% \node[shape=circle,draw=black] (2) at (3,1) {C};
% \node[shape=circle,draw=black] (3) at (2,0) {B};
% \draw [->,opacity=0.5](S) -- (1) node[midway,fill=white]{$s(S,A)$};
% \draw [->,opacity=0.5](S) -- (3) node[midway,fill=white]{$s(S,B)$};
% \draw [->,opacity=0.5](1) -- (3) node[midway,fill=white]{$s(A,B)$};
% \draw [->,opacity=0.5](1) -- (2) node[midway,fill=white]{$s(A,C)$};
% \draw [->,opacity=0.5](3) -- (2) node[midway,fill=white]{$s(B,C)$};
% \draw [->,opacity=0.5](2) -- (E) node[midway,fill=white]{$s(C,E)$};
% \draw [->,opacity=0.5](3) -- (E) node[midway,fill=white]{$s(B,E)$};
% \end{tikzpicture}
% \end{center}

% \begin{exo}Donner une valuation numérique aux arcs du \ac{dag} suivant et  simuler l'exécution de l'algorithme \ref{algo-searchMemo} sur papier.
% \begin{center}
% \begin{tikzpicture}[xscale=2,yscale=2]
% \node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
% \node[shape=circle,draw=black,double=red] (E) at (4,0) {E};
% \node[shape=circle,draw=black] (1) at (1,1) {A};
% \node[shape=circle,draw=black] (2) at (3,1) {C};
% \node[shape=circle,draw=black] (3) at (2,0) {B};
% \draw [->,opacity=0.5](S) -- (1) node[midway,fill=white]{$s(S,A)$};
% \draw [->,opacity=0.5](S) -- (3) node[midway,fill=white]{$s(S,B)$};
% \draw [->,opacity=0.5](1) -- (3) node[midway,fill=white]{$s(A,B)$};
% \draw [->,opacity=0.5](1) -- (2) node[midway,fill=white]{$s(A,C)$};
% \draw [->,opacity=0.5](3) -- (2) node[midway,fill=white]{$s(B,C)$};
% \draw [->,opacity=0.5](2) -- (E) node[midway,fill=white]{$s(C,E)$};
% \draw [->,opacity=0.5](3) -- (E) node[midway,fill=white]{$s(B,E)$};
% \end{tikzpicture}
% \end{center}
% \end{exo}
\begin{exo}
Reformuler l'algorithme \ref{algo-searchMemo} de telle sorte que le chemin optimal 
soit celui de poids minimum.  Simuler son exécution sur papier.
\end{exo}
\begin{exo}
Reformuler l'algorithme \ref{algo-searchMemo} en supprimant la conditionnelle qui réalise la mémoisation.  Tenter de le simuler sur papier.
\end{exo}

\section{Algorithme de Viterbi}
\label{sec-viterbi}

L'algorithme mémoisé présenté dans la section précédente peut se
reformuler par une version plus directe. C'est l'\kw{algorithme de Viterbi}.

\begin{definition}[Ordre topologique] Un ordre topologique sur un \ac{dag} $G=(V,E)$ est tout ordre total sur les noeuds $V$ de ce \ac{dag} tel que pour tout couple de noeuds $(x,y) \in E$,  $x \prec y$. Il existe en général plusieurs ordres topologiques valides pour un \ac{dag} donné.
\end{definition}

L'algorithme de Viterbi est un algorithme de recherche du chemin de
poids maximal dans un \ac{dag} (Figure \ref{algo-viterbi-general}). 
 En supposant un noeud source $s$ unique dont le poids $\delta(s)$ est
 initialisé à 1, l'algorithme parcourt le \ac{dag} en suivant l'ordre
 topologique. Chaque noeud est à son tour valué par le poids
 $\delta(s)$ du chemin maximal qui mène de la source jusqu'à ce
 noeud. Toute l'idée de l'algorithme consiste à mémoriser les poids
 $\delta(s)$ au fur et à mesure qu'ils sont calculés pour les
 réutiliser lors de calculs ultérieurs.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\delta(s) \gets 1$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\delta(s) \gets 0$
\ForAll {$(s',s) \in AE(s)$}
\State  $\delta(s) \gets \Call{Max}{\delta(s) , \delta(s')  \times \psi(s',s) $}
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-general}Algorithme de Viterbi}
\end{algorithm}

On donne en figure \ref{fig-viterbi-general-dag} un exemple de
résultat de l'exécution de l'algorithme sur un cas concret. Chacun des
noeuds du \ac{dag} est annoté (case bleue) par la valeur du $\delta(x)$
qui lui correspond.



\begin{exo}[Limitation aux \ac{dags}]
L'algorithme de Viterbi ne peut pas être utilisé si le graphe contient
au moins un cycle (le graphe n'est pas un \ac{dag}). Expliquer
pourquoi par un exemple.
\end{exo}
\begin{exo}[Extraction de la séquence de poids maximal]
Donner une extension de l'algorithme donné en figure
\ref{algo-viterbi-general} qui permet de renvoyer comme résultat non
seulement le score du chemin de poids maximal (plus long chemin) mais
aussi la séquence de tags de ce chemin.
\end{exo}


\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=1.5,yscale=1.5]
    \node[shape=circle,draw=black] (A1) at (1,1) {D};
    \node[shape=circle,draw=black] (B1) at (1,2) {N};
    \node[shape=circle,draw=black] (C1) at (1,3) {A};
    \node[shape=circle,draw=black] (D1) at (1,4) {P};
    \node[shape=circle,draw=black] (E1) at (1,5) {V};
     \node[shape=circle,draw=black] (A2) at (2,1) {D};
    \node[shape=circle,draw=black] (B2) at (2,2) {N};
    \node[shape=circle,draw=black] (C2) at (2,3) {A};
    \node[shape=circle,draw=black] (D2) at (2,4) {P};
    \node[shape=circle,draw=black] (E2) at (2,5) {V};
     \node[shape=circle,draw=black] (A3) at (3,1) {D};
    \node[shape=circle,draw=black] (B3) at (3,2) {N};
    \node[shape=circle,draw=black] (C3) at (3,3) {A};
    \node[shape=circle,draw=black] (D3) at (3,4) {P};
    \node[shape=circle,draw=black] (E3) at (3,5) {V};
     \node[shape=circle,draw=black] (A4) at (4,1) {D};
    \node[shape=circle,draw=black] (B4) at (4,2) {N};
    \node[shape=circle,draw=black] (C4) at (4,3) {A};
    \node[shape=circle,draw=black] (D4) at (4,4) {P};
    \node[shape=circle,draw=black] (E4) at (4,5) {V};
     \node[shape=circle,draw=black] (A5) at (5,1) {D};
    \node[shape=circle,draw=black] (B5) at (5,2) {N};
    \node[shape=circle,draw=black] (C5) at (5,3) {A};
    \node[shape=circle,draw=black] (D5) at (5,4) {P};
    \node[shape=circle,draw=black] (E5) at (5,5) {V};
    \node[draw=white,text depth=0.25ex,text height=1cm] (W1) at (1,0) {La} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W2) at (2,0) {belle} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W3) at (3,0) {porte} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W4) at (4,0) {le} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W5) at (5,0) {cache} ;
    \node[shape=circle,draw=black,double=red] (S) at (0,3) {S};
 \node[shape=circle,draw=black,double=red] (E) at (6,3) {E};

 \draw [->,ultra thick,opacity=0.5] (S) -- (A1);
 \draw [->,opacity=0.5] (S) -- (B1);
 \draw [->,opacity=0.5] (S) -- (C1);
 \draw [->,opacity=0.5] (S) -- (D1);
 \draw [->,opacity=0.5] (S) -- (E1);
 
 \draw [->,opacity=0.5] (A1) -- (A2);
 \draw [->,opacity=0.5] (A1) -- (B2);
 \draw [->,ultra thick,opacity=0.5] (A1) -- (C2);
 \draw [->,opacity=0.5] (A1) -- (D2);
 \draw [->,opacity=0.5] (A1) -- (E2);

\draw [->,opacity=0.5] (B1) -- (A2);
 \draw [->,opacity=0.5] (B1) -- (B2);
 \draw [->,opacity=0.5] (B1) -- (C2);
 \draw [->,opacity=0.5] (B1) -- (D2);
 \draw [->,opacity=0.5] (B1) -- (E2);

\draw [->,opacity=0.5]  (C1) -- (A2);
 \draw [->,opacity=0.5] (C1) -- (B2);
 \draw [->,opacity=0.5] (C1) -- (C2);
 \draw [->,opacity=0.5] (C1) -- (D2);
 \draw [->,opacity=0.5] (C1) -- (E2);

\draw [->,opacity=0.5]  (D1) -- (A2);
 \draw [->,opacity=0.5] (D1) -- (B2);
 \draw [->,opacity=0.5] (D1) -- (C2);
 \draw [->,opacity=0.5] (D1) -- (D2);
 \draw [->,opacity=0.5] (D1) -- (E2);
 
 \draw [->,opacity=0.5]  (E1) -- (A2);
 \draw [->,opacity=0.5] (E1) -- (B2);
 \draw [->,opacity=0.5] (E1) -- (C2);
 \draw [->,opacity=0.5] (E1) -- (D2);
 \draw [->,opacity=0.5] (E1) -- (E2);
 
 \draw [->,opacity=0.5] (A2) -- (A3);
 \draw [->,opacity=0.5] (A2) -- (B3);
 \draw [->,opacity=0.5] (A2) -- (C3);
 \draw [->,opacity=0.5] (A2) -- (D3);
 \draw [->,opacity=0.5] (A2) -- (E3);

\draw [->,opacity=0.5] (B2) -- (A3);
 \draw [->,opacity=0.5] (B2) -- (B3);
 \draw [->,opacity=0.5] (B2) -- (C3);
 \draw [->,opacity=0.5] (B2) -- (D3);
 \draw [->,opacity=0.5] (B2) -- (E3);

\draw [->,opacity=0.5]  (C2) -- (A3);
 \draw [->,ultra thick,opacity=0.5] (C2) -- (B3);
 \draw [->,opacity=0.5] (C2) -- (C3);
 \draw [->,opacity=0.5] (C2) -- (D3);
 \draw [->,opacity=0.5] (C2) -- (E3);

\draw [->,opacity=0.5]  (D2) -- (A3);
 \draw [->,opacity=0.5] (D2) -- (B3);
 \draw [->,opacity=0.5] (D2) -- (C3);
 \draw [->,opacity=0.5] (D2) -- (D3);
 \draw [->,opacity=0.5] (D2) -- (E3);
 
 \draw [->,opacity=0.5]  (E2) -- (A3);
 \draw [->,opacity=0.5] (E2) -- (B3);
 \draw [->,opacity=0.5] (E2) -- (C3);
 \draw [->,opacity=0.5] (E2) -- (D3);
 \draw [->,opacity=0.5] (E2) -- (E3);

 \draw [->,opacity=0.5] (A3) -- (A4);
 \draw [->,opacity=0.5] (A3) -- (B4);
 \draw [->,opacity=0.5] (A3) -- (C4);
 \draw [->,opacity=0.5] (A3) -- (D4);
 \draw [->,opacity=0.5] (A3) -- (E4);

\draw [->,opacity=0.5] (B3) -- (A4);
 \draw [->,opacity=0.5] (B3) -- (B4);
 \draw [->,opacity=0.5] (B3) -- (C4);
 \draw [->,ultra thick,opacity=0.5] (B3) -- (D4);
 \draw [->,opacity=0.5] (B3) -- (E4);

\draw [->,opacity=0.5]  (C3) -- (A4);
 \draw [->,opacity=0.5] (C3) -- (B4);
 \draw [->,opacity=0.5] (C3) -- (C4);
 \draw [->,opacity=0.5] (C3) -- (D4);
 \draw [->,opacity=0.5] (C3) -- (E4);

\draw [->,opacity=0.5]  (D3) -- (A4);
 \draw [->,opacity=0.5] (D3) -- (B4);
 \draw [->,opacity=0.5] (D3) -- (C4);
 \draw [->,opacity=0.5] (D3) -- (D4);
 \draw [->,opacity=0.5] (D3) -- (E4);
 
 \draw [->,opacity=0.5] (E3) -- (A4);
 \draw [->,opacity=0.5] (E3) -- (B4);
 \draw [->,opacity=0.5] (E3) -- (C4);
 \draw [->,opacity=0.5] (E3) -- (D4);
 \draw [->,opacity=0.5] (E3) -- (E4);

 \draw [->,opacity=0.5] (A4) -- (A5);
 \draw [->,opacity=0.5] (A4) -- (B5);
 \draw [->,opacity=0.5] (A4) -- (C5);
 \draw [->,opacity=0.5] (A4) -- (D5);
 \draw [->,opacity=0.5] (A4) -- (E5);

\draw [->,opacity=0.5] (B4) -- (A5);
 \draw [->,opacity=0.5] (B4) -- (B5);
 \draw [->,opacity=0.5] (B4) -- (C5);
 \draw [->,opacity=0.5] (B4) -- (D5);
 \draw [->,opacity=0.5] (B4) -- (E5);

\draw [->,opacity=0.5]  (C4) -- (A5);
 \draw [->,opacity=0.5] (C4) -- (B5);
 \draw [->,opacity=0.5] (C4) -- (C5);
 \draw [->,opacity=0.5] (C4) -- (D5);
 \draw [->,opacity=0.5] (C4) -- (E5);

\draw [->,opacity=0.5]  (D4) -- (A5);
 \draw [->,opacity=0.5] (D4) -- (B5);
 \draw [->,opacity=0.5] (D4) -- (C5);
 \draw [->,opacity=0.5] (D4) -- (D5);
 \draw [->,ultra thick,opacity=0.5] (D4) -- (E5);
 
 \draw [->,opacity=0.5] (E4) -- (A5);
 \draw [->,opacity=0.5] (E4) -- (B5);
 \draw [->,opacity=0.5] (E4) -- (C5);
 \draw [->,opacity=0.5] (E4) -- (D5);
 \draw [->,opacity=0.5] (E4) -- (E5);

 \draw [->,opacity=0.5] (A5) -- (E);
 \draw [->,opacity=0.5] (B5) -- (E);
 \draw [->,opacity=0.5] (C5) -- (E);
 \draw [->,opacity=0.5] (D5) -- (E);
 \draw [->,ultra thick,opacity=0.5] (E5) -- (E);

\end{tikzpicture}
\end{center}
\caption{\label{fig-pos-dag}Graphe acyclique orienté pour énumérer les
  solutions de manière compacte dans un cas de tagging}
\end{figure}


\paragraph{Viterbi pour l'étiquetage morphosyntaxique}
Dans le cas de l'étiquetage morphosyntaxique en \ac{tal}, le \ac{dag}
de programmation dynamique est conventionnellement construit comme
illustré en figure \ref{fig-pos-dag}. Pour chaque occurrence de mot
$w_i$ dans la phrase, on construit un noeud correspondant à chacun des tags possibles.
Chacun de ces noeuds est connecté par un arc à l'ensemble des noeuds
de la position suivante $w_{i+1}$ dans la phrase. 



En utilisant cette représentation, évaluer successivement les noeuds
de gauche à droite,  c'est-à-dire en valuant l'ensemble des mots de
$w_i$  avant ceux de $w_{i+1}$ revient à valuer le graphe suivant un
ordre topologique valide.

Dans ce contexte spécifique, il est classique de stocker les quantités
$\delta$ dans une matrice $\Delta$ à $i$ colonnes et $j$ lignes.
Chaque ligne correspond à un pos tag parmi un ensemble de $K$ tags et chaque colonne à une position
dans une phrase de $N$ mots. Ainsi $\delta(i,j)$ correspond au score du noeud en
position $i$ taggué par le tag $j$. L'algorithme prend alors la forme
donnée en Algorithme \ref{algo-viterbi-table} où on choisit de 
ne pas expliciter l'état cible noté $E$ dans les exemples précédents.

Cette dernière version permet également de mettre en évidence que la complexité
de l'algorithme est en ${\cal O}(NK^2)$.  
Autrement dit la méthode de programmation dynamique permet de
donner une solution en temps polynomial à un problème dont la
résolution naïve est en temps exponentiel.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{$N$,$K$,$s$}
\For{$0 \leq j < K $}\Comment{Initialisation}
\State $\delta(0,j) \gets \psi(s , j$) 
\EndFor
\For {$0 < i <  N$}\Comment{Recurrence}
    \For{$0 \leq j < K $}
        \State $\delta(i,j) \gets 0$
        \For {$0\leq  k < K$}
        \State  $\delta(i,j) \gets \Call{Max}{\delta(i,j) ,
          \delta(i-1,k)  \otimes \psi(k , j) $}
\EndFor
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-table}Algorithme de Viterbi (version tabulaire)}
\end{algorithm}

Ce type de formulation est fréquemment utilisée dans les
implémentations. Signalons que dans un contexte d'implémentation il est d'usage de
ne pas représenter explicitement les arcs du \ac{dag} mais plutôt de
construire directement la matrice de scores $\Delta$.

\begin{exo}[Historique de dérivation]
Augmenter l'algorithme \ref{algo-viterbi-table} pour qu'il renvoie
également la séquence de tags de score maximal.
\end{exo}

\paragraph{Equation de Bellmann}
Les techniques de programmation dynamique ne sont pas limitées
au cas du tagging mais sont héritées de méthodes plus générales de
résolution de problèmes d'optimisation de fonctions récursives.

En notant $\delta(x_{-1}) ,\delta(x_{-2})\ldots \delta(x_{-k})$ 
les solutions de sous problèmes qu'il faut résoudre récursivement pour
trouver la solution du problème $\delta(x)$, la résolution par
programmation dynamique consiste à calculer $\delta(x)$
à partir des valeurs mémorisées pour les sous-problèmes à traiter $\delta(x_{-1}) ,\delta(x_{-2})\ldots \delta(x_{-k})$ 
en suivant le schéma donné par l'équation suivante~:
\begin{equation}
\label{eq-bellmann}
\delta(x) = \left\{ 
\begin{array}{ll}
1 & \text{si }  x = q_0\\
\text{max} \bigg( \delta(x_{-1}) \times \psi(x_{-1},x), \ldots ,\delta(x_{-k}) \times \psi(x_{-k},x) \bigg) &\text{sinon}
\end{array}
\right.
\end{equation}
qui est appelée équation de programmation dynamique ou \kw{équation de
  Bellmann}. Il s'agit d'une formule récursive 
qui fait intervenir deux opérations~: {\sc Max} 
 est une opération d'aggrégation et $\times$ est une opération de
 composition destinée à calculer le score de chemins dans le \ac{dag}
de calcul. 

Des variantes et des généralisations sur les opérations d'aggrégation et de composition sont
possibles, c'est ce qu'on propose d'examiner dans la section suivante.

\section{Abstractions algébriques}
\label{sec-semi-ring}

Les algorithmes que nous présentons ici sont destinés à être utilisés
en combinaison avec une méthode d'apprentissage.
C'est cette dernière
qui donne une méthode pour valuer la fonction $\psi$ et pour estimer
les éventuels paramètres qui lui sont associés.

L'algorithme de Viterbi est un algorithme qui ne fait rien
d'autre que de calculer un {\sl max} ou un {\sl argmax} pour un
très grand ensemble de séquences.

Or chaque méthode d'apprentissage manipule des poids qui se combinent
différemment. Par exemple pour calculer le poids d'une séquence avec
un \ac{hmm} il faut réaliser une multiplication alors qu'avec un
perceptron il faut réaliser une addition. L'algorithme de Viterbi peut
être réutilisé pour chacun de ces paradigmes mais avec les ajustements
nécessaires au système de pondération du paradigme en question.

Nous introduisons ici la notion de demi-anneau
car elle permet de spécifier l'interface entre les
algorithmes présentés ici et des
modèles d'apprentissage variés. 
Plus spécifiquement cette notion aide à caractériser
les conditions d'utilisation d'un algorithme de recherche (notamment
celui de Dijkstra) pour un
un modèle d'apprentissage. En second lieu elle donne des points de
repères sur les paramètres à considérer pour adapter les algorithmes
aux problèmes d'apprentissage traités. Et finalement cela permet de
dériver de nouvelles utilisations pour un algorithme donné.

Un \kw{demi-anneau} est une structure algébrique abstraite qui
permet de généraliser le calcul avec des nombres naturels (ensemble
$\mathbb{N}$)\footnote{Le calcul avec des entiers (ou des réels) se
  généralise par une structure d'\kw{anneau}. C'est-à-dire qu'on a
  nécessairement des
additifs inverses.}.
Le calcul suppose deux opérations~: l'addition qui est commutative et
qui a un élément neutre noté $\bar{0}$, la multiplication qui peut
être commutative et qui a un élément neutre noté
$\bar{1}$. De plus la multiplication distribue sur l'addition et
$\bar{0}$ est absorbant pour la multiplication.
Contrairement aux \kw{anneaux}, les demi-anneaux n'ont pas
nécessairement un additif inverse tel que $a \oplus -a = \bar{0}$.

Un demi anneau est un quintuple $(E,\oplus,\otimes,\bar{0},\bar{1})$
où $E$ est un ensemble, 
$\oplus$ l'opération d'addition, $\otimes$ l'opération de multiplication, $\bar{0}$ le neutre pour l'addition et
$\bar{1}$ le neutre pour la multiplication.  

L'intérêt d'utiliser cette généralisation dans la spécification des
algorithmes est de donner une formulation unique d'un algorithme qu'il
ne reste plus qu'à instancier avec le demi-anneau correspondant au
problème d'apprentissage à traiter. 

On donne en Figure \ref{algo-viterbi-semiring} une reformulation de
l'algorithme de Viterbi (Algorithme \ref{algo-viterbi-general}) en utilisant la notation
en semi-anneau. Par ailleurs, on donne en figure \ref{fig-semirings} quelques exemples de
demi-anneaux qui sont utilisés dans ce cours.


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\delta(s) \gets \bar{1}$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\delta(s) \gets \bar{0}$
\ForAll {$(s',s) \in AE(s)$}
\State  $\delta(s) \gets \Call{$\oplus$}{\delta(s) , \delta(s')  \otimes \psi(s',s) $}
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-semiring}Algorithme de Viterbi avec
  opérations abstraites}
\end{algorithm}



\begin{figure}[htbp]
\begin{center}
\scalebox{0.85}{
\begin{tabular}{llccccl}\toprule
Nom   &Ensemble&$\oplus$&$\otimes$&$\bar{0}$&$\bar{1}$&Usage possible\\\midrule
Viterbi& $[0,1]$    & max&$\times$&0&1&meilleure séquence
(\ac{hmm})\\
Viterbi-\ac{crf}& $\mathbb{R}^+$  & max&$\times$&0&1&meilleure
séquence (\ac{crf})\\
Viterbi-réel& $\mathbb{R}\cup\{-\infty\} $ &max&+&$-\infty$&0&meilleure
séquence (perceptron)\\
Tropical& $\mathbb{R}^+\cup \{-\infty\}$&min&+&$-\infty$&0&plus court chemin ($-log(p)$)\\
Avant    &$[0,1]$ &+&$\times$&0&1&Algorithme avant (\ac{hmm})\\
Avant-\ac{crf} &$\mathbb{R}^+$ &+&$\times$&0&1&Algorithme avant (\ac{crf})\\
Comptage&$\mathbb{N}$ &+&$\times$&0&1&Compte le nombre de séquences\\
\bottomrule
\end{tabular}}
\end{center}
\caption{\label{fig-semirings}Quelques demi-anneaux utilisés dans ce cours}
\end{figure}

On termine par donner quelques définitions et propriétés qui seront
utiles notamment dans les sections suivantes.  Un demi-anneau
$(E,\oplus,\otimes,\bar{0},\bar{1})$ 
est \kw{idempotent} si $e \oplus e = e \qquad (\forall e \in E)$.
Si le demi-anneau est idempotent, on peut alors définir la relation
d'ordre partiel $\leq$ comme suit~:
\begin{displaymath}
a \leq b \,\Leftrightarrow\,  (a\oplus b) = a
\end{displaymath}
appelée ordre naturel de $E$. On dit qu'un demi-anneau a la propriété
de \kw{supériorité} si pour tout couple $a,b \in E$:
\begin{displaymath}
a\leq a \otimes b, \qquad b \leq a\otimes b
\end{displaymath}
Ce qui revient à dire que combiner par multiplication deux quantités
$a,b$ renvoie comme résultat une valeur plus grande. Cette propriété est
requise pour utiliser l'algorithme de Dijkstra ou ses dérivés (y
compris l'algorithme de Knuth) dans un contexte de prédiction structurée.




\begin{exo}[Algorithme somme produit]
Instancier l'algorithme de Viterbi (Algorithme
\ref{algo-viterbi-general}) en utilisant le demi anneau 
appelé Avant-\ac{crf} (Figure \ref{fig-semirings}). Simuler ce nouvel
algorithme à l'aide de l'exemple  de \ac{dag} donné en figure
\ref{fig-viterbi-general-dag}. Donner en français une explication de
ce que cet algorithme calcule. 
\end{exo}


\section{Algorithme de Dijkstra et recherche A$\star$}
\label{sec-dijkstra}

Dans certains cas, il est possible de reformuler le problème de recherche de la séquence
de poids maximal dans un \ac{dag} comme un problème du plus court
chemin dans un graphe de telle sorte que le problème se résoud avec
l'algorithme de Dijkstra.
 
Intuitivement l'algorithme de Dijkstra peut s'utiliser dans un
contexte de tagging lorsque les scores associés aux arcs
s'interprètent comme des mesures dites de \kw{surprise} que l'on obtient à partir
de probabilités $(\text{surprise} =  -\log_2(p))$.
\begin{algorithm}[htbp]
\begin{algorithmic}
  \Function{Dijkstra}{V,E,s}
  \State $\delta(x) \gets \infty\qquad  (\forall x \in V)$
  \State $\delta(s) \gets 0$
  \State $\Call{PushPriorityQueue}{Q ,V}$
  \While {$Q \not = \emptyset$}
       \State $x \gets \Call{PopMin}{Q}$
        \For{$y \in AS(x)$}
        \State $\delta (y) \gets \Call{min}{\delta(y), \delta(x)+ \psi(x,y)}$
        \State $\Call{UpdatePriorityQueue}{Q,\delta(y)}$
        \EndFor
  \EndWhile
\EndFunction
\end{algorithmic}
\caption{\label{algo-dijkstra-general}Algorithme de Dijkstra}
\end{algorithm}

Commençons par rappeler le fonctionnement de l'algorithme de Dijkstra
dans le cas classique. On suppose un graphe dont les arcs sont
pondérés par des distances entre des stations de métro. Le problème est de trouver le
plus court chemin entre deux stations, la première est appelée la
source, la seconde la destination.

L'algorithme suppose un graphe $G= \langle S,E \rangle$ une file de priorité $Q$. Une file de priorité
est une structure de donnée qui maintient ses arguments triés. On peut
ainsi lui ajouter des éléments pondérés et extraire l'élément de
poids minimal\footnote{On suppose que les poids des éléments
  définissent la relation d'ordre.}.

L'algorithme de Dijkstra, détaillé en Algorithme
\ref{algo-dijkstra-general}, est conceptuellement très simple. 
L'invariant se résume comme suit.
L'algorithme procède en évaluant comment progresser à partir du noeud
$s$ du graphe qui est le plus proche de la source.
Aucun chemin alternatif plus court ne peut mener à $s$ sinon ce serait
un noeud sur ce chemin alternatif qui serait
sélectionné à la place de $s$. L'algorithme termine quand le noeud $s$
est le but à atteindre.

Il faut remarquer que l'algorithme de Dijkstra fonctionne uniquement
si les poids des chemins sont positifs. Dans le cas où certains
chemins ont des poids négatifs, l'algorithme donne un résultat incorrect.



\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{3};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%deltas
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){10};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){8};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){6};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){8};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){7};

\end{tikzpicture}
\end{center}
\caption{Exemple de recherche du plus court chemin avec Dijkstra}
\end{figure}


% \begin{figure}
% \scalebox{0.7}{
% \begin{tikzpicture}[xscale=2.5,yscale=2.5]
%     \node[shape=ellipse,draw=black] (C) at (-0.5,0.3) {Châtelet};
%     \node[shape=ellipse,draw=black] (E) at (-2.5,1) {Etoile};
%     \node[shape=ellipse,draw=black] (N) at (3,0) {Nation};
%     \node[shape=ellipse,draw=black] (S) at (-1.5,2.5) {Saint-Lazare};
%     \node[shape=ellipse,draw=black] (R) at (1,1) {République};
%     \node[shape=ellipse,draw=black] (B) at (0.75,-0.25) {Bastille};
%     \node[shape=ellipse,draw=black] (M) at (-1.4,-1.5) {Montparnasse};
%     \node[shape=ellipse,draw=black] (O) at (-1,1) {Opéra};
%     \node[shape=ellipse,draw=black] (I) at (0.75,-2) {Pl. Italie};


%     \node[shape=rectangle,fill=white] (X) at (-0.55,1.5) {3};
%     \node[shape=rectangle,fill=white] (Y) at (-0.25,2.4) {22};

%     \draw [-,opacity=1] (C) -- (O) node[midway,fill=white]{3};
%     \draw [-,opacity=1] (C) -- (B) node[midway,fill=white]{3};
%     \draw [-,opacity=1] (C) -- (R) node[near end,fill=white]{4};
%     \draw [-,opacity=1] (C) -- (E) node[midway,fill=white]{7};
%     \draw [-,opacity=1] (C) -- (M) node[midway,fill=white]{7};
%     \draw [-,opacity=1] (C) -- (I) node[midway,fill=white]{7};
%     \draw [-,opacity=1] (C) -- (I) node[midway,fill=white]{6};
%     \draw [-,opacity=1] (C) to [out=30,in=-70] (S);
%     \draw [-,opacity=1] (E) -- (M) node[midway,fill=white]{11};
%     \draw [-,opacity=1] (M) -- (I) node[midway,fill=white]{7};
%     \draw [-,opacity=1] (B) -- (I) node[midway,fill=white]{5};
%     \draw [-,opacity=1] (B) -- (R) node[midway,fill=white]{4};
%     \draw [-,opacity=1] (N) -- (I) node[midway,fill=white]{9};
%     \draw [-,opacity=1] (N) -- (B) node[midway,fill=white]{3};
%     \draw [-,opacity=1] (N) -- (R) node[midway,fill=white]{6};
%     \draw [-,opacity=1] (O) -- (R) node[near end,fill=white]{5};
%     \draw [-,opacity=1] (O) -- (E) node[midway,fill=white]{3};
%     \draw [-,opacity=1] (S) -- (M) node[near end,fill=white]{9};
%     \draw [-,opacity=1] (S) -- (O) node[midway,fill=white]{2};
%     \draw [-,opacity=1] (S) -- (R) node[midway,fill=white]{9};
%     \draw [-,opacity=1] (E) to [out=70,in=90] (N);
% \end{tikzpicture}
% }
% \caption{\label{fig-ratp}Plan simplifié du métro parisien}
% \end{figure}

% \begin{exo}[De \'Etoile à Nation]
% Simuler l'algorithme de Dijkstra pour calculer le plus court chemin
% entre \'Etoile et Nation sur le plan du métro parisien donné en Figure \ref{fig-ratp}.
% \end{exo}
% \begin{exo}[De place d'Italie à Saint-Lazare]
% Simuler l'algorithme de Dijkstra pour calculer le plus court chemin
% entre Place d'Italie et Saint-Lazare sur le plan du métro parisien donné en Figure \ref{fig-ratp}.
% \end{exo}
% \begin{center}
% \scalebox{0.7}{
% \begin{tabular}{cl}\toprule
% Itération&File de priorité ($Q$)\\\midrule
% 1& Italie(0)\\
% 2& Bastille(5) $\prec$ Chatelet(6) $\prec$ Montparnasse(7) $\prec$ Nation(9)\\
% 3& Chatelet(6) $\prec$ Montparnasse(7) $\prec$ Nation(8) $\prec$ République(9)\\
% 4& Montparnasse(7) $\prec$ Nation(8) $\prec$ Saint-Lazare(9) $\prec$ Opéra(9) $\prec$ Republique(10) $\prec$ Etoile(13)\\
% 5 & Nation(8) $\prec$ Saint-Lazare(9) $\prec$ Opéra(9) $\prec$ Republique(10) $\prec$ Etoile(13)\\
% 6 & {\bf Saint-Lazare(9)} $\prec$ Opéra(9) $\prec$ Republique(10) $\prec$ Etoile(13)\\\bottomrule
% \end{tabular}}
% \end{center}

% \begin{exo}[Historique]
% Donner une extension au pseudo-code en figure
% \ref{algo-dijkstra-general} pour renvoyer également le plus court
% chemin et pas seulement sa valeur.
% \end{exo}
% \begin{exo}[Invariant de l'algorithme et poids négatifs]
% Donner un exemple de graphe comportant au moins un arc de poids
% négatif pour lequel une exécution naïve de l'algorithme de Dijkstra
% renvoie un résultat incorrect.
% \end{exo}
% \begin{exo}[Graphe acyclique orienté]
% En faisant l'hypothèse que le graphe est un \ac{dag}, proposez une
% simplification de l'algorithme \ref{algo-dijkstra-general}
% \end{exo}

% \paragraph{Application de l'algorithme de Dijkstra en \ac{tal}} 
%  Pour les problèmes de \ac{tal} comme le tagging, le problème peut se
%  reformuler comme un problème de recherche du plus court chemin
%  lorsque le modèle d'apprentissage produit des poids qui s'apparentent
%  à des probabilités.  Dans le cadre de ce cours, cet algorithme sera donc approprié pour
% être utilisé en combinaison avec des modèles d'apprentissage tels que
% \ac{hmm}, \ac{memm} et des modèles neuronaux qui généralisent \ac{memm}.

% L'algorithme peut ainsi être réutilisé en représentant le problème par
% un graphe identique aux \ac{dags} de programmation dynamique manipulés
% par l'algorithme de Viterbi. Contrairement à l'algorithme
% de Viterbi, l'algorithme de Dijkstra cherche explicitement un court
% chemin, ce qui demande de remplacer la fonction de pondération
% probabiliste par une fonction de pondération qui calcule des scores
% qui se comportent de manière analogue aux distances entre stations de métro.

% Il est d'usage, notamment pour \ac{hmm},
% d'utiliser des log-probabilités dans les implémentations pour éviter
% les problèmes de manque de précision dans la manipulation de réels
% trop proches de 0.  Ici on réutilise cette pratique allègrement~:  si
% $p$ est une probabilité de transition, on peut interpréter $-\log(p)$ comme l'effort (ou une longueur de chemin ou encore une surprise) qui permet
% d'avancer dans la séquence. Dans ce cas suivre un chemin de très haute
% probabilité ($p\approx 1.0$) aura un coût très faible ($-\log(1.0)\approx 0$)
% alors que suivre un chemin de très basse probabilité ($p\approx 0.0$)
% aura un coût énorme ($-\log(0.0) \approx +\infty$). 
% Autrement dit, on suppose que fonction de score $\psi(s_i,s_{i+1}) =
% -\log(p)$ où $p$ est une probabilité de transition.
% Dans ce contexte, utiliser l'algorithme de Dijkstra revient à chercher
% le chemin pour lequel l'effort (ou la surprise) global est le plus
% faible\footnote{On verra en section \ref{sec-semi-ring} que ces
%   intuitions se formalisent explicitement en termes algébriques. 
% L'algorithme de Dijkstra est utilisable lorsque le demi-anneau utilisé pour combiner les
%   scores possède une propriété dite de supériorité. Celle-ci
%   généralise l'idée que lorsque deux chemins sont combinés la distance
%   augmente. Le demi-anneau décrit informellement ici est en fait le demi-anneau tropical.
% }.

% On peut illustrer cela par un exemple. Considérons les séquence de tags 
% $t_1,t_2,t_3,t_4$ et $t_1,t_2,t_3,t_5$. Supposons que $P(t_1) = 0.2, P(t_2|t_1) = 0.8,
% P(t_3|t_2) = 0.1,P(t_4|t_3) = 0.5, P(t_5|t_3) = 0.2$. En termes de surprise cumulée, 
% on a que~:
% \begin{displaymath}
% \sigma(t_1,t_2,t_3,t_4) = \sum_{i} \psi(t_{i}, t_{i-1}) = 1.61 + 0.22 + 2.30 + 0.69 
% \end{displaymath}
% \begin{displaymath}
% \sigma(t_1,t_2,t_3,t_5) = \sum_{i} \psi(t_{i} , t_{i-1})  = 1.61 + 0.22 + 2.30 + 1.61 
% \end{displaymath}
% On voit que la surprise cumulée augmente lors de chaque transition.
% et que la séquence de plus haute probabilité aura la plus petite
% surprise cumulée. 

% On peut démontrer que dans le pire des cas, l'algorithme de Dijkstra a
% une complexité un peu plus élevée que l'algorithme de Viterbi. 
% La complexité additionnelle est liée à l'usage de la file de priorité
% $Q$. 
% Par
% contre l'algorithme de Viterbi explore en largeur l'ensemble des
% noeuds du graphe alors que l'algorithme de Dijkstra est un exemple
% d'algorithme d'exploration en profondeur (meilleur d'abord). 
% Il est susceptible dans certains cas de
% trouver la solution en explorant moins de noeuds. 
% C'est ce qui motive l'extension de cet algorithme connue sous le nom d'heuristique \kw{A$\star$}.

\subsection{Algorithme A$\star$}

L'algorithme $A\star$ est un algorithme de recherche du plus court
chemin qui est à voir comme une extension de l'algorithme de Dijkstra.
L'invariant de l'algorithme de
Dijkstra est conservé~: \`a chaque itération c'est le noeud $s$ qui a
le coût $\delta(s)$ le plus faible qui est sélectionné pour la suite de l'exploration.

Par contre l'algorithme $A\star$ change la méthode d'évaluation du
coût. Ce n'est plus uniquement $\delta(s)$ qui représente le coût mais la
combinaison~:
\begin{displaymath}
\phi(s) = \delta(s)+h(s)
\end{displaymath}
Cette fois-ci, le coût $c(s)$ est la somme du coût $\delta(s)$ du
chemin déjà parcouru et d'une heuristique $h(n)$ qui estime le coût du
chemin qui reste à parcourir.  Ainsi l'algorithme de Dijkstra classique est un algorithme $A\star$
pour lequel $h(s) = 0\, (\forall s \in S)$. 

\begin{algorithm}[htbp]
\begin{algorithmic}
  \Function{Astar}{V,E,s}
  \State $\delta(x) \gets \infty\qquad  (\forall x \in V)$
  \State $\delta(s) \gets 0$
  \State $\Call{PushPriorityQueue}{Q ,V}$
  \While {$Q \not = \emptyset$}
       \State $x \gets \Call{PopMin}{Q}$
        \For{$y \in AS(x)$}
        \State $\delta (y) \gets \Call{min}{\delta(y), \delta(x)+  \psi(x,y)}$
        \State $\Call{UpdatePriorityQueue}{Q,\delta(y)+ h(y)}$
        \EndFor
  \EndWhile
\EndFunction
\end{algorithmic}
\caption{\label{algo-astar-general}Algorithme A star}
\end{algorithm}


\paragraph{Conception de l'heuristique} La difficulté lors de la
conception d'un algorithme $A\star$ consiste à définir une heuristique
qui permette d'obtenir une \kw{solution optimale}. 
Un algorithme de recherche de court chemin qui renvoie une solution
optimale est un algorithme qui renvoie effectivement comme résultat la
valeur du plus court chemin entre deux points. C'est ce que garantit
l'algorithme de Dijkstra.

Si l'heuristique $h(s)$ est mal définie l'algorithme $A\star$ n'est
pas garanti de renvoyer la solution optimale. On propose d'illustrer
ce point par l'exemple

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{3};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%deltas
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){10};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){8};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){6};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){8};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){7};



\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (0+\x,0.5-\y){4};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (4+\x,0.5-\y){0};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,0-\y){3};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,1-\y){3};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,0-\y){2};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,1-\y){2};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,0-\y){1};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,1-\y){1};
\end{tikzpicture}
\end{center}
\caption{Exemple d'heuristique valide si $\psi(x,y) \geq 1$}
\end{figure}

Une heuristique $h$ est dite \kw{admissible} si pour tout $s\in S$ 
la distance estimée $h(s)$ n'est jamais strictement supérieure à la distance
minimale réelle qu'il reste à parcourir pour atteindre la destination
depuis $s$.

La seconde condition que l'heuristique $h$ doit 
satisfaire pour garantir l'optimalité de l'algorithme est la condition
de \kw{monotonie} (ou de consistance)~:
\begin{displaymath} 
h(s) \leq \psi(s,s') + h(s') \qquad \forall (s,s') \in AS(s) 
\end{displaymath}
Ce qui revient à dire que l'estimation du coût pour arriver à
destination depuis $n$ doit être inférieur au coût pour arriver à
destination à partir de chacun de ses successeurs dans le graphe. C'est une
généralisation de la condition excluant les chemins de poids négatif
pour l'algorithme de Dijkstra. On peut alternativement reformuler
cette condition en incluant le terme $\delta(s)$~:
\begin{displaymath} 
\delta(s) + h(s) \leq \delta(s) + \psi(s,s') + h(s') \qquad \forall (s,s') \in AS(s) 
\end{displaymath}
pour exprimer explicitement que la longueur d'un chemin ne peut pas
raccourcir.
En général satisfaire l'une des deux conditions permet de satisfaire
l'autre. Mais ce n'est pas toujours vrai.

En \ac{tal} la recherche $A\star$ a surtout été utilisée dans des
contextes d'analyse syntaxique automatique (comme extensions de
l'algorithme de Knuth).

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{3};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%deltas
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){10};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){8};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){6};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){8};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){7};

\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (0+\x,0.5-\y){4};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (4+\x,0.5-\y){0};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,0-\y){3};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,1-\y){3};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,0-\y){2};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,1-\y){2};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,0-\y){1};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,1-\y){10};
\end{tikzpicture}
\end{center}
\caption{Exemple d'heuristique invalide si $\psi(x,y) \geq 1$}
\end{figure}

En résumé, la conception d'une bonne heuristique $A\star$ est en
général non
triviale. L'heuristique évidente $h(s) = 0$ n'aide pas à réaliser une
meilleure recherche que l'algorithme de Dijkstra. Une heuristique plus informative qui préserve
l'optimalité demande de vérifier des propriétés qui ne sont pas
triviales à satisfaire en pratique. Pour cette raison, on trouve
souvent dans la littérature des heuristiques approximatives qui sacrifient l'optimalité de la solution.


\chapter{Rappels de classification non structurée}

= modèles + descente de (sous-) gradient.

\section{Minimum d'une fonction strictement convexe}

%$f(\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N)$

\subsection{Fonctions monovariées}


Si on sait que la fonction est strictement convexe (resp. concave) ---~
 ce qui est le cas pour tous les modèles d'apprentissage décrits dans
 ce cours~--- (à l'exception des réseaux de neurones), alors il existe
 un minimum (resp. maximum) global unique.
On trouve ce minimum en résolvant :
\begin{equation}
\label{eq-derivative}
\frac{\delta f(x)}{\delta x} = 0 
\end{equation}
Par exemple si $f(x) = (x-3)^2$, on a que $\frac{\delta f(x)}{\delta
  x} = 2(x-3)$. En résolvant $2(x-3) = 0$, on trouve $x=3$. Comme la
fonction est convexe, on sait que $x=3$ est le minimum unique.
Cette méthode de résolution est appelée méthode analytique.

\begin{figure}[htbp]
\begin{center}
\scalebox{0.5}{
\begin{tabular}{cc}
\begin{tikzpicture}
\foreach \x in {-1,0,1,2,3,4,5,6}
    {        
      \coordinate (A\x) at ($(0,0)+(\x*0.5cm,0)$) {};
      \draw ($(A\x)+(0,5pt)$) -- ($(A\x)-(0,5pt)$);
      \node at ($(A\x)+(0,-3ex)$) {\x};
    }
    \draw[->] (-1,0) -- (5,0) node[right] {$x$};
    \draw[->] (0,-0.25) -- (0,6) node[above] {$f(x)$};
    \draw[scale=0.5,domain=-0.3:6.3,smooth,variable=\x,blue] plot({\x},{(\x -3) * (\x -3)});
\end{tikzpicture}
&
\begin{tikzpicture}
\foreach \x in {-1,0,1,2,3,4,5,6}
    {        
      \coordinate (A\x) at ($(0,0)+(\x*0.5cm,0)$) {};
      \draw ($(A\x)+(0,5pt)$) -- ($(A\x)-(0,5pt)$);
      \node at ($(A\x)+(0,-3ex)$) {\x};
    }
    \draw[->] (-1,0) -- (5,0) node[right] {$x$};
    \draw[->] (0,-0.25) -- (0,6) node[above] {$f(x)$};
    \draw[scale=0.5,domain=-0.3:6.3,smooth,variable=\x,blue] plot({\x},{10+-(\x -3) * (\x -3)});
\end{tikzpicture}\\
$f(x) = (x-3)^2$&$f(x) = -(x-3)^2 + 10$
\end{tabular}
}
\end{center}
\caption {Fonctions strictement convexe (gauche) et concave (droite)}
\end{figure}

Pour la très grande majorité  des fonctions utilisées par les modèles
d'apprentissage utilisés en \ac{tal},
résoudre (\ref{eq-derivative}) n'est pas possible analytiquement. On
utilise plutôt une méthode de résolution numérique appelée \kw{descente de gradient}.
\'Etant donnée une première hypothèse $x_0 = c$, la méthode de
descente de gradient consiste à calculer une suite d'hypothèses
$x_0,x_1,\ldots x_k$ qui approchent progressivement la solution.
La dérivée en un point $x_i$, $\frac{\delta f(x_i)}{\delta x}$ nous donne
la pente de la tangente en $x_i$. On sait que pour se rapprocher de la
solution, il faut choisir un point $x_{i+1} = x_i - \frac{\delta
  f(x_i)}{\delta x}$. Pour se déplacer plus ou moins vite dans une
direction, on utilise généralement un pas de gradient noté $\alpha$ de
telle sorte qu'on choisit $x_{i+1}$ comme suit~:
\begin{displaymath}
x_{i+1} = x_i - \alpha   \frac{\delta
  f(x_i)}{\delta x}
\end{displaymath}
Prenons l'exemple  de la fonction $f(x) = (x-3)^2$ et supposons $x_0
= 0$ et $\alpha =  0.1$, le début de la suite $x_0,x_1,x_2\ldots$ prend la forme suivante~:
\begin{center}
\begin{tabular}{cc}\toprule
$x_i$& $\alpha\,  2(x-3)$\\\midrule
0&$0.1\times 2\times (0-3) = -0.6$\\
0.6&$0.1\times 2\times (0.6-3) = -0.48$\\
1.08&$0.1\times 2\times  (1.08-3) = -0.384$\\
1.464&\ldots\\\bottomrule
\end{tabular}
\end{center}

\subsection{Fonctions de plusieurs variables}

La méthode de descente de gradient se généralise au cas de fonctions de plusieurs variables, 
de la forme $f(\mathbf{w})$, où $\mathbf{w}$ est un vecteur de
variables ($\mathbf{w}\in \mathbb{R}^d$).
\begin{displaymath}
\mathbf{w}_{i+1} = \mathbf{w}_i - \alpha   \nabla f(\mathbf{w})
\end{displaymath}
où $\nabla f(\mathbf{w})$ est le \kw{vecteur gradient} au point $\mathbf{w}$. 
Un vecteur gradient est un vecteur de dérivées
partielles tel que $\nabla f(\mathbf{w}) = \frac{\partial f}{\partial
  w_1}(\mathbf{w}) \ldots \frac{\partial f}{\partial w_d}(\mathbf{w})$. 
Pour trouver le minimum d'une fonction strictement convexe $f(\mathbf{w})$, il faut alors
résoudre $\nabla f(\mathbf{w})= \mathbf{0}$, c'est-à-dire un système
d'équations de la forme~:
\begin{displaymath}
\left[\begin{array}{lll}
 \frac{\partial f}{\partial
  w_1}(\mathbf{w})&=&0\\
\vdots&\vdots&\vdots\\
 \frac{\partial f}{\partial
  w_d}(\mathbf{w})&=&0
\end{array}\right]
\end{displaymath}
Prenons l'exemple de la fonction de deux variables $f(w_1,w_2) =
w_1^2+w_2^2+2w_1+8w_2$ dont le graphe est représenté en figure \ref{fig-bivariate}.
On a que  $\frac{\partial f}{\partial w_1}(\mathbf{w}) = 2w_1+2$ et que  $\frac{\partial f}{\partial
  w_2}(\mathbf{w}) = 2w_2+ 8$. Pour annuler le gradient, il faut donc résoudre
analytiquement
le système d'équations~:
\begin{displaymath}
\left[\begin{array}{lll}
2w_1+ 2&=&0\\
2w_2+ 8&=&0
\end{array}\right]
\end{displaymath}
ce qui donne $(w_1,w_2) = (-1,-4)$ et ce qui nous permet de déterminer
que sa valeur au minimum est $-1^2-4^2-2-32 =-17$. 
Par la suite on utilisera la notation suivante pour référencer ces deux valeurs~:
\begin{eqnarray*}
(-1,-4)&=&\mathop{\text{argmin}}_{\mathbf{w}\in\mathbb{R}^2} f(\mathbf{w})\\
-17 &=&\text{min} f(\mathbf{w})
\end{eqnarray*}
La résolution par la méthode
numérique suit le même principe que précédemment. Pour le déroulé de
l'exemple, on suppose que
$\mathbf{w}_0=(0,0)$ et $\alpha=0.1$.
\begin{center}
\scalebox{0.9}{
\begin{tabular}{lll}\toprule
$\mathbf{w}_i$& $\alpha\,  (2w_1+2))$&$\alpha\,  (2w_2+8))$\\\midrule
(0,0)&$0.1\times (2\times 0 + 2) = 0.2$&$0.1\times (2\times 0+8) = 0.8$\\
(-0.2,-0.8)&$0.1\times (2\times -0.2 + 2) = 0.16$&$0.1\times (2\times -0.8+8) = 0.64$\\
(-0.36,-1.44)&$0.1\times (2\times -0.36 + 2) = 0.128$&$0.1\times (2\times -1.44+8) = 0.512$ \\
(-0.488,-1.952)&\ldots&\ldots\\\bottomrule
\end{tabular}
}
\end{center}

La méthode de résolution numérique pour fonctions strictement convexes
de plusieurs variables se résume par un algorithme dit de descente de
gradient qui est explicité en Algorithme \ref{algo-GD}. Le critère
d'arrêt est en général un test de convergence de la forme
$f(\mathbf{w}_{i+1}) \approx f(\mathbf{w}_{i})$. On peut
également donner une borne sur le nombre maximal d'itérations si la
précision de la solution n'est pas essentielle.


\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}
\begin{axis}
[
    %title={$f(w_1,w_2) = w_1^2+w_2^2+2w_1+8w_2$},
    view={0}{90}
]
\addplot3[
    contour gnuplot={levels={0,-5,-10, -15, -16.5}}
]
{x^2+y^2+2*x+8*y};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{\label{fig-bivariate}Contour de la fonction $f(w_1,w_2)= w_1^2+w_2^2+2w_1+8w_2$}
\end{figure}

\begin{algorithm}
\begin{algorithmic}
\Function{GradientDescent}{$\alpha$,$f(\mathbf{w})$}
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State $\mathbf{w} \gets \mathbf{w} - \alpha \nabla f(\mathbf{w})$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-GD}Algorithme de descente de gradient}
\end{algorithm}

 
Un des points difficile concerne le choix du pas de gradient $\alpha$.
Trop petit, l'algorithme progresse trop lentement vers la solution,
trop grand, l'algorithme risque de diverger. Il existe un très grand
nombre de méthodes de descente de gradient qui traitent les problèmes
mentionnés ici et qui ont fait l'objet d'études considérables en
calcul numérique et en optimisation. 
Les méthodes utilisées en \ac{tal}, et abordées dans ce cours restent en général particulièrement
simples et approximatives. Celles-ci sont adaptées au traitement de jeux de données (1) de très
grande dimensionalité et (2) comportant un très grand nombre d'exemples.
Ceci dit, dans certains cas, il peut être utile de s'appuyer sur des librairies de
calcul numérique comme {\tt scipy.optimize}.

\begin{exo}[Montée de gradient]
La fonction $f(w_1,w_2)= -(w_1^2+w_2^2+2w_1+8w_2)$ est
strictement concave. Calculer son gradient et définissez un algorithme de montée de gradient
qui permet de déterminer numériquement son maximum.
\end{exo}


\section{Régression logistique}

Les modèles logistiques sont des modèles qui permettent de prédire une
variable binaire $Y =  \{0,1\}$ à partir d'un certain nombre de
prédicteurs notés $\mathbf{x}\in \mathbb{R}^d$ et de paramètres $\mathbf{w}\in \mathbb{R}^d$.
Il s'agit d'une brique de base pour plusieurs modèles de classification plus complexes.

\paragraph{Modèle} Supposons que l'on ait observé les résultats de
deux tests d'un étudiant au contrôle continu. 
Celui-ci obtient la note $x_1 = 6$ et la note $x_2 = 7$, ce qui
constitue le vecteur d'observations $\mathbf{x}$.
Un modèle logistique permet par exemple de donner une probabilité de succès (de réussite à l'examen)
$P(Y=1| \mathbf{x};\mathbf{w})$ à l'aide de la formule suivante~:
\begin{equation}
 P(Y=1|\mathbf{x}; \mathbf{w}) =\frac{e^{\mathbf{w}^T
     \mathbf{x}}}{1+e^{\mathbf{w}^T \mathbf{x}}}
\end{equation}
où le vecteur de poids $\mathbf{w}$ est supposé estimé depuis un jeu
de données. Comme $Y =  \{0,1\}$, on peut remarquer que~:
\begin{displaymath}
P(Y=0|\mathbf{x};\mathbf{w}) = 1 - P(Y=1| \mathbf{x};\mathbf{w})
\end{displaymath}
ce qu'il est utile de développer analytiquement pour la suite~:
\begin{eqnarray}
P(1|\mathbf{x};\mathbf{w}) &=&\frac{\text{exp}(\mathbf{w}^T
     \mathbf{x})}{1+\text{exp}(\mathbf{w}^T
     \mathbf{x})}\label{eq-logistic-positive}\\
P(0|\mathbf{x};\mathbf{w}) &=& 1 - \frac{\text{exp}(\mathbf{w}^T
     \mathbf{x})}{1+\text{exp}(\mathbf{w}^T \mathbf{x})}\\
&=&\frac{1+\text{exp}(\mathbf{w}^T \mathbf{x})}{1+\text{exp}(\mathbf{w}^T \mathbf{x})} - \frac{\text{exp}(\mathbf{w}^T
     \mathbf{x})}{1+\text{exp}(\mathbf{w}^T \mathbf{x})}\\
&=&\frac{1}{1+\text{exp}(\mathbf{w}^T \mathbf{x})}\label{eq-logistic-negative}
\end{eqnarray}

\paragraph{Estimation des paramètres}
Un mini jeu de données pour estimer des paramètres d'un modèle de
régression logistique aura par exemple l'allure suivante~:
\begin{center}
\begin{tabular}{llll}\toprule
$y$&$x_0$&$x_1$&$x_2$\\\midrule
1   & 1       &    7   &  9 \\
1   &    1    &    6    &8\\
0   & 1       &    4    & 5\\
0  & 1        &   3      &   4\\
1  &  1       &  9    &6\\\bottomrule
\end{tabular}
\end{center}
où $y$ dénote le résultat binaire observé (comme la réussite à
l'examen pour un étudiant donné), la colonne $x_0$ dénote le biais 
et chacune des autres colonnes $x_i$ dénotera par exemple le résultat
de chaque étudiant aux tests intermédiaires. On note un jeu de données 
comme suit~: $D= \mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$ pour dire que le
jeu de données comporte $N$ lignes qui apparient chacune un vecteur de données
$\mathbf{x}_i$ et une prédiction observée $y_i$.

L'objectif de la méthode d'estimation des paramètres par \kw{maximum
  de vraisemblance} consiste à trouver la valeur du vecteur
$\mathbf{w}$ telle que~:
\begin{displaymath}
\mathbf{w} = \mathop{\text{argmax}}_{\mathbf{w} \in \mathbb{R}^d} \prod_{i=1}^N P(y_i|\mathbf{x}_i; \mathbf{w}) 
\end{displaymath}
où la fonction de vraisemblance $f(\mathbf{w}) =  \prod_{i=1}^N P(y_i|\mathbf{x}_i; \mathbf{w})$
est ce qu'on appelle la \kw{fonction objective} du problème d'optimisation.
Le facteur $P(y_i|\mathbf{x}_i; \mathbf{w})$ dénote la probabilité que
le modèle donne à la ligne de donnée $i$ avec une certaine valeur de
paramètres $\mathbf{w}$. Cette probabilité prendra la forme
$P(1|\mathbf{x}_i;\mathbf{w})$ si $y_i$ vaut 1 et la forme 
$P(0|\mathbf{x}_i;\mathbf{w})$ si $y_i$ vaut 0. Pour éviter de
manipuler les deux formules (\ref{eq-logistic-positive}) et (\ref{eq-logistic-negative}) dans ce qui suit,
on utilise la formule synthétique (et équivalente) suivante~:
\begin{displaymath}
P(y_i |\mathbf{x}_i;\mathbf{w}) = \frac{\text{exp}(y_i(\mathbf{w}^T\mathbf{x}_i))}{1+\text{exp}(\mathbf{w}^T\mathbf{x}_i)}
\end{displaymath}
où $y_i\in \{1,0\}$ prend la valeur de la ligne qui lui correspond dans le jeu de données.

Comme la fonction de (log-)vraisemblance est une fonction strictement
concave, il ne reste
plus qu'à obtenir une forme analytique du gradient de cette fonction
pour réaliser la maximisation par montée de gradient.
Pour simplifier les calculs, on commence par utiliser la version
logarithmique de la fonction objective~:
\begin{eqnarray}
\hat{\mathbf{w}} &=& \mathop{\text{argmax}}_{\mathbf{w} \in
  \mathbb{R}^d} \prod_{i=1}^N P(y_i|\mathbf{x}_i; \mathbf{w})\\
&=&\mathop{\text{argmax}}_{\mathbf{w} \in  \mathbb{R}^d} \sum_{i=1}^N
\log P(y_i|\mathbf{x}_i; \mathbf{w})\\
&=&\mathop{\text{argmax}}_{\mathbf{w} \in  \mathbb{R}^d} \sum_{i=1}^N
y_i ( \mathbf{w}^T \mathbf{x}_i )- \log ( 1+e^{\mathbf{w}^T
  \mathbf{x}_i} )
\end{eqnarray}
Dont chacune des dérivées partielles $\frac{\partial f}{\partial w_j}(\mathbf{w})$ au point $\mathbf{w}$
s'obtient comme suit~:
\begin{eqnarray}
\frac{\partial f(\mathbf{w})}{\partial w_j}&=&\frac{\partial \sum_{i=1}^N
y_i ( \mathbf{w}^T \mathbf{x}_i ) - \log ( 1+e^{\mathbf{w}^T
  \mathbf{x}_i} )}{\partial w_j}\\
&=&\sum_{i=1}^N y_i  x_{ij} - \frac{\partial \log [ 1+e^{\mathbf{w}^T
  \mathbf{x}_i} ] }{\partial w_j}\\
&=&\sum_{i=1}^N y_i  x_{ij} - 
\frac{\frac{\partial e^{\mathbf{w}^T  \mathbf{x}_i} }{\partial
    w_j}}{1+ e^{\mathbf{w}^T  \mathbf{x}_i}}\\
&=&\sum_{i=1}^N y_i  x_{ij} - 
\frac{e^{\mathbf{w}^T  \mathbf{x}_i} x_{ij}} {1+ e^{\mathbf{w}^T  \mathbf{x}_i}}\\
&=&\sum_{i=1}^N y_i  x_{ij} - [ P( 1 | \mathbf{x}_i,\mathbf{w}) \, x_{ij} ]\\
&=&\sum_{i=1}^N x_{ij} \, [ y_i  - P( 1 | \mathbf{x}_i,\mathbf{w}) ]
\end{eqnarray}
Autrement dit, le gradient $\nabla f(\mathbf{w})$ au point
$\mathbf{w}$ correspond au vecteur $(\frac{\partial f}{\partial w_1}(\mathbf{w}) \ldots
\frac{\partial f}{\partial w_d}(\mathbf{w}))$ qui prend la forme suivante~:
\begin{displaymath}
\nabla f(\mathbf{w}) = \sum_{i=1}^n  \mathbf{x}_{i} \, [ y_i  - P( 1 | \mathbf{x}_i,\mathbf{w}) ]
\end{displaymath}
Dans ce contexte l'algorithme de descente de gradient  (ici de montée)  prend la forme
donnée en algorithme \ref{algo-logistic-gradient}.
\begin{algorithm}
\begin{algorithmic}
\Function{BatchGradientAscent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State $\mathbf{w} \gets \mathbf{w} + \alpha \sum_{i=1}^N \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-logistic-gradient}Algorithme de montée  de gradient (batch)}
\end{algorithm}
Le cas de la régression logistique n'est pas isolé. En fait dans la
plupart des modèles d'apprentissage, le gradient prend la forme
générale suivante~:
\begin{equation}
\label{eq-sgd-gradient}
\nabla f(\mathbf{w}) = \sum_{i=1}^n  \ell(y_i, \mathbf{x}_{i} ,\mathbf{w})
\end{equation}
où $\ell(y_i, \mathbf{x}_{i} ,\mathbf{w})$ représente une fonction qui
compare la prédiction du modèle étant donné la valeur courante de $\mathbf{w}$
pour un exemple $i$ à la valeur de référence observée dans les données $y_i$.

\subsection{Descente de gradient stochastique}

Dans un contexte d'apprentissage artificiel pour le \ac{tal}, la
taille $N$ du jeu de données est en général considérable.
De telle sorte que l'algorithme de descente (ou de montée) de gradient
peut devenir un processus très coûteux en temps de par la nécessité à
chaque itération de parcourir tout le jeu de données pour évaluer le
gradient.


La méthode de \kw{descente de gradient stochastique} (\ac{sgd}) cherche à
corriger ce problème en posant l'hypothèse simplificatrice suivante~:
\begin{displaymath}
\nabla f(\mathbf{w}) \approx \ell(y_i,\mathbf{x}_i; \mathbf{w}) \qquad
({i \sim \text{\sc Uniform}(1,N)})
\end{displaymath} 
Celle-ci consiste à approximer le gradient, en principe calculé à
partir de tout le jeu de données par  un gradient tiré au sort sur un
seul exemple. L'idée est qu'après un nombre suffisant d'itérations, la
très grande majorité des exemples du jeu de données auront été tirés
au sort. On donne la variante \ac{sgd} de l'algorithme de
descente\footnote{Pour la régression logistique il faut utiliser la montée.} de
gradient en algorithme \ref{algo-gradient-sgd}.
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{StochasticGradientDescent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State $i \sim$ \Call{Uniform}{1,N}
\State $\mathbf{w} \gets \mathbf{w} - \alpha\, \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-gradient-sgd}Algorithme de descente de gradient stochastique}
\end{algorithm}
Vu que les mises à jour du gradient sont dans ce nouveau contexte
beaucoup plus fréquentes, on espère que le processus global convergera
plus rapidement vers une solution.
Notons également, que dans la pratique, on trouve couramment la
variante donnée en algorithme \ref{algo-gradient-sgd-epoch}.
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{StochasticGradientDescent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State\Call{Shuffle}{$\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$}
\For{$1\leq i\leq N$}
    \State $\mathbf{w} \gets \mathbf{w} - \alpha\, \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\EndFor
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-gradient-sgd-epoch}Variante de l'algorithme de descente de gradient stochastique}
\end{algorithm}


Cet algorithme, très utilisé en \ac{tal}, connaît de nombreuses
variantes, une des plus importantes est la variante dite en minibatch.
Celle-ci consiste à sélectionner aléatoirement un nombre d'exemple $k$
($1 < k \ll N)$ pour évaluer le gradient. Cette variante est
particulièrement utilisée  pour paralléliser les calculs sur plusieurs
processeurs. L'idée est que chaque processeur calcule indépendamment 
un gradient approximé pour le minibatch qui lui est assigné. La mise à
jour des poids est ensuite réalisée séquentiellement.

La force de la méthode \ac{sgd} est aussi son problème principal.
Le problème essentiel de la méthode c'est l'aspect aléatoire.
Il est possible que certains exemples aberrants dans les données
créent des estimations approximatives de gradients bruitées, ce qui
peut perturber l'estimation des poids, surtout si ces exemples sont
tirés en fin de procédure.

Pour corriger ce problème, on utilise couramment la version moyennée
qui est appelée \kw{descente de gradient stochastique moyennée} (\ac{asgd}).
L'idée de ce dernier algorithme est de maintenir une somme cumulée des
différents vecteurs $\mathbf{w}$ obtenus au cours des itérations et de
renvoyer la moyenne. Ce type de méthode peut être vue comme une
application de la loi des grands nombres dans le contexte de la descente
de gradient (Algorithme \ref{algo-asgd}).  
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{AveragedStochasticGradientDescent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\State $\bar{\mathbf{w}} \gets \mathbf{0}$
\State $C \gets 0$
\While{non convergence}
\State $i \sim$ \Call{Uniform}{1,N}
\State $\mathbf{w} \gets \mathbf{w} - \alpha\, \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\State $\bar{\mathbf{w}} \gets \bar{\mathbf{w}} + \mathbf{w}$
\State $C \gets C+1$
\EndWhile
\State\Return $\bar{\mathbf{w}}/C$
\EndFunction
\end{algorithmic}
\caption{\label{algo-asgd}Algorithme de descente de gradient moyennée (ASGD)}
\end{algorithm}


\subsection{Instabilités numériques}

$\text{exp}(x)$ peut créer un overflow si $x$ trop grand.
Or on a l'équivalence suivante
\begin{eqnarray}
\frac{e^x}{1+e^x} &= &\frac{e^x}{1+e^x} \frac{e^{-x}}{e^{-x}}\\
&=&\frac{1}{(1+e^x)e^{-x}}\\
\label{eq-logisitic-positive}&=&\frac{1}{e^{-x}+1}
\end{eqnarray}
Utiliser (\ref{eq-logisitic-positive}) lorsque $x$ est positif permet
d'éviter l'overflow. Utiliser $\frac{e^x}{1+e^x}$ lorsque $x$ est
négatif permet d'éviter l'overflow (dans l'autre sens).


\section{Régression logistique multinomiale}

Le modèle de régression logistique multinomiale est une généralisation
du modèle de régression logistique au cas où $Y$ est un ensemble de deux valeurs
discrètes ou plus. Un tel modèle prédit une probabilité
$P(y|\mathbf{x};\mathbf{w})$ pour chaque classe $y\in Y$ étant donné
un vecteur d'observations $\mathbf{x}\in \mathbb{R}^d$ et une matrice
de poids $\mathbf{w}\in \mathbb{R}^{d\times|Y|}$.

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}

 \matrix (mat) at (0,0) [matrix of nodes,ampersand replacement=\&,
    nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $z_{y_1}$\\
      $z_{y_2}$\\
      $z_{y_3}$\\
    };

    \node (A) at (1,0){=};
    \matrix (mat) at (4,0) [matrix of nodes,ampersand replacement=\&,
    nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $w_{11}$ \& $w_{12}$ \& $w_{13}$ \& $w_{14}$ \&  $w_{15}$\\
      $w_{21}$ \& $w_{22}$ \& $w_{23}$ \& $w_{24}$ \&  $w_{25}$\\
      $w_{31}$ \& $w_{32}$ \& $w_{33}$ \& $w_{34}$ \&  $w_{35}$\\    
    };

  \matrix (mat) at (8,0) [matrix of nodes,ampersand replacement=\&,
    nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $x_{1}$ \\
      $x_{2}$ \\
      $x_{3}$ \\
      $x_{4}$ \\
      $x_{5}$ \\
    };

  \end{tikzpicture}
\caption{\label{fig-logistic-multinomial-schema}Représentation
schématique d'un modèle de régression
  logistique multinomiale ($\mathbf{w}\in\mathbb{R}^{5\times 3}$, $\mathbf{x}\in\mathbb{R}^5$)}
\end{center}
\end{figure}

En première approximation, on peut considérer qu'
un vecteur de poids $\mathbf{w}_y \in \mathbb{R}^d$ (une ligne de la
matrice) correspond à chaque classe $y\in Y$.
Le score $z_y$ de la classe $y$  se calcule par le produit scalaire $\mathbf{w}^T\mathbf{x}$.
On peut ainsi calculer le score de l'ensemble des classes par le
produit de la matrice $\mathbf{w}$ et du vecteur $\mathbf{x}$, ce qu'on illustre
schématiquement en figure \ref{fig-logistic-multinomial-schema}.

Pour obtenir des probabilités à partir du vecteur de scores --
positifs ou négatifs --  on les transforme d'abord en nombres positifs à l'aide de la
fonction exponentielle (exp) puis en divisant chacun de ces nombres
par le total des scores $(\sum_y z_y )$, ce qui donne le modèle de
régression logistique multinomiale\footnote{Cette fonction de
  normalisation de scores en probabilités est également appelée fonction softmax.}~:
\begin{equation}
\label{eq-multinomial-logistic-numeric}
P(y|\mathbf{x};\mathbf{w}) =  \frac{\text{exp}(\mathbf{w}_y^T
    \mathbf{x}) }{\sum_{y'\in Y} \text{exp}(\mathbf{w}_{y'}^T
    \mathbf{x})}
\end{equation}
\paragraph{Codage des symboles par des vecteurs creux}
Pour utiliser un tel modèle
en \ac{tal}, il reste un problème à
traiter~: le modèle suppose naturellement des données $\mathbf{x}$ réelles alors
que les données langagières sont le plus souvent représentées par des
symboles discrets (à l'exception des données audio).

Supposons que $\mathbf{x}$ est un vecteur de symboles
discrets de dimension $k$ comme par exemple les familles du jeu de
cartes~: $\{\diamondsuit ,\spadesuit ,\heartsuit , \clubsuit \}$. La
manière classique de coder numériquement ce type de symboles consiste
à les coder sur des vecteurs à $|F|$ dimensions, tel que chaque
symbole value à 1 une dimension et à 0 les autres. Par exemple pour les
familles du jeu de cartes~:
\begin{eqnarray*}
\diamondsuit &=& [1,0,0,0]\\
\spadesuit &=& [0,1,0,0]\\
\heartsuit &=& [0,0,1,0]\\
\clubsuit &=& [0,0,0,1]
\end{eqnarray*}
On peut formaliser cette méthode de codage, appelée \kw{one hot
  coding}, à l'aide de \kw{fonctions features}. \`A chaque dimension $i$
du vecteur codé $\boldsymbol\Phi(x) = \phi_1(x),\phi_2(x),\phi_3(x),\phi_4(x)$ on fait correspondre une
fonction feature $\phi_i(x)$ à valuation booléenne, par
exemple si on a tiré une carte $x$, on pourra la coder à l'aide des
features suivantes~:
\begin{center}
\vspace{-0.75cm}\scalebox{0.7}{
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_1(x) = 
\left\{
\begin{array}{ll}
1&\text{si } x = \diamondsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_2(x) = 
\left\{
\begin{array}{ll}
1&\text{si } x = \spadesuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_3(x) = 
\left\{
\begin{array}{ll}
1&\text{si } x = \heartsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_4(x) = 
\left\{
\begin{array}{ll}
1&\text{si } x = \clubsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
}
\end{center}
Supposons maintenant qu'on ait tiré un vecteur $\mathbf{x} = x_1,x_2$
de deux cartes. On peut toujours utiliser un vecteur de features $\boldsymbol\Phi(\mathbf{x})$ pour coder la
séquence $\mathbf{x}$ de cartes tirées~:
\begin{center}
\vspace{-0.75cm}\scalebox{0.7}{
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_1(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \diamondsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\begin{displaymath}
\phi_5(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_2 = \diamondsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_2(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \spadesuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\begin{displaymath}
\phi_6(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_2 = \spadesuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_3(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \heartsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\begin{displaymath}
\phi_7(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_2 = \heartsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
\begin{minipage}[t]{.35\textwidth}
\begin{displaymath}
\phi_4(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \clubsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\begin{displaymath}
\phi_8(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_2 = \clubsuit \\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{minipage}
}
\end{center}
mais on peut aussi envisager coder les information qui portent sur les
\kw{interactions} entre variables. Si on veut indiquer explicitement qu'on a tiré
deux cartes de la famille pique, on pourra utiliser par exemple une
feature telle que~:
\begin{displaymath}
\phi_9(\mathbf{x}) = 
\left\{
\begin{array}{ll}
1&\text{si } x_1 = \spadesuit \quad \&\quad  x_2 = \spadesuit\\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
de telle sorte que les vecteurs de features
$\boldsymbol\Phi(\mathbf{x})$ ont généralement une dimensionnalité
considérable en pratique. 
Notons que cette première méthode de codage permet d'utiliser le
modèle logistique multinomial avec des symboles discrets comme données.
En explicitant le codage, le modèle (\ref{eq-multinomial-logistic-numeric}) prend ainsi la forme suivante~:
\begin{equation}
\label{eq-multinomial-logistic-sparse1}
P(y|\mathbf{x};\mathbf{w}) =  \frac{\text{exp}(\mathbf{w}_y^T
    \boldsymbol\Phi(\mathbf{x})) }{\sum_{y'\in Y} \text{exp}(\mathbf{w}_{y'}^T
   \boldsymbol\Phi( \mathbf{x}))}
\end{equation}

Un tel modèle fait encore l'hypothèse implicite que les poids sont
organisés en matrice~: chaque ligne $\mathbf{w}_y$ de la matrice de
poids correspond aux poids destinés à scorer la classe $y\in Y$. 
Lorsque le nombre de classes est grand (voire infini) ou lorsqu'on ne
souhaite pas utiliser une matrice de poids, on peut généraliser la méthode
de codage par interactions en spécialisant les features à une classe
donnée, c'est-à-dire en spécifiant des features qui ont la forme générale suivante~:
\begin{displaymath}
\phi_i(\mathbf{x}, y) = 
\left\{
\begin{array}{ll}
1&\text{si } Y=y \quad\&\quad  x_k = \text{valeur}\quad (\&\, x_l = \text{valeur})*\\
0&\text{sinon}
\end{array}
\right.
\end{displaymath}
Cette représentation alternative --~qui est le plus souvent utilisée dans
ce cours~-- permet de représenter les poids comme un simple vecteur
$\mathbf{w}$. Le score d'une classe est obtenu par un produit scalaire 
$z_y = \mathbf{w}^T\boldsymbol\Phi(\mathbf{x},y)$ qui ne fait intervenir
que les features qui sont pertinentes pour scorer cette classe.
Lorsqu'on utilise ce codage, on notera que le modèle (\ref{eq-multinomial-logistic-sparse1}) 
prend alors la forme suivante~:
\begin{equation}
\label{eq-multinomial-logistic-sparse2}
P(y|\mathbf{x};\mathbf{w}) =  \frac{\text{exp}(\mathbf{w}^T
    \boldsymbol\Phi(\mathbf{x},y)) }{\sum_{y'\in Y} \text{exp}(\mathbf{w}^T
   \boldsymbol\Phi( \mathbf{x},y'))}
\end{equation}


\paragraph{Estimation des paramètres} L'entraînement d'un modèle de
régression logistique multinomiale est la procédure qui consiste à
estimer un vecteur $\mathbf{w}$ de poids à partir  de  données annotées.
Un jeu de données aura en général une allure du type~:
\begin{center}
\begin{tabular}{llll}\toprule
$y$ &$x_0$&$x_1$&$x_2$\\\midrule
Animé&la&	souris&	grise\\
Inanimé&	la&	souris&	apple\\
Inanimé&	une&	souris&	cassée\\
Animé&	une&	souris&	affamée\\
Groupe	&un&	troupeau&	errant\\\bottomrule
\end{tabular}
\end{center}
Cet exemple pourrait constituer le début d'un jeu de données destiné à
classer les occurrences de noms en classes d'animacité ($Y = \{\text{Animé,Inanimé,Groupe}\}$)
en fonction de leur contexte. 

Dans ce qui suit, on note le jeu de
données $\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$, et comme dans le cas de
la régression logistique, l'objectif est de trouver une valeur des
paramètres qui maximise l'objectif de maximum de vraisemblance~:
\begin{equation}
f(\mathbf{w}) =  \prod_{i=1}^N P(y_i|\mathbf{x}_i;\mathbf{w})
\end{equation}
La fonction de log-vraisemblance est en général celle qui est
maximisée car elle est strictement concave et la version logarithmique
facilite les calculs~:
\begin{align}
\nonumber
\hat{\mathbf{w}} &=\mathop{\text{argmax}}_{\mathbf{w} \in
  \mathbb{R}^d} \prod_{i=1}^N P(y_i|\mathbf{x}_i;\mathbf{w})\\
\nonumber
&= \mathop{\text{argmax}}_{\mathbf{w} \in \mathbb{R}^d} \sum_{i=1}^N
\log P(y_i|\mathbf{x}_i;\mathbf{w})\\
\nonumber
&= \mathop{\text{argmax}}_{\mathbf{w} \in \mathbb{R}^d} 
\sum_{i=1}^N \log \frac{\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y_i)) } 
{\sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y')) }\\
&=\mathop{\text{argmax}}_{\mathbf{w} \in \mathbb{R}^d} 
\sum_{i=1}^N \left[\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y_i)  
-\log\left(\sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y')) \right)\right]
\end{align}
On obtient les dérivées partielles de manière analogue au cas de la régression logistique~:
\begin{align}
\nonumber
\frac{\partial f(\mathbf{w})}{\partial w_j} &=\frac{\partial
  f}{\partial w_j} \sum_{i=1}^N \left[\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y_i)  
-\log\left(\sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y'))\right) \right] \\
\nonumber
&= \sum_{i=1}^N 
\left[  \phi_j(\mathbf{x}_i,y_i)  
- \frac{\partial
  f}{\partial w_j}\log\left(\sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y')) \right)\right] \\
\nonumber
&=\sum_{i=1}^N 
\left[  \phi_j(\mathbf{x}_i,y_i)  
-\frac{\frac{\partial f}{\partial w_j}\sum_{y'\in Y} 
  \text{exp}(\mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,y'))  }{\sum_{y'\in Y}\text{exp}(\mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,y')) }
\right]\\
\label{eq-triptrap}
&=\sum_{i=1}^N 
\left[  \phi_j(\mathbf{x}_i,y_i)  
-\frac{ \sum_{y'\in Y}\text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}_i,y')) \phi_j(\mathbf{x}_i,y')  }{\sum_{y'\in
    Y}\text{exp}(\mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,y')) } 
\right] \\
\label{eq-multinomial-derivative}
&=\sum_{i=1}^N 
( \phi_j(\mathbf{x}_i,y_i)  
- \sum_{y'\in Y} P(y' | \mathbf{x}_i;\mathbf{w})  \phi_j(\mathbf{x}_i,y'))
\end{align}
La dérivation qui précède applique essentiellement des règles de
dérivation classiques (log et exp). Par contre il faut voir que le facteur 
$\phi_j(\mathbf{x},y')$ qui apparaît en  (\ref{eq-triptrap})
n'est valué à 1 que pour le seul $y'$ où la feature est effectivement
valuée à 1. 
Intuitivement, la mise à jour consiste à donner un bonus à $\phi_j$
lorsqu'elle
contribue à prédire la bonne hypothèse et un malus lorsqu'elle
contribue à prédire une mauvaise hypothèse. 
Le bonus sera d'autant plus important que le modèle aura mal prédit la
bonne solution, et le malus est proportionnel à la
probabilité que le modèle donne à  cette mauvais hypothèse.

Autrement dit, la montée de gradient consiste à compter le nombre
d'occurrences de la feature observées dans les données (premier terme)
et à lui soustraire un pseudo-compte d'occurrences de la feature tel
que prédit par le modèle (second terme).
Le gradient sera nul lorsque ces deux nombres seront égaux pour toutes
les features (et la procédure d'estimation aura convergé). 

Pour le calcul de l'ensemble du gradient, on peut ainsi formuler une contrepartie de la fonction $\ell(y_i,\mathbf{x}_i;\mathbf{w})$,
donnée en équation \ref{eq-sgd-gradient}, pour le cas multinomial~:
\begin{displaymath}
\ell(y_i,\mathbf{x}_i,\mathbf{w}) = \boldsymbol\Phi(\mathbf{x}_{i},y)
-  \sum_{y'\in Y} P(y'|\mathbf{x}_i;\mathbf{w}) \boldsymbol\Phi(\mathbf{x}_i,y')
\end{displaymath}
On peut ainsi réutiliser des algorithmes de montée de gradient
standard ou stochastiques pour réaliser l'entrainement. On donne un
exemple d'algorithme de montée de gradient en batch en Algorithme 
\ref{algo-batch-multi-logistic}.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{MultinomialLogisticGradientAscent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
    \State $\mathbf{w} \gets \mathbf{w} + 
\alpha\, \left(\sum_{i=1}^N\boldsymbol\Phi(\mathbf{x}_i,y_i) -  \sum_{y'\in Y} P(y'|\mathbf{x}_i;\mathbf{w}) \boldsymbol\Phi(\mathbf{x}_i,y')\right)$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-batch-multi-logistic}Algorithme de
  montée de gradient pour la régression logistique multinomiale}
\end{algorithm}

\begin{exo}[Régularisation]
On utilise parfois une version régularisée du modèle logistique
multinomial. La fonction objective de ce modèle s'exprime comme suit~:
\begin{equation}
\label{eq-multi-logistic-L2}
f(\mathbf{w}) =  \frac{\lambda}{2}||\mathbf{w}||_2^2+ \sum_{i=1}^N
\log P(y_i|\mathbf{x}_i;\mathbf{w})
\end{equation}
où $\lambda \in \mathbb{R}^+$ est un paramètre fixé par l'utilisateur.  
Donner une explication intuitive de l'intérêt que peut avoir le terme
de régularisation. 
Donner le gradient de la version régularisée du modèle logistique (pas
besoin de refaire tous les calculs). Quel effet a $\lambda$ ? 
\end{exo}
\begin{exo}[\ac{sgd}]
Donner une reformulation de l'algorithme
\ref{algo-batch-multi-logistic} qui utilise \ac{sgd}
\end{exo}
\begin{exo}[\ac{sgd}]
Donner une reformulation de l'algorithme
\ref{algo-batch-multi-logistic} pour la fonction
objective régularisée (\ref{eq-multi-logistic-L2}) et en utilisant \ac{sgd}.
\end{exo}

\section{Large marge multiclasse}

Si les modèles logistiques cherchent à maximiser la probabilité que le
modèle donne aux données, les modèles à large marge cherchent à
produire un modèle qui non seulement minimise les erreurs sur les
données d'entrainement mais également essaye de donner une marge de
confiance aux décisions qu'il va prendre. Deux modèles très connus
font partie de cette famille~: l'algorithme du perceptron et le modèle
des machines à vecteurs support linéaires (\ac{svm}).

Les modèles à large marge, présentés ici, sont des modèles linéaires, chaque classe
$y\in Y$ est associée à un vecteur de poids qui lui correspond et le
score d'une classe est déterminé par un produit scalaire~:
\begin{equation}
\text{score}(y,\mathbf{x};\mathbf{w}) =  \mathbf{w}_y^T \,
    \boldsymbol\Phi(\mathbf{x})
\end{equation}
On peut utiliser les modèles à large marge avec le même système de
codage que les modèles logistiques. On utilisera ici la version du modèle avec le 
codage en $\phi(\mathbf{x},y)$, c'est-à-dire~:
\begin{equation}
\text{score}(y,\mathbf{x};\mathbf{w}) =  \mathbf{w}^T \,
    \boldsymbol\Phi(\mathbf{x},y)
\end{equation}
Contrairement aux modèles logistiques, les modèles à large marge
produisent des scores qui couvrent toute l'intervalle réelle. La
procédure de décision sous-jacente consiste à choisir la classe de
score maximal. Donc plus un score est élevé, plus la classe a de
chances d'être choisie par la procédure de décision.

On voit donc que les modèles à large marge ont un fonctionnement
général qui est très similaire aux modèles logistiques. La différence
principale provient du fait que les prédictions ne s'interprètent pas
comme des probabilités.



\paragraph{Estimation des paramètres} L'originalité des modèles à
large marge tient dans le procédé d'apprentissage des poids. Les
données utilisées ont la même allure que les données utilisées par les
modèles logistiques. Ainsi on note un jeu de données $D = \mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$.

La fonction objective d'un modèle à large marge multiclasse est la suivante~:
\begin{equation}
\label{eq-largemargin-objective}
f(\mathbf{w}) = \frac{1}{N}\sum_{i=1}^N \text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))
\end{equation}
où $y^* = 
\mathop{\text{argmax}}_{y'\in Y\backslash\{y\}} \mathbf{w}^T \,
    \boldsymbol\Phi(\mathbf{x},y')$ représente l'hypothèse incorrecte
    qui a le meilleur le score (le plus sérieux concurrent de
    l'hypothèse correcte).  La fonction $\text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))$
est appelée \kw{hinge loss multiclasse}, on peut remarquer que plus
le score du plus sérieux concurrent est élevé plus la valeur de la
fonction de coût augmente.
Par conséquent, l'objectif d'un modèle à large marge est de minimiser la fonction
objective (on utilisera cette fois l'algorithme de descente de gradient).
Pour le dire encore autrement,  il faut voir que pour un exemple donné, le
coût augmente lorsque~:
\begin{displaymath}
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i)  -
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) \leq 1
\end{displaymath}
c'est-à-dire tant que le score de la prédiction de référence n'est pas supérieur à
la somme score du meilleur concurrent avec une marge de 1. La marge a
en général la valeur conventionnelle 1.  Certains modèles utilisent
une marge nulle, comme typiquement  l'algorithme du perceptron.

\paragraph{Notion de sous-gradient d'une fonction convexe}La procédure d'estimation des paramètres consiste à minimiser
(\ref{eq-largemargin-objective}).  Bien que convexe, cette fonction n'est pas
différentiable sur l'intégralité de son domaine car elle fait intervenir
un maximum. On illustre cet aspect en figure \ref{fig-maxfun} où la
fonction $f(x) = \text{max}(0,1-x)$ n'est pas différenciable en
$x_0=1$~: visuellement on peut constater qu'un nombre infini de droites
sont tangentes à la fonction en $x_0=1$.

On appelle \kw{sous-dérivée} d'une fonction convexe $f(x)$ en $x_0$
tout nombre réel $s\in\mathbb{R}$ tel que~:
\begin{displaymath}
f(x) \geq f(x_0) + s(x-x_0)
\end{displaymath}
intuitivement $s$ est l'ensemble des coefficients de pente des droites
qui passent en $(x_0,f(x_0))$ et qui sont situées sous la fonction
$f(x)$. Sur l'exemple en figure \ref{fig-maxfun}, $s\in [-1,0]$.
L'ensemble $S$ de toutes les sous-dérivées de $f(x)$ en $x_0$ est appelé
\kw{sous-différentiel} de $f$ en $x_0$.  Le calcul des bornes de $S$ est donné dans le cas de la fonction max
par les dérivées des fonctions linéaires $f(x) = 0$ et $f(x) =
1-x$. 
\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}
\foreach \x in {-4,-3,-2,-1,0,1,2,3,4}
    {        
      \coordinate (A\x) at ($(0,0)+(\x*0.5cm,0)$) {};
      \draw [gray!75]($(A\x)+(0,5pt)$) -- ($(A\x)-(0,5pt)$);
      \node[gray!75] at ($(A\x)+(0,-3ex)$) {\x};
    }
    \draw[->,gray!75] (-5,0) -- (5,0) node[right] {$x$};
    \draw[->,gray!75] (0,-1.5) -- (0,4) node[above] {$f(x)$};
    \draw[scale=0.5,domain=-4:4,smooth,thick,variable=\x,blue] plot({\x},{-(\x-1)});
    \draw[scale=0.5,domain=-5:5,smooth,thick,variable=\x,red] plot({\x},{0});
    \draw[scale=0.5,domain=-5:5,samples=400,dashed,variable=\x,ultra thick,black] plot({\x},{max(0,-(\x-1))});
%\addlegendentry{$f_1(x) = 1-x$}
%\addlegendentry{$f_2(x) = 0$}
%\addlegendentry{$f_3(x) = max(0,1-x)$}
\end{tikzpicture}
\end{center}
\caption{\label{fig-maxfun}Maximum de deux fonctions $f(x) = \text{max}(0,1-x)$}
\end{figure}

De manière générale la dérivée d'une fonction $f(x) = \text{max}(f_1(x),f_2(x))$
s'obtient en divisant le domaine en deux sous-intervalles réparties autour du point de non
différentiabilité ($x_0=1$ sur l'exemple). On utilisera la dérivée
correspondant à l'intervalle dans lequel on se trouve.
On peut déterminer facilement cet intervalle en comparant $f_1$ et $f_2$ de telle
sorte que~:
\begin{displaymath}
\frac{\partial f}{\partial x}\text{max}(f_1(x),f_2(x)) = \left\{
\begin{array}{ll}
\frac{\partial f_1}{\partial x}(x) & \text{si } f_1(x) > f_2(x)\\\\
\frac{\partial f_2}{\partial x}(x) & \text{si } f_2(x) > f_1(x)
\end{array}\right.
\end{displaymath}
Lors de la descente de sous-gradient, au point non différentiable, on
peut choisir tout $s\in S$ comme valeur de la dérivée. En pratique on
prendra arbitrairement la dérivée de $f_1$ ou de $f_2$. 

Ce qui précède se généralise aux cas des fonctions de plusieurs variables.
En ce qui concerne la fonction objective des
modèles à large marge (\ref{eq-largemargin-objective}), on obtient les
dérivées partielles suivantes~:
\begin{eqnarray}
\hat{\mathbf{w}}&=&\mathop{\text{argmin}}_{\mathbf{w} \in \mathbb{R}^d}\sum_{i=1}^N
\text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))\\
\nonumber
\frac{\partial f}{\partial w_j} &=&\sum_{i=1}^N
\frac{\partial}{\partial w_j} \text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) -
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))\\
\nonumber
&=&\sum_{i=1}^N
\left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_i,y*) - \phi_j(\mathbf{x}_i,y_i) & \text{si }  1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) -
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i)  \geq 0\\
0&\text{sinon}
\end{array}\right.\\
%\nonumber
&=&\sum_{i=1}^N
\left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_i,y*) - \phi_j(\mathbf{x}_i,y_i) & \text{si }  
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i)   - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) \leq 1\\
0&\text{sinon}
\end{array}\right.
\end{eqnarray}
Au final, on peut formuler une fonction $\ell$ qui représente 
la contribution de chaque exemple dans les données au gradient~:
\begin{displaymath}
\ell(y_i,\mathbf{x}_i,\mathbf{w}) = 
\left\{
\begin{array}{ll}
 \boldsymbol\Phi(\mathbf{x}_i,{y}^*_i)-
\boldsymbol\Phi(\mathbf{x}_{i},y_i)&\text{si }
[ \text{score}(y_i) - \text{score}(y^*_i)  ]\leq 1\\
 \mathbf{0}& \text{sinon}
\end{array}\right.
\end{displaymath}
L'algorithme de descente de gradient s'instancie de manière
habituelle,
ce qui donne la version présentée en algorithme \ref{algo-grad-LM}.
On peut noter qu'on a procédé à une légère réorganisation des signes, ce
qui facilite notamment la comparaison avec les algorithmes
d'optimisation pour le cas logistique.
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{BatchLargeMarge}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State
\scalebox{0.8}{$\mathbf{w} \gets \mathbf{w} + \alpha \left(  
\frac{1}{N}\sum_{i=1}^N
\left\{
\begin{array}{ll}
\boldsymbol\Phi(\mathbf{x}_{i},y_i) - \boldsymbol\Phi(\mathbf{x}_i,{y}^*_i)
&\text{si }
[ \text{score}(y_i) - \text{score}(y^*_i)  ]\leq 1\\
 \mathbf{0}& \text{sinon}
\end{array}\right. \right)$}
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-grad-LM}Descente de gradient pour modèle à large marge linéaire}
\end{algorithm}
On peut remarquer que l'algorithme d'optimisation met à jour les poids
uniquement lorsque la classe correcte n'est pas prédite avec une marge
supérieure à 1 sur sa plus sérieuse concurrente.
Dans ce cas l'algorithme donne un bonus au poids associés aux features
de la référence et un malus aux poids associés aux features de la
prédiction concurrente.

L'algorithme de descente de gradient à large marge peut être utilisé
tel quel, mais on va maintenant montrer que deux algorithmes très connus peuvent être
vus comme des cas particuliers de la famille des modèles à large
marge~: l'algorithme du perceptron et les \ac{svm} linéaires.


\subsection{Algorithme du perceptron}

L'algorithme du \kw{perceptron} est un algorithme très populaire en \ac{tal}
car il est particulièrement simple à implémenter. On peut le voir
comme un cas particulier des modèles à large marge dont la procédure
d'optimisation est \ac{sgd}. Ainsi en posant que la marge est nulle, l'objectif à
large marge devient~:
\begin{equation}
f(\mathbf{w}) = \frac{1}{N}\sum_{i=1}^N \text{max}(0,
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))
\end{equation}
et le sous-gradient devient~:
\begin{equation}
\label{eq-perceptron-grad}
\frac{\partial f(\mathbf{w})}{\partial w_j} =  
\sum_{i=1}^N \left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_{i},y^*_i) -\phi_j(\mathbf{x}_{i},y_i) &\text{si }
[ \text{score}(y_i) - \text{score}(y^*_i)  ]\leq 0\\
0&\text{sinon}
\end{array}\right.
\end{equation}
Si l'algorithme utilisé pour réaliser la descente de gradient est \ac{sgd}
structuré en itérations sur les données (Algorithme \ref{algo-gradient-sgd-epoch}),
on peut observer que ce cas d'utilisation correspond exactement
à l'algorithme du \kw{perceptron multiclasse} traditionnel que l'on
reproduit en algorithme \ref{algo-perceptron-sgd}.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Perceptron}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State\Call{Shuffle}{$\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$}
\For{$1\leq i\leq N$}
    \State $\hat{y} \gets \mathop{\text{argmax}}_{{y\in Y}}
    \mathbf{w}^T \, \boldsymbol\Phi(\mathbf{x}_i,y)$
    \If{$\hat{y} \not = y_i$}
       \State $\mathbf{w} \gets \mathbf{w} + \alpha\, (\phi_j(\mathbf{x}_{i},y_i)-\phi_j(\mathbf{x}_{i},\hat{y})) $
    \EndIf
\EndFor
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-sgd}Algorithme du perceptron}
\end{algorithm}
\begin{exo}[Vérification]
Pour vous convaincre que l'algorithme \ref{algo-perceptron-sgd} est
bien une variante notationnelle d'un modèle à large marge. Ecrivez
l'algorithme de descente de gradient stochastique qui utilise
directement (\ref{eq-perceptron-grad}) et procédez à la comparaison.
\end{exo}

Notons finalement que l'algorithme du perceptron est très utilisé dans
sa version moyennée ce qui permet de lui donner une certaine stabilité
et de réduire les effets de surentrainement (Algorithme \ref{algo-perceptron-asgd})
\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{AveragedPerceptron}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\State $\bar{\mathbf{w}} \gets \mathbf{0}$
\State $e\gets 0$
\While{non convergence}
\State\Call{Shuffle}{$\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N$}
\For{$1\leq i\leq N$}
    \State $\hat{y} \gets \mathop{\text{argmax}}_{{y\in Y}}
    \mathbf{w}^T \, \boldsymbol\Phi(\mathbf{x}_i,y)$
    \If{$\hat{y} \not = y_i$}
       \State $\mathbf{w} \gets \mathbf{w} + \alpha\, (\phi_j(\mathbf{x}_{i},y_i)-\phi_j(\mathbf{x}_{i},\hat{y})) $
    \EndIf
       \State $\bar{\mathbf{w}} \gets  \bar{\mathbf{w}}+ \mathbf{w} $
\EndFor
\State $e \gets e + 1$
\EndWhile
\State\Return $\bar{\mathbf{w}}/(N\times e)$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-asgd}Algorithme du perceptron moyenné}
\end{algorithm}


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{BatchSVM}{$\alpha,\lambda, \mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State
\scalebox{0.8}{$\mathbf{w} \gets \mathbf{w} + \alpha \left( 
\frac{1}{N}\sum_{i=1}^N
\left\{
\begin{array}{ll}
\boldsymbol\Phi(\mathbf{x}_{i},y_i) - \boldsymbol\Phi(\mathbf{x}_i,{y}^*_i)
&\text{si }
[ \text{score}(y_i) - \text{score}(y^*_i)  ]\leq 1\\
 \mathbf{0}& \text{sinon}
\end{array}\right. - \lambda
  \mathbf{w} \right)$}
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-linear-svm}Descente de gradient de \ac{svm}
  linéaire (batch)}
\end{algorithm}





\subsection{\ac{Svm} linéaire multiclasse}
Si maintenant on ajoute un terme de régularisation à l'objectif (\ref{eq-largemargin-objective}), celui-ci prend la forme suivante~:
\begin{equation}
f(\mathbf{w}) = \frac{\lambda}{2}||\mathbf{w}||_2^2 +
\frac{1}{N}\sum_{i=1}^N \text{max}(0, 1 + 
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))
\end{equation}
Cet objectif correspond à celui d'une \kw{machine à vecteurs de support}
(\ac{svm}) linéaire. On peut indiquer que les modèles à large marge
ont pour origine les travaux sur \ac{svm}, même si ceux-ci ont été
initialement formulés de manière très différente (en apparence). 

On peut optimiser cet objectif avec les
algorithmes de descente de gradient et de descente de gradient
stochastique moyennée présentés dans ce chapitre. Ainsi le problème
d'optimisation consiste à minimiser~:
\begin{equation}
\hat{\mathbf{w}}=\mathop{\text{argmin}}_{\mathbf{w} \in \mathbb{R}^d}
\frac{\lambda}{2}||\mathbf{w}||_2^2+\sum_{i=1}^N
\text{max}(0,
1+\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))
\end{equation}
dont on obtient les dérivées partielles suivantes en procédant à un
développement analogue aux précédents~:
\begin{equation}
\frac{\partial f}{\partial w_j} = \lambda w_j+\sum_{i=1}^N
\left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_i,y*) - \phi_j(\mathbf{x}_i,y_i) & \text{si }  
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i)   - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) \leq 1\\
0&\text{sinon}
\end{array}\right.
\end{equation}
Contrairement au perceptron, la résolution du problème d'optimisation
de \ac{svm} en forme primale est
habituellement présenté comme un  algorithme de descente de gradient en batch
(Algorithme \ref{algo-linear-svm}). Mais rappelons que \ac{svm} est
habituellement présenté à partir de sa forme duale.  Celle-ci est
toutefois inadaptée
aux problèmes de \ac{tal}. 

\begin{center}

\scalebox{0.7}{\footnotesize
\begin{tabular}{lll}\toprule
{\sc Modèle} & {\sc Objectif} & {\sc Gradient}\\\midrule
Régression softmax&$\prod_{i=1}^N P(y_i | \mathbf{x};\mathbf{w})$&
$\sum_{i=1}^N\phi_j(\mathbf{x_i},y_i) - \sum_{y'\in Y} P(y'|\mathbf{x_i},\mathbf{w})\phi_j(\mathbf{x_i},y_i)$ \\
Large marge & $\sum_{i=1}^N \text{max}(0, 1 + 
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i) ))$
&$\sum_{i=1}^N
\left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_i,y*) - \phi_j(\mathbf{x}_i,y_i) & \text{si }  
\mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y_i)   - \mathbf{w}^T\boldsymbol\Phi(\mathbf{x}_i,y^*_i) \leq 1\\
0&\text{sinon}
\end{array}\right.
$\\\bottomrule
\end{tabular}}
\end{center}





\section{Réseaux de neurones}

On propose d'introduire l'usage de réseaux de neurones en \ac{tal}
comme une généralisation des modèles de régression logistique multinomiale.

La difficulté pratique quand on utilise un modèle
de régression logistique multinomiale consiste à définir les
fonctions features et notamment leurs interactions. Deux problèmes se
posent~:
\begin{itemize}
\item Le nombre de features et notamment d'interactions est en général
  considérable {\bf (feature engineering)}
\item Quelles features (interactions) inclure dans le modèle ? {\bf
    (feature selection)}
\end{itemize}

En \ac{tal} on utilise des réseaux de neurones pour construire de
meilleures représentations numériques de symboles discrets, comme par
exemple des représentations des mots appelées plongements lexicaux ou {\em word embeddings}).

\subsection{Réseau à Propagation avant}

On peut voir le modèle de régression logistique multinomiale (ou
modèle de régression softmax) tel que présenté en équation
(\ref{eq-multinomial-logistic-numeric}) et réécrite ici sous forme
plus compacte à l'aide de la notation softmax~:
\begin{equation}
\mathbf{y} = \text{softmax}(\mathbf{W}_1 \mathbf{x})
\end{equation}

Pour exprimer une contrepartie aux interactions et à la réduction de
dimensionnalité (feature selection) des modèles traditionnels, un
réseau de neurones à propagation avant introduit une couche cachée $\mathbf{h}$
supplémentaire à (\ref{eq-multinomial-logistic-numeric}).

\begin{eqnarray} 
\mathbf{h} &=& g(\mathbf{W}_2\mathbf{x})\\
\mathbf{y} &=& \text{softmax}(\mathbf{W}_1 \mathbf{h})
\end{eqnarray}
où $g$ dénote une fonction non linéaire de la forme $\mathbb{R}^d \mapsto
\mathbb{R}^d$ dite fonction d'activation. Celle-ci est typiquement
choisie parmi la fonction logistique, la fonction tangente
hyperbolique ou la fonction relu (Figure \ref{fig-activations}).

\begin{figure}[htbp]
\begin{center}
\scalebox{0.5}{
\begin{tikzpicture}
\foreach \x in {-3,-2,-1,0,1,2,3}
    {        
      \coordinate (A\x) at ($(0,0)+(\x*1cm,0)$) {};
      \draw ($(A\x)+(0,5pt)$) -- ($(A\x)-(0,5pt)$);
      \node at ($(A\x)+(0,-3ex)$) {\x};
    }

\foreach \y in {-1,1}
    {        
      \coordinate (A\y) at ($(0,0)+(0,\y*1cm)$) {};
      \draw ($(A\y)+(5pt,0)$) -- ($(A\y)-(5pt,0)$);
      \node at ($(A\y)+(-3ex,0)$) {\y};
    }
    \draw[->] (-4,0) -- (4,0) node[right] {$x$};
    \draw[->] (0,-1.5) -- (0,1.5) node[above] {$f(x) = tanh(x)$};
    \draw[scale=1,domain=-3:3,smooth,variable=\x,blue] plot({\x},{tanh(\x )});
\end{tikzpicture}
\begin{tikzpicture}
\foreach \x in {-3,-2,-1,0,1,2,3}
    {        
      \coordinate (A\x) at ($(0,0)+(\x*1cm,0)$) {};
      \draw ($(A\x)+(0,5pt)$) -- ($(A\x)-(0,5pt)$);
      \node at ($(A\x)+(0,-3ex)$) {\x};
    }

\foreach \y in {-1,1}
    {        
      \coordinate (A\y) at ($(0,0)+(0,\y*1cm)$) {};
      \draw ($(A\y)+(5pt,0)$) -- ($(A\y)-(5pt,0)$);
      \node at ($(A\y)+(-3ex,0)$) {\y};
    }
    \draw[->] (-4,0) -- (4,0) node[right] {$x$};
    \draw[->] (0,-1.5) -- (0,1.5) node[above] {$f(x) = \frac{1}{1+e^{-x}}$};
    \draw[scale=1,domain=-3:3,smooth,variable=\x,blue]
    plot({\x},{exp(\x )/(1+exp(\x ))});
\end{tikzpicture}
\begin{tikzpicture}
\foreach \x in {-3,-2,-1,0,1,2,3}
    {        
      \coordinate (A\x) at ($(0,0)+(\x*1cm,0)$) {};
      \draw ($(A\x)+(0,5pt)$) -- ($(A\x)-(0,5pt)$);
      \node at ($(A\x)+(0,-3ex)$) {\x};
    }

\foreach \y in {-1,1}
    {        
      \coordinate (A\y) at ($(0,0)+(0,\y*1cm)$) {};
      \draw ($(A\y)+(5pt,0)$) -- ($(A\y)-(5pt,0)$);
      \node at ($(A\y)+(-3ex,0)$) {\y};
    }
    \draw[->] (-4,0) -- (4,0) node[right] {$x$};
    \draw[->] (0,-1.5) -- (0,1.5) node[above] {$f(x) = \text{max}(0,x)$};
    \draw[scale=1,domain=-3:1.5,smooth,variable=\x,blue]
    plot({\x},{max(0,\x )});
\end{tikzpicture}
}
\end{center}
\caption{\label{fig-activations}Fonctions d'activation}
\end{figure}

On illustre en figure \ref{fig-ffwd} l'allure schématique d'un réseau
de ce type. En général la couche cachée a une dimension qui est choisie
plus petite que la dimension du vecteur d'entrée de telle sorte
qu'elle encode une représentation des données en dimension réduite. 

\begin{figure}[htbp]
\begin{center}
\scalebox{0.6}{
\begin{tikzpicture}

 \matrix (mat) at (-0.5,0) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $z_{y_1}$\\
      $z_{y_2}$\\
      $z_{y_3}$\\
    };

    \node (A) at (0.5,0){=};
    \matrix (mat) at (4,0) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $w_{11}$ \& $w_{12}$ \& $w_{13}$ \& $w_{14}$ \&  $w_{15}$ \& $w_{16}$\\
      $w_{21}$ \& $w_{22}$ \& $w_{23}$ \& $w_{24}$ \&  $w_{25}$ \& $w_{26}$\\
      $w_{31}$ \& $w_{32}$ \& $w_{33}$ \& $w_{34}$ \&  $w_{35}$ \& $w_{36}$\\    
    };

  \matrix (mat) at (8,0) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $h_{1}$ \\
      $h_{2}$ \\
      $h_{3}$ \\
      $h_{4}$ \\
      $h_{5}$ \\
      $h_{6}$\\
    };

\matrix (mat) at (13,0) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
{
      $w_{11}$ \& $w_{12}$ \& $w_{13}$ \&  $w_{14}$ \& $w_{15}$ \& $w_{16}$\&  $w_{17}$ \& $w_{18}$\\
      $w_{21}$ \& $w_{22}$ \& $w_{23}$ \& $w_{24}$ \& $w_{25}$ \& $w_{26}$\&  $w_{27}$ \& $w_{28}$\\
      $w_{31}$ \& $w_{32}$ \& $w_{33}$ \& $w_{34}$ \& $w_{35}$ \& $w_{36}$\&  $w_{37}$ \& $w_{38}$ \\
      $w_{41}$ \& $w_{42}$ \& $w_{43}$ \&  $w_{44}$ \& $w_{45}$ \& $w_{46}$\&  $w_{47}$ \& $w_{48}$\\
      $w_{51}$ \& $w_{52}$ \& $w_{53}$ \& $w_{54}$ \& $w_{55}$ \& $w_{56}$ \&  $w_{57}$ \& $w_{58}$\\
      $w_{61}$ \& $w_{62}$ \& $w_{63}$ \& $w_{64}$ \& $w_{65}$ \& $w_{66}$\&  $w_{67}$ \& $w_{68}$\\
    };

\matrix (mat) at (18,0) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $x_{1}$ \\
      $x_{2}$ \\
      $x_{3}$ \\
      $x_{4}$ \\
      $x_{5}$ \\
      $x_{6}$\\
      $x_{7}$ \\
      $x_{8}$\\
    };
\end{tikzpicture}
}
\end{center}
\caption{\label{fig-ffwd}$\mathbf{y} = \text{softmax}(\mathbf{W}_1 g(\mathbf{W}_2\mathbf{x} ) )$}
\end{figure}

\paragraph{Estimation des paramètres} L'estimation des paramètres 
consiste généralement à maximiser la vraisemblance (on parle également
de minimisation de l'entropie croisée) d'un jeu de données. 
La méthode d'optimisation utilisée est en général la descente de gradient
stochastique ( \ac{sgd} ).
Si le principe reste le même que pour les cas précédents, le calcul du
gradient à chaque itération est plus complexe. Il est réalisé à l'aide
d'un algorithme appelé rétropropagation du gradient. Par ailleurs la
fonction objective d'un réseau de neurone n'est en général pas
convexe. Il existe en général un grand nombre de minima locaux et il y
a peu de garanties de trouver un minimum global. 

TODO (backprop) \url{http://colah.github.io/posts/2015-08-Backprop/}



Notons pour terminer que l'utilisation d'une couche de sortie softmax
n'a rien d'obligatoire, on peut utiliser des couches de sorties à
large marge ou du perceptron. Il reste que la couche de sortie softmax
est en pratique très utilisée.

\paragraph{Plongements lexicaux}
Reste la question de l'interface d'un réseau de neurones avec des
données langagières. On a implicitement supposé que le vecteur de
données $\mathbf{x}$ est un vecteur de réels. Or en \ac{tal} 
les données sont des symboles discrets (des mots). 

L'interface est réalisée par une couche de dictionnaire (dite parfois
couche de lookup ou couche de plongement) qui consiste à encoder un
dictionnaire qui envoie des mots sur des vecteurs.

Dans ce contexte, on suppose que les données du réseau 
sont des symboles codés par la méthode one-hot. 
La couche de plongement est alors une simple matrice $\mathbf{E}$ dont
la multiplication avec chaque vecteur one-hot renvoie l'embedding $\mathbf{e}$
correspondant. Le vecteur d'entrée $\mathbf{x}$ est la concaténation
des vecteurs d'embeddings correspondant à chacun de ces symboles,
comme illustré en Figure \ref{fig-embedding}.

\begin{figure}
\begin{tikzpicture}
\matrix (mat) at (0,0) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $x_{1}$ \\
      $x_{2}$ \\
      $x_{3}$ \\
      $x_{4}$ \\
      $x_{5}$ \\
      $x_{6}$\\
      $x_{7}$ \\
      $x_{8}$\\
    };

\node (A) at (1.5,0){=};

 \matrix (mat) at (5,2.25) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $e_{11}$ \& $e_{12}$ \& $e_{13}$\& $e_{14}$\& $e_{15}$\\
      $e_{21}$ \& $e_{22}$ \& $e_{23}$\& $e_{24}$\& $e_{25}$\\
      $e_{31}$ \& $e_{32}$ \& $e_{33}$\& $e_{34}$\& $e_{35}$\\
      $e_{41}$ \& $e_{42}$ \& $e_{43}$\& $e_{44}$\& $e_{45}$\\
    };

 \matrix (mat) at (5,-2.25) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $e_{11}$ \& $e_{12}$ \& $e_{13}$\& $e_{14}$\& $e_{15}$\\
      $e_{21}$ \& $e_{22}$ \& $e_{23}$\& $e_{24}$\& $e_{25}$\\
      $e_{31}$ \& $e_{32}$ \& $e_{33}$\& $e_{34}$\& $e_{35}$\\
      $e_{41}$ \& $e_{42}$ \& $e_{43}$\& $e_{44}$\& $e_{45}$\\
    };


 \matrix (mat) at (9,3) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $s_{1}$ \\
      $s_{2}$ \\
      $s_{3}$ \\
      $s_{4}$ \\
      $s_{5}$ \\
    };

\matrix (mat) at (9,-3) [matrix of nodes,ampersand replacement=\&, nodes={draw,rectangle, minimum width=1cm, minimum height=1cm}]
    {
      $s'_{1}$ \\
      $s'_{2}$ \\
      $s'_{3}$ \\
      $s'_{4}$ \\
      $s'_{5}$ \\
    };
\end{tikzpicture}
\caption{\label{fig-embedding} Couche de plongements}
\end{figure}
 
Comme la matrice $\mathbf{E}$ est une matrice de paramètres,
ceux-ci sont mis à jour, au même titre que tous les autres paramètres,
 lors de la descente de gradient.









\chapter{Perceptron structuré}

Le modèle du perceptron structuré est initialement dû à \cite{collins-2002}.

\section{Généralisation du modèle du perceptron}

Le perceptron structuré est un modèle qui généralise le modèle du
perceptron au cas des données structurées. 
Dans ce chapitre, on donne une présentation pour la modélisation de
séquences. On généralisera ce cas à la prédiction d'arbres dans les
chapitres suivants.

Un perceptron multiclasse est un modèle statistique qui prédit le
score $\psi(y)$ d'une donnée $y\in Y$ de manière linéaire~:
\begin{equation}
\psi(y) = \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y)
\end{equation}
Comme $\mathbf{w} \in \mathbb{R}^d$ et $\boldsymbol\Phi(\mathbf{x},y)
\in \{0,1\}^d$, on a que $\psi(y) \in \mathbb{R}$. 
Ce modèle est habituellement utilisé dans un contexte de prise de
décision, il s'agit de sélectionner parmi un ensemble $Y$ d'hypothèses, 
l'hypothèse $y\in Y$ de score maximal~:
\begin{equation}
\hat{y} =   \mathop{\text{argmax}}_{y\in Y} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y)
\end{equation}

Dans le cas où $Y$ est un ensemble de structures, comme un ensemble de
séquences, la taille de cet ensemble croît exponentiellement en
fonction de la longueur de la phrase. 
L'idée d'un modèle de perceptron structuré est de permettre la
décomposition du calcul du score des séquences de telle sorte qu'il
soit possible de partager des sous-calculs entre des sous-séquences communes.
Ainsi une séquence de tags $\mathbf{y} = y_1,y_2\ldots y_m\ldots $
sera évaluée par la fonction de score suivante~:
\begin{equation}
\Psi(\mathbf{y}) = \sum_{i=1}^m \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)
\end{equation}
Autrement dit, le score d'une séquence est la somme des scores 
$\psi_i(\mathbf{x}, y_{i-1},y_i) = \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)$
attribués à tous les couples de tags qui la composent. Lorsqu'il
s'agit de donner un score à un ensemble de séquences, il est ainsi
possible de représenter le problème dans un \ac{dag} de programmation
dynamique et de réutiliser l'algorithmique décrite dans les chapitres précédents.

\begin{tikzpicture}

\node[draw,circle,above] at (0,0) (a) { $y_1$ };
\node[draw,circle,above] at (3,0) (b) { $y_2$ };
\node[draw,circle,above] at (6,0) (c) { $y_3$ };
\node[draw,circle,above] at (10,0) (d) { $y_n$ };

\draw (a) -- node[above] {$\psi(\mathbf{x}, y_1,y_2)$} (b) -- node[above] {$\psi(\mathbf{x}, y_2,y_3)$} (c);
\draw[dashed] (c) -- (d);

\end{tikzpicture}



\section{Recherche de la meilleure analyse}

\subsection{Fonctions features}


\begin{exo}[Algorithme de Dijkstra ?]
Est-il possible d'adapter l'algorithme de Dijkstra pour prédire la
meilleure séquence de tags avec un modèle de perceptron structuré ?
si oui comment ? si non, justifiez.
\end{exo}

\section{Estimation des paramètres}

On suppose qu’un corpus annoté $C = \mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$ est un
exemplaire de $N$ phrases. 
Chaque exemple annoté est un couple $(x_i , y_i )$ qui représente une
séquence de mots $x = x_1 \ldots x_m$ et une séquence de tags de
référence $y = y_1 \ldots y_m$ de même longueur.

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{train-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{\mathbf{y}} \gets \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,\mathbf{y})$
\Comment{Tagging}
\label{algoline-pseudoargmax}
\If{$\hat{\mathbf{y}} \not = \mathbf{y}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[\boldsymbol\Phi(\mathbf{x}_i,\mathbf{y}_i) 
       - \boldsymbol\Phi(\mathbf{x}_i,\hat{\mathbf{y}})  \right]$ 
     \label{algoline-update}
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-train}Estimation des paramètres d'un
  perceptron}
\end{algorithm}


\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{train-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \mathbf{0}$
\State $\bar{\mathbf{w}} \gets \mathbf{0}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State $\hat{\mathbf{y}} \gets \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,\mathbf{y})$
\Comment{Tagging}
\If{$\hat{\mathbf{y}} \not = \mathbf{y}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[\boldsymbol\Phi(\mathbf{x}_i,\mathbf{y}_i) 
       - \boldsymbol\Phi(\mathbf{x}_i,\hat{\mathbf{y}})  \right]$ 
\EndIf
\State $\bar{\mathbf{w}} \gets \bar{\mathbf{w}}+\mathbf{w}$
\EndFor
\EndFor
\State \Return $\bar{\mathbf{w}}/N$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-train-avg}Estimation des paramètres d'un
  perceptron moyenné}
\end{algorithm}


\section{Estimation des paramètres et approximations}

TODO: cette section, introduire la décomposition du score partout, y
compris dans le pseudo code.

Pour certains types de problèmes ou de représentations, il n'est pas
possible d'évaluer un \ac{dag} de programmation dynamique exhaustivement.
En pratique, les temps de calcul deviennent prohibitifs.
Pour cette raison, on peut souhaiter utiliser une méthode de recherche
approximative en faisceau, y compris lors de l'apprentissage.

Dans le contexte d'un problème d'estimation des paramètres,
l'utilisation d'un faisceau pose un problème au niveau de la procédure
de prédiction (Algorithme  \ref{algo-perceptron-train}, ligne \ref{algoline-pseudoargmax})
Le problème posé par ce type de méthode est que les méthodes en
faisceau renvoient un {\sl pseudo-argmax} qui a pour origine
l'inexactitude de l'algorithme de recherche de solutions.
Cela signifie que $\hat{\mathbf{y}}$ est potentiellement sous-optimal,
ce qui fausse la mise à jour (ligne \ref{algoline-update}) et peut
causer la divergence de la procédure d'estimation.

\paragraph{Mise à jour d'un modèle à large marge}
Pour comprendre le problème, on commence par reformuler la procédure 
de mise à jour dans le cas exact (sans utiliser un faisceau). Notons  $\mathbf{y}^*$ la séquence
incorrecte à laquelle le modèle attribue le meilleur score, c'est-à-dire~:
\begin{displaymath}
\mathbf{y}^* = \mathop{\text{argmax}}_{\mathbf{y} \in
  \mathbf{Y}\backslash \{\mathbf{y}\}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},\mathbf{y})
\end{displaymath}
Il y a nécessairement mise à jour lorsque le score de la meilleure séquence
incorrecte est supérieur au score de la séquence correcte~: $\Psi(\mathbf{y}^*) \geq \Psi(\mathbf{y})$.
Lorsque $\Psi(\mathbf{y}^*) <\Psi(\mathbf{y})$ il n'y a pas de mise à
jour. Cette reformulation se jsutifie par le fait que le perceptron
peut être vu comme un cas particulier de modèle à large marge
(Chapitre XXX). 

\paragraph{Généralisation aux méthodes en faisceau}
Dans un contexte où on utilise un faisceau ($\mathbf{Y}' \subsetneqq \mathbf{Y}$), la meilleure prédiction dans le
beam $\tilde{\mathbf{y}} = \text{argmax}_{\mathbf{y} \in \mathbf{Y'}}
\mathbf{w}^T \boldsymbol\Phi(\mathbf{x},\mathbf{y})$ ne correspond pas nécessairement à
la meilleure séquence optimale $\hat{\mathbf{y}} = \text{argmax}_{\mathbf{y} \in \mathbf{Y}}
\mathbf{w}^T \boldsymbol\Phi(\mathbf{x},\mathbf{y})$ qui a pu être écartée du faisceau prématurément.  
Le cas suivant devient désormais possible $\Psi(\tilde{\mathbf{y}}) < \Psi(\mathbf{y}) \text{ alors que } \hat{\mathbf{y}} = \mathbf{y}$
\begin{center}
\begin{tikzpicture}
\draw [thick,->](0,0) -- (7,0);

\foreach \x in {1,2,3,4,5,6}
   \draw (\x cm,1pt) -- (\x cm,-1pt) node[anchor=north] {$\x$};

\draw [thick,->](0,-2) -> (0,2);

\node[text=blue,right] at (7,1)   (a) {$\tilde{\mathbf{y}}$};
\node[right] at (7,2)   (b) {{\color{red}$\hat{\mathbf{y}}$} = {\color{green} ${\mathbf{y}}$}} ;


\draw [draw=blue](0,0) -- (2,1) -- (4,3) -- (6,2) -- (7,1);
\draw [draw=green](0,0) -- (2,-1) -- (4,-2) -- (6,-3) -- (7,2);
\draw [draw=red](0,0) -- (2,0.5) -- (4,0.5) -- (6,-1);
\draw [dashed,draw=red] (6,-1) -- (7,2);


\end{tikzpicture}
\\{\em On doit garantir que $score(\tilde{\mathbf{y}}) > score(\mathbf{y})$ pour que l'update
soit valide}
\end{center}


Une telle configuration entraine la mise à jour des paramètres du perceptron. Dans
ce cas on parle de mise à jour invalide. Il a été démontré
\cite{huang-2012} qu'une mise à jour valide respecte nécessairement la
condition suivante~: 
\begin{displaymath}
\Psi(\tilde{\mathbf{y}}_{1\ldots k}^*) > \Psi(\mathbf{y}_{1\ldots k})
\end{displaymath}
où $\tilde{\mathbf{y}}_{1\ldots k}^*$ dénote la sous séquence préfixe
de tags incorrecte de meilleur score dans le beam et  $\mathbf{y}_{1\ldots k}$
dénote une sous séquence préfixe de tags de référence.
Si cette condition est respectée, la convergence de la procédure d'estimation des paramètres
est garantie. On peut remarquer que cette condition revient à
généraliser le déclenchement de la mise à jour pour les modèles à
large marge au cas des sous-séquences.

Dans la pratique, il est courant depuis \cite{collins-2004} 
de réaliser la mise à jour dès que la séquence de référence sort du
beam pendant l'étape de parsing.
C'est ce qu'on appelle la mise à jour rapide (\kw{early update}).
D'autres méthodes sont possibles. Par exemple, en définissant la marge d'erreur
$\Delta_k =  \Psi(\tilde{\mathbf{y}}_{1\ldots k}^*) -
\Psi(\mathbf{y}_{1\ldots k})$, et en sélectionnant l'indice $k =
\text{argmax}_{1\leq k \leq m} \Delta_k$ on obtient la mise à jour
dite à \kw{violation maximale}. 



\chapter{Champs conditionnels aléatoires}

\section{Généralisation des modèles logistiques}

Les modèles de champs conditionnels aléatoires \ac{crf}
sont des modèle qui généralisent les modèles de régression logistique multinomiale au cas des données structurées.
Dans ce cours, on  donne une présentation pour la modélisation de séquences, ce qui est le cas d'usage le plus courant.

On se rappelle qu'un modèle de régression logistique multinomiale prédit une donnée $y$ à partir de variables observées $\mathbf{x}$ de la manière suivante~:
\begin{equation}
\label{eq-logistic-base}
P(Y = y \,|\, \mathbf{x},\mathbf{w}) = \frac{\text{exp}(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y))}{\sum_{y'\in Y}\text{exp}(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y'))}
\end{equation}
Le numérateur représente un score $\psi(y) = \text{exp}(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y))$ tel que  $\psi(y) \geq 0$~: la fonction exponentielle transforme toute valeur réelle en  réel positif. 

Comme chaque classe $y\in Y$ reçoit un score $\psi(y)$,
le dénominateur ne dit rien d'autre qu'un score se transforme en probabilité en le divisant par la somme totale des scores pour toutes les classes. Le dénominateur est parfois appelé constante de normalisation.

Un \ac{crf} linéaire n'est rien d'autre qu'un modèle de régression logistique multinomiale dont la variable $Y$ à prédire est un ensemble de séquences. Dans ce contexte, la difficulté est que le nombre de séquences possibles de tags (ou plus généralement de symboles) croit exponentiellement en fonction de la longueur de la séquence à prédire.
Ainsi il devient rapidement très difficile de réutiliser naïvement le modèle de régression logistique multinomiale (équation \ref{eq-logistic-base}), car le calcul de la constante de normalisation devient très vite ingérable.

Toute l'idée de \ac{crf} c'est de permettre la décomposition du calcul du score d'une séquence de telle sorte que l'on puisse réutiliser les méthodes de programmation dynamique notamment introduites dans les cours précédents pour réaliser les calculs dans des temps raisonnables (complexité polynomiale).  Ainsi une séquence de tags $\mathbf{y} = y_1 \ldots y_m$ sera prédite par un \ac{crf} à l'aide de la formule suivante~:
\begin{equation}
\label{eq-crf-predict}
P(\mathbf{Y} = \mathbf{y} \,|\, \mathbf{x},\mathbf{w}) = \frac{\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)}
{\sum_{\mathbf{y}'\in \mathbf{Y}}
\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y^{'}_{i-1},y^{'}_i)\right)}
\end{equation}
On voit que dans cette formulation le score global d'une séquence se
décompose en une somme de scores locaux\footnote{Le tout est encore
  argument d'une fonction exponentielle. Le traitement est détaillé en
section suivante.}.  Il ne s'agit de rien d'autre que d'imposer une décomposition du calcul d'un produit scalaire destiné à évaluer une séquence (un produit scalaire est une grosse addition de toute façon).

On va évidemment développer et exploiter  cette propriété pour exprimer des algorithmes qui partagent des sous parties de calculs efficacement\ldots  On traite en priorité l'algorithmique des deux problèmes d'inférence suivants~:
\begin{itemize}
\item Prédire la séquence de tags la plus probable $\hat{\mathbf{y}}$ pour une séquence de mots $\mathbf{x}$, c'est-à-dire résoudre le problème suivant~:
\begin{equation}
\label{eq-crf-argmax}
\hat{\mathbf{y}} =  \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}}
\, P(\mathbf{Y}=\mathbf{y} | \mathbf{x},\mathbf{w})
\end{equation}
\item Estimation par maximum de vraisemblance conditionnelle des paramètres d'un modèle dans un contexte d'apprentissage supervisé.
La résolution de ce problème nous fera résoudre par effet de bord le sous-problème de calcul de la probabilité d'une assignation de tags $P(\mathbf{Y}=\mathbf{y} | \mathbf{x},\mathbf{w})$.
\end{itemize}

\begin{exo}[fonction exponentielle]
Faire un graphique avec la librairie graphique de votre choix de la fonction $x\mapsto e^x $ sur l'intervalle réelle $]-\infty,+\infty[$
\end{exo}

\section{Recherche de la séquence de tags la plus probable}

\paragraph{La solution du paresseux}
La solution la plus efficace (et à utiliser en pratique) au problème (\ref{eq-crf-argmax}) est celle du paresseux.  Il suffit de remarquer que les fonctions exponentielles utilisées en (\ref{eq-crf-predict})  n'ont pas d'autre fonction que de normaliser les scores de produits scalaires pour obtenir des probabilités et que la normalisation
ne change pas la valeur du maximum. Par conséquent, chercher la solution de~:
\begin{equation}
\hat{\mathbf{y}} =  \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}}
\, \sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)
\end{equation}
à la place de (\ref{eq-crf-argmax}) résoud le problème. La solution du paresseux revient donc à réutiliser la méthode de résolution déjà présentée pour le modèle du perceptron global (algorithme de Viterbi). 

\paragraph{La solution par décomposition explicite du score}
Le détail de l'autre solution présentée ici (à ne pas utiliser en pratique) permet de mieux comprendre comment le score d'un \ac{crf} se décompose.
L'idée est de reformuler le score non normalisé d'une séquence par un produit comme suit~: 
\begin{displaymath}
\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)
\end{displaymath}
devient~:
\begin{displaymath}
\prod_{i=1}^m \text{exp}\left(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)
\end{displaymath}
On peut donc remarquer qu'on peut reformuler le score d'une séquence
par un produit de réels strictement positifs appelés potentiels (et
notés $\psi(\mathbf{x},y_{i-1},y_i) = \text{exp}\left(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)$). 


On peut également donner une représentation graphique au calcul réalisé sous
forme de chemin dans un graphe :
 
\begin{tikzpicture}

\node[draw,circle,above] at (0,0) (a) { $y_1$ };
\node[draw,circle,above] at (3,0) (b) { $y_2$ };
\node[draw,circle,above] at (6,0) (c) { $y_3$ };
\node[draw,circle,above] at (10,0) (d) { $y_n$ };

\draw (a) -- node[above] {$\psi(\mathbf{x}, y_1,y_2)$} (b) -- node[above] {$\psi(\mathbf{x}, y_2,y_3)$} (c);
\draw[dashed] (c) -- (d);

\end{tikzpicture}



La conséquence est que l'algorithme de Viterbi pour \ac{crf} a exactement la même forme que pour \ac{hmm}~:
les scores de séquences sont des produits de potentiels et les séquences sont comparées par la fonction maximum. Plus généralement, la reformulation de (\ref{eq-crf-predict}) par 
\begin{equation}
P(\mathbf{Y} = \mathbf{y} \,|\, \mathbf{x},\mathbf{w}) = \frac{\prod_{i=1}^m\text{exp}\left( \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)}
{\sum_{\mathbf{y}'\in \mathbf{Y}}
\prod_{i=1}^m \text{exp}\left(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y^{'}_{i-1},y^{'}_i)\right)}
\end{equation}
permet de tirer parti de toute l'algorithmique de programmation dynamique déjà développée pour \ac{hmm}.

\section{\`A la découverte des \ac{dag}s de programmation dynamique}

On se propose dans cette section d'étudier par l'exemple quelques propriétés des \ac{dags}
de programmation dynamique qui seront déterminantes pour résoudre le problème d'estimation des paramètres d'un \ac{crf}. 
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (3,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](4) -- (E) node[midway,fill=white]{3};
\end{tikzpicture}
\end{center}
Le \ac{dag} ci-dessus va nous servir d'exemple de départ. Il encode un problème qui correspond à  probabiliser toutes les séquences possibles de 2 tags, pris dans le jeu de tags $Y=\{A,B\}$, pour une séquence de deux mots. On ajoute un état source unique $S$ et un état de but à atteindre $E$. La pondération des arcs correspond à des valeurs possibles pour des potentiels $\psi(\mathbf{x},y_{i-1},y_{i})$ strictement positifs.
 
En termes de notations, on notera $s_i$ un noeud du \ac{dag} où $s\in Y$ est un tag et $i$ sa position. Chaque chemin $\pi = s_1,s_2\ldots s_{k-1},s_k$ dans le \ac{dag} a un score noté $\sigma(\pi)$.  

%\item On a $\sigma(\pi)$, score d'un chemin.
%\item On a $\alpha(s_i)$, somme des scores de tous les chemins qui mènent à $s_i$ depuis l'origine.
%\item On a $\beta(s_i)$, somme des scores de tous les chemins qui mènent à $s_i$ depuis le but.
%\item $\psi(s_i,s_{i+1})$, score d'un arc


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\delta(s) \gets 1$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\delta(s) \gets 0$
\ForAll {$(s',s) \in AE(s)$}
\State  $\delta(s) \gets \Call{Max}{\delta(s) , \delta(s')  \times \psi(\mathbf{x},s',s) $}
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-crf}Algorithme de Viterbi pour \ac{crf}}
\end{algorithm}
 
\begin{exo}[Viterbi]
Simuler l'exécution de l'algorithme de Viterbi (Algorithme \ref{algo-viterbi-crf}) sur l'exemple illustratif. Quel est le poids du meilleur chemin ? Quel est ce chemin ? 
\end{exo}

\begin{exo}[Viterbi]
Dans la section précédente, on suggère une "solution du paresseux" pour trouver le meilleur chemin dans un \ac{crf}.  L'algorithme \ref{algo-viterbi-crf} est-il directement utilisable dans ce contexte ? Si la réponse est négative, quelles modifications faudrait-il lui apporter ?
\end{exo}




\subsubsection{Algorithme avant} Quelle est la somme des scores qui mènent à un état $s_i$ depuis la source ? C'est la question à laquelle répond l'algorithme avant.
Notons $\alpha(s_i)$ la quantité qui correspond à la somme des scores de tous les chemins qui mènent à $s_i$ depuis la source. Par exemple $\alpha(B_2) = (2\times 4) + (5\times 4) = 28$.


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Forward}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\alpha(s) \gets 1$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\alpha(s) \gets 0$
\ForAll {$(s',s) \in AE(s)$}
\State  $\alpha(s) \gets \alpha(s) + (\alpha(s')  \times \psi(\mathbf{x},s',s) ) $
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-forward}Algorithme Avant}
\end{algorithm}

On peut automatiser ce type de calcul à l'aide de l'algorithme avant qui est une variante, à demi-anneau près, de l'algorithme de Viterbi. Celle-ci est donnée en algorithme \ref{algo-forward}. La récurrence de cet algorithme est la suivante~: 
\begin{equation}
\label{eq-forward}
\alpha(s_i) = \left\{ 
\begin{array}{ll}
1 & \text{si }  i = 0\\
\sum_{(s',s_i)\in AE(s_i)}  \alpha(s') \times \psi(\mathbf{x},s',s_i)&\text{sinon}
\end{array}
\right.
\end{equation}
On peut remarquer que la quantité $\alpha(E)$ correspond au facteur de normalisation $Z$, c'est-à-dire la somme des scores de tous les chemins qui mènent de la source jusqu'à la destination (toutes les séquences de tags possibles). Autrement dit, l'algorithme avant permet de résoudre en temps polynomial le problème de sommation de scores pour un nombre exponentiel de séquences de tags. Formellement on a donc que~: 
\begin{displaymath}
\alpha(s_i) = \sum_{y_1\ldots y_i \in \mathbf{Y^i}}\prod_{j=1}^{j=i} \psi(\mathbf{x},y_{j-1},y_j)
\end{displaymath}
et pour la cas spécifique des séquences complètes~: 
\begin{displaymath}
\alpha(s_{m+1}) = Z = \sum_{\mathbf{y}\in \mathbf{Y}}\prod_{j=1}^{j=m} \psi(\mathbf{x},y_{j-1},y_j)
\end{displaymath}


\begin{exo}[Probabilité d'une séquence]
Utiliser les propriétés de l'algorithme avant pour 
calculer $P(S_0,B_1,A_2,E_3)$ la probabilité de la séquence $S,B,A,E$ dans le \ac{dag} exemple.
\end{exo}

\begin{exo}[Probabilité de toutes les séquences]
Calculer la probabilité de tous les chemins qui mènent de la source à la destination dans le \ac{dag} exemple. Vérifier que ces probabilités somment à 1 et que la séquence qui a la plus haute probabilité correspond à celle que vous avez trouvé avec l'algorithme de Viterbi.
\end{exo}

\subsubsection{Algorithme arrière} Quelle est la somme des scores qui mènent à un état $s_i$ depuis la destination ?
C'est la question à laquelle répond l'algorithme arrière.
On notera $\beta(s_i)$ la quantité qui correspond à la somme des scores de tous les chemins qui mènent à $s_i$ depuis la destination. Par exemple $\beta(B_1) = (2\times 3) + (3\times 4) = 18$. Il s'agit essentiellement d'une variante miroir de l'algorithme avant. La récurrence est la suivante~:
\begin{equation}
\label{eq-backward}
\beta(s_i) = \left\{ 
\begin{array}{ll}
1 & \text{si }  i = m+1\\
\sum_{(s_i,s')\in AS(s_i)}  \beta(s') \times \psi(\mathbf{x},s_i,s')&\text{sinon}
\end{array}
\right.
\end{equation}
En tant que tel cet algorithme arrière n'a pas beaucoup d'intérêt. C'est en combinaison avec l'algorithme avant que l'on peut faire émerger son utilité.

\begin{exo}[Pseudo-code]
Donner un pseudo code pour l'algorithme arrière.
\end{exo}

\subsubsection{Combiner les quantités avant et arrière}
Utilisées en combinaison, les quantités $\alpha(s_i)$ et $\beta(s_i)$ permettent de donner des probabilités à des sous-chemins dans un \ac{dag}.

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%alphas
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){573};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){29};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){28};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){114};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){115};
%betas
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (0+\x,0.5-\y){573};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (4+\x,0.5-\y){1};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,0-\y){67};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,1-\y){119};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,0-\y){13};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,1-\y){7};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,0-\y){2};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,1-\y){3};
\end{tikzpicture}
\end{center}
\caption{\label{fig-fb-trellis}Treillis de programmation dynamique annoté par $\alpha$ et $\beta$}
\end{figure}

L'exemple donné en figure \ref{fig-fb-trellis} illustre les quantités $\alpha(s_i)$, notées en bleu sur chaque noeud, et les quantités $\beta(s_i)$ sont notées en rouge.
On peut commencer par observer que la  quantité $\alpha(E_4) = 573$ correspond au facteur $Z$. 
On obtient la probabilité d'un chemin (d'une séquence de tags) comme par exemple le chemin $S_0,A_1,B_2,B_3,E_4$ en réalisant la division suivante~:
\begin{displaymath}
P(S_0,A_1,B_2,B_3,E_4) = \frac{5\times 4\times 1\times 3}{573} = \frac{60}{573}
\end{displaymath}
En utilisant la quantité $\alpha(s_i)$, on peut déterminer la probabilité d'un séquence de tags qui termine par $B,B,E$ de la manière suivante~:
\begin{displaymath}
P(\lhd,B_2,B_3,E_4) = \frac{\alpha(B_2)\times \psi(\mathbf{x},B_2,B_3)\times\psi(\mathbf{x},B_3,E_4)}{Z} = \frac{28\times 1\times 3}{573} = \frac{84}{573} 
\end{displaymath}
En continuant le raisonnement on peut calculer la probabilité de suivre une transition (par exemple $A_1,B_2$ représente la probabilité de tagguer le premier mot $A$ et le second mot $B$) en utilisant les quantités $\alpha(s_i)$ et $\beta(s_i)$~:
\begin{displaymath}
P(\lhd,A_1,B_2,\rhd) = \frac{\alpha(A_1)\times \psi(\mathbf{x},A_1,B_2)\times \beta(B_2)}{Z} = \frac{5\times 4 \times 7}{543}=\frac{140}{543}
\end{displaymath}
En résumé, et comme illustré dans les exercices qui suivent, on peut en réalité transformer un graphe de programmation dynamique en calculette.

Ce dernier exemple introduit une quantité clé qui est réutilisée par la méthode d'estimation des paramètres par descente de gradient qui est~:
\begin{equation}
P(\lhd,s_i,s_{i+1},\rhd | \mathbf{x};\mathbf{w}) = 
\frac{\alpha(s_i)\times \psi(\mathbf{x},s_i,s_{i+1}) \times \beta(s_{i+1})}
{Z}
\end{equation}
Celle-ci correspond à la probabilité de suivre une transition entre deux tags consécutifs. Utiliser les quantités avant et arrière pour calculer ces probabilités de transition, c'est utiliser l'\kw{algorithme avant/arrière}. Formellement, on peut remarquer que $P(\lhd,s_i,s_{i+1},\rhd | \mathbf{x})$ correspond à :
\begin{eqnarray}
P(\lhd,s_i,s_{i+1},\rhd | \mathbf{x})&=& \frac{1}{Z} \sum_{y_1\ldots y_{i-1}}\prod_{j=1}^{j={i-1}} \psi(\mathbf{x},y_{i-1},y_{i})\\
&\times &\psi(\mathbf{x},y_{i-1},y_i)\\
&\times &\sum_{y_i\ldots y_m}\prod_{j={i+1}}^{j=m} \psi(\mathbf{x},y_{j-1},y_{j})
\end{eqnarray}


\begin{exo}
\`A partir de la figure \ref{fig-fb-trellis},
donner la probabilité que le second mot soit taggué $B$, c'est-à-dire, $P(\lhd,B_2,\rhd)$.
\end{exo}

\begin{exo}
Observer que $P(\lhd,B_2,\rhd) + P(\lhd,A_2,\rhd) = 1$
à partir de la figure \ref{fig-fb-trellis}.
Expliquer informellement pourquoi.
\end{exo}

\section{Estimation des paramètres}

L'estimation des paramètres d'un \ac{crf} consiste à déterminer les valeurs du vecteur de paramètres $\mathbf{w}$ à partir d'un corpus annoté.

On suppose qu'un corpus annoté $C =\mathop{(\mathbf{x}_i,\mathbf{y}_i)\}}_{i=1}^N$ est un exemplaire de $N$ phrases. Chaque exemple annoté est un couple $(\mathbf{x}_i,\mathbf{y}_i)$ qui représente une séquence de mots $\mathbf{x}=x_1\ldots x_m$ et une séquence de tags de référence $\mathbf{y} = y_1\ldots y_m$ de même longueur.

Comme pour la régression logistique multinomiale,
on présente ici l'estimation des paramètres par maximum de (log-) vraisemblance conditionnelle. 
\begin{equation}
L(\mathbf{w}) = \sum_{i=1}^N \log P(\mathbf{y}_i | \mathbf{x}_i;\mathbf{w})
\end{equation}
Autrement dit on cherche à résoudre le problème d'optimisation suivant~:
\begin{equation}
\hat{\mathbf{w}} =  \mathop{\text{argmax}}_{\mathbf{w}\in\mathbb{R}^d} \sum_{i=1}^N \log P(\mathbf{y}_i | \mathbf{x}_i;\mathbf{w})
\end{equation}
En substituant la probabilité $P(\mathbf{y}_i | \mathbf{x}_i;\mathbf{w})$ par sa définition en équation (\ref{eq-crf-predict}), on optimise~:
\begin{equation}
\hat{\mathbf{w}} =  \mathop{\text{argmax}}_{\mathbf{w}\in\mathbb{R}^d} \sum_{i=1}^N \log\frac{\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)}
{\sum_{\mathbf{y}'\in \mathbf{Y}}
\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y^{'}_{i-1},y^{'}_i)\right)}
\end{equation}
Les dérivées partielles ont la même allure que pour la régression logistique multinomiale~:
\begin{equation}
\label{eq-crf-derivative}
\frac{\partial L(\mathbf{w})}{\partial w_k} 
= \sum_{i=1}^N C_k(\mathbf{x}_i,\mathbf{y}_i)
- \sum_{i=1}^N \sum_{\mathbf{y}\in \mathbf{Y}} P(\mathbf{y}|\mathbf{x}_i,\mathbf{w}) C_k(\mathbf{x}_i,\mathbf{y})
\end{equation}
où l'abbréviation $C_k(\mathbf{x},\mathbf{y})$
représente le comptage de la feature $\phi_k$
dans une séquence de référence, c'est-à-dire~:
\begin{displaymath}
C_k(\mathbf{x}_i,\mathbf{y}_i) = \sum_{j=1}^m \phi_k(\mathbf{x}_i,y_{j-1}^i,y_j^i)
\end{displaymath}
Le calcul du premier terme en (\ref{eq-crf-derivative}) consiste à compter les occurrences de $\phi_k$ dans l'ensemble des séquences du corpus de référence.

En ce qui concerne le second terme en (\ref{eq-crf-derivative}), il faut compter les occurrences de $\phi_k$ 
--~dans toutes les séquence de tags possibles~-- en pondérant chaque occurrence par la probabilité de la séquence de tags dans laquelle elle apparait. 
Naïvement, ce calcul demande d'énumérer
l'ensemble exponentiel $\mathbf{Y}$ 
de toutes les séquences de tags $\mathbf{y}\in\mathbf{Y}$ possibles pour chaque exemple du jeu de données.

Le développement qui suit consiste à montrer comment utiliser les techniques de programmation dynamique présentées précédemment pour réaliser ce calcul de manière efficace.  Le second terme de la formule (\ref{eq-crf-derivative}) nous dit que pour chaque exemple dans les données il faut calculer~:
\begin{align}
&\sum_{\mathbf{y}\in \mathbf{Y}} P(\mathbf{y}|\mathbf{x},\mathbf{w}) \sum_{j=1}^m \phi_k(\mathbf{x},y_{j-1},y_j)\\
&=\sum_{\mathbf{y}\in \mathbf{Y}} \sum_{j=1}^m P(\mathbf{y}|\mathbf{x},\mathbf{w})  \phi_k(\mathbf{x},y_{j-1},y_j)\\
&= \sum_{j=1}^m \sum_{\mathbf{y}\in \mathbf{Y}} P(\mathbf{y}|\mathbf{x},\mathbf{w})  \phi_k(\mathbf{x},y_{j-1},y_j)\\
&=  \sum_{j=1}^m \sum_{y_{j-1}}\sum_{y_j} P(\lhd,y_{j-1},y_j,\rhd|\mathbf{x},\mathbf{w})  \phi_k(\mathbf{x},y_{j-1},y_j)
\end{align}
Au terme de cette reformulation, l'évaluation du second terme revient à compter les occurrences de la feature $\phi_k$ --~pondérées par les probabilités de transitions où elles apparaissent~-- dans le \ac{dag} de programmation dynamique, et ce pour l'ensemble des exemples du jeu de données.




\chapter{Modèles locaux et modèles récurrents}


\section{Modèles markoviens à maximum d'entropie}

Des modèles d'étiquetage de la famille {\sc crf} supposent d'assigner une séquence de tags
$\mathbf{y}$ à une séquence de mots $\mathbf{x}$, ce qui est résumé par la formule (\ref{eq-crf-argmax})
répétée ici~:
\begin{equation}
\hat{\mathbf{y}} =  \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}}
\, P(\mathbf{Y}=\mathbf{y} | \mathbf{x} ; \mathbf{w})
\end{equation}
On a vu que le problème d'optimisation de {\sc crf} fait intervenir des algorithmes coûteux en temps de calcul. 
La difficulté vient du fait que l'ensemble $\mathbf{Y}$ de toutes les séquences de tags possibles croit exponentiellement en 
fonction de la longueur de la phrase.

La motivation des modèles locaux est de simplifier la procédure d'estimation  des paramètres 
en reformulant (\ref{eq-crf-argmax}) par l'approximation suivante~:
\begin{equation}
\label{eq-local-model}
P(\mathbf{Y}=\mathbf{y} | \mathbf{x} ; \mathbf{w}) \approx \prod_{i=2}^n P(y_i | y_{i-1}, \mathbf{x} ; \mathbf{w})
\end{equation}
ce qui est une réutilisation de l'approximation markovienne classique 
\begin{displaymath}
P(\mathbf{y} = y_1\ldots y_n | \mathbf{x};\mathbf{w}) \approx \prod_{i=2}^n P(y_i|y_{i-1},\mathbf{x};\mathbf{w})
\end{displaymath}

L'équation (\ref{eq-local-model}) permet de réduire le problème d'apprentissage structuré à un cas d'apprentissage 
non structuré où la tâche de prédiction consiste à prédire la probabilité du tag $y_i$ d'un mot donné sachant la séquence de mots 
$\mathbf{x}$ et le tag du mot précédent $y_{i-1}$.  
Un tel modèle se réduit donc à un modèle de régression logistique
multinomiale (ou modèle à maximum d'entropie) où:
\begin{displaymath}
P(y_i|y_{i-1},\mathbf{x};\mathbf{w}) = \frac{\text{exp}(  \mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}, y_{i-1}, y_i ))  }{ \sum_{y'\in Y }  \text{exp}(\mathbf{w}^T
  \boldsymbol\Phi(\mathbf{x}, y_{i-1}, y')) } 
\end{displaymath}

Les paramètres du modèle étant connus, on peut en théorie réaliser la prédiction avec tout algorithme de recherche de solutions approprié
(Viterbi, Dijkstra ou toute approximation en faisceau).

\paragraph{Estimation des paramètres}
Un jeu de données pour un modèle local est un ensemble de couples $\mathop{(\mathbf{x}_i y_{i-1}, y_i)}_{i=1}^N$
où $\mathbf{x}_i$ est une séquence de mots (et le tag $y_{i-1}$ dans le corpus)  et $y_i$ est une catégorie morphosyntaxique.
L'estimation des paramètres du modèle se fait donc en optimisant la log-vraisemblance des données en utilisant par exemple un algorithme de descente
de gradient stochastique ou tout algorithme d'optimisation approprié.


\paragraph{Error propagation} On peut remarquer que contrairement à un {\sc crf}, un modèle markovien à maximum d'entropie ne visite pas tous les états.
Il ne voit que les états supposés ``gold'', c'est-à-dire que $y_{i-1}$ sera toujours supposé correct dans les données d'entrainement.
Par conséquent ce type de modèle est en théorie exposé à des effets de propagation d'erreur~: le modèle n'est pas naturellement entraîné pour traiter des 
états où il est est arrivé par erreur.

\paragraph{Label bias} Le problème du {\em label bias} est lié à la
prise de décision locale, par exemple :
\begin{itemize}
\item The robot wheels Fred round
\item The robot wheels are round
\end{itemize}
Si la tâche est de prédire la catégorie morphologique des mots,
la décision sera identique dans les deux cas avec un modèle local
(dont les facteurs sont de la forme $P(y_i|y_{i-1},\mathbf{x})$) pour
étiqueter {\em wheels}. 

\section{Modèles neuronaux}

\paragraph{Modèles de langage neuronaux pour le tagging} Une autre famille importante de modèles locaux sont constitués par des réseaux de neurones à propagation avant dont
la couche de sortie est de type softmax de telle sorte que les sorties du réseau s'interprètent comme des probabilités de la forme
$P(y_t|y_{t-1},\mathbf{x};\mathbf{w})$.

L'archétype de ce type de modèle est le modèle de langage neuronal
({\sc Nnlm} Bengio et al 2003) qui est un réseau à propagation avant qui prend la
forme suivante~:
\begin{align}
\mathbf{y} &= \text{softmax}(\mathbf{W}_1 \mathbf{h})\\
\mathbf{h} &= g(\mathbf{W}_2\mathbf{e})\\
\mathbf{e} &= \left [ 
\begin{array}{c}
\mathbf{E} \mathbf{x}_1\\
\vdots\\
\mathbf{E} \mathbf{x}_k\\
\end{array}\right]
\end{align}
où $\mathbf{x}_1 \ldots \mathbf{x}_k$  sont des vecteurs one-hot qui
codent les symboles prédicteurs. Ces vecteurs représentent par
exemple les quelques mots qui précèdent ou les quelques mots qui suivent le mot $w_t$ (à
tagguer par $y_t$) ainsi que le tag du mot précédent $(y_{t-1})$.

La couche de sortie softmax de ce modèle s'interprète comme une
probabilité conditionnelle de la forme $P(y_t |
y_{t-1},\mathbf{x})$. Autrement dit, ce modèle est une variante de
{\sc Memm}.

Les paramètres du modèle étant connus, on peut réaliser la prédiction avec tout algorithme de recherche de solutions approprié
(Viterbi, Dijkstra ou toute approximation en faisceau).

L'estimation des paramètres se fait de manière analogue au cas des
{\sc Memm} en optimisant la log-vraisemblance des données en utilisant par exemple un algorithme de descente
de gradient stochastique ou tout algorithme d'optimisation approprié.


\paragraph{Réseaux de neurones récurrents pour le tagging} 
Les réseaux de neurones récurrents constituent de nos jours une alternative très
populaire aux {\sc  Memm} et à leurs variantes depuis l'introduction 
des modèles de langages à réseaux récurrents ({\sc Rnnlm}) par  Mikolov 2010. 

Les réseaux de neurones récurrents ont pour propriété intéressante de
permettre de mémoriser l'historique de la phrase dans une cellule
(vecteur noté $\mathbf{h}$) qui s'interprète comme une mémoire. 

Le problème de prédiction de séquence est vu comme une succession
d'étapes de prédiction temporelles qui à chaque étape mettent à jour
la mémoire du système en fonction de l'état courant de la mémoire et
du symbole courant. 
La forme primitive d'un réseau de ce type est la suivante.
Soit une séquence de vecteurs $\mathbf{x}_t$ ($1\leq t \leq n$) qui est
donnée, le réseau prédit la séquence de vecteurs $\mathbf{y}_t$ comme suit:
\begin{align*}
\mathbf{y}_t &= \text{softmax}(\mathbf{W}_0 \mathbf{h}_t)    &(1 \leq t \leq n)\\
\mathbf{h}_t &= g(\mathbf{W}_1\mathbf{x}_t + \mathbf{W}_2  
\mathbf{h}_{t-1}+\mathbf{b} ) &(1 \leq t \leq n)
\end{align*}
Il faut remarquer que la mémoire $\mathbf{h}$ est mise à jour à chaque
étape temporelle. Pour la modélisation du langage, on utilisera en
général la forme où les données sont des embeddings, c'est-à-dire un
réseau de la forme:
\begin{align*}
\mathbf{y}_t &= \text{softmax}(\mathbf{W}_0 \mathbf{h}_t)  &(1 \leq t \leq n)\\
\mathbf{h}_t &= g(\mathbf{W}_1\mathbf{e}_t + \mathbf{W}_2
\mathbf{h}_{t-1}+\mathbf{b} )  &(1 \leq t \leq n)\\
\mathbf{e}_t &= \mathbf{E}\mathbf{x}_t  &(1 \leq t \leq n)
\end{align*}
où on suppose que chaque $\mathbf{x}_t$ est un vecteur one hot qui
code le mot $w_t$ pris dans la séquence $w_1\ldots w_n$.

Dans le cas du tagging, on observe que la probabilité de sortie du
modèle décrit ci-dessus s'interprète comme la probabilité 
$P(y_t | w_1\ldots w_t)$ car la mémoire du {\sc Rnn}
n'est pas bornée.  Et c'est cet aspect non borné qui lui donne son
originalité principale par contraste avec les autres modèles présentés
dans ce cours qui posent tous des hypothèses simplificatrices de type
markovienne.  

La prédiction avec un tel modèle est en général réalisée de manière
gloutonne. \`A chaque étape temporelle le tag prédit est celui dont le
score maximise la couche de sortie:
\begin{displaymath}
\hat{y}_t  = \mathop{\text{argmax}}_{y_t \in Y} \mathbf{y}_t
\end{displaymath}


\paragraph{Réseaux récurrents empilés}
Parmi les nombreuses variantes de réseaux récurrents, signalons le cas des
réseaux empilés. Il s'agit de réseaux de la forme: 
\begin{align*}
\mathbf{y}_t &= \text{softmax}(\mathbf{W}_0 \mathbf{h}^j_t)\\
\mathbf{h}^j_t &= g(\mathbf{W}^j_1\mathbf{h}^{j-1}_t + \mathbf{W}^j_2 \mathbf{h}^j_{t-1}+\mathbf{b}^j )\\
& \vdots\\
\mathbf{h}^1_t &= g(\mathbf{W}^1_1\mathbf{x}_t + \mathbf{W}^1_2 \mathbf{h}^1_{t-1}+\mathbf{b}^1 )
\end{align*}

Parmi ceux-ci, les réseaux bi-récurrents constituent un cas particulier emblématique. Il
s'agit de réseaux empilés à deux couches dont la forme élémentaire est
la suivante:
\begin{align*}
\mathbf{y}_t &= \text{softmax}(\mathbf{W}_0 \left[ \begin{array}{c}\mathbf{h}^b_t \\\mathbf{h}^f_t \end{array}\right])\\
\mathbf{h}^b_t &= g(\mathbf{W}^b_1\mathbf{x}_t + \mathbf{W}^b_2 \mathbf{h}^b_{t+1}+\mathbf{b}^b )\\
\mathbf{h}^f_t &= g(\mathbf{W}^f_1\mathbf{x}_t + \mathbf{W}^f_2 \mathbf{h}^f_{t-1}+\mathbf{b}^f )
\end{align*}
Ces réseaux bi-récurrents possèdent deux mémoires: $\mathbf{h}^b_t$ et
$\mathbf{h}^f_t$ qui représentent respectivement les contextes non
bornés droite et gauche du mot en position $t$. 

Cette dernière propriété permet de voir un bi-{\sc Rnn} comme un procédé
d'encodage de mots sur des vecteurs qui tient compte
du contexte dans lequel apparaît chaque mot.
Ainsi les vecteurs $\mathbf{h}^b_t$ et $\mathbf{h}^f_t$
peuvent être utilisés à la place de word embeddings classiques comme représentation des mots pour des tâches
additionnelles comme par exemple une tâche d'analyse syntaxique.  


\paragraph{Estimation des paramètres} L'estimation des paramètres pour
des réseaux récurrents se fait par maximum de vraisemblance à l'aide d'une descente de gradient
classique comme {\sc Sgd}. 
\`A chaque évaluation du gradient, pour l'ensemble des données,
l'algorithme de rétropropagation du gradient compare la prédiction du
modèle pour chaque mot à l'annotation de référence et met à jour les
poids de manière appropriée.

L'évaluation du gradient pose en général des problèmes formels
non négligeables pour les {\sc Rnn} standards (disparition ou explosion du gradient). Pour cette raison on
utilise en pratique des  variantes appelées {\sc Lstm} (long short
term memory network) ou {\sc Gru} (gated recurrent unit)
qui corrigent le problème mais dont les formulations explicites sont plus complexes.


\paragraph{Aspects pratiques}
Les jeux de données pour les modèles récurrents ont la forme $\mathop{\{(\mathbf{w}_i,\mathbf{t}_i)\}}_{i=1}^N$ 
où $\mathbf{w}_i$ représente une séquence de mots et $\mathbf{t}_i$
une séquence de tags. 

La descente de gradient de modèles récurrents peut, selon les cas,
demander un calcul long et intensif.
Pour des raisons d'efficacité tant quant à l'utilisation de {\sc Cpu}
que de {\sc Gpu}, les bibliothèques appliquent une
procédure de descente de gradient organisée en mini-batches. 
Les exemples d'un même mini batch sont traités en parallèle pour
rendre la  descente de gradient plus efficace.

Cette méthode impose que les séquences d'un même mini-batch ont
toutes exactement la même longueur. Lorsque cela n'est pas possible il
est d'usage d'ajouter des éléments factices au début ou à la fin de
séquences trop courtes ({\em padding}) et de tronquer des séquences
trop longues ({\em truncation}).


\paragraph{Réseaux de neurones récurrents pour la classification de phrases}
\`A côté des réseaux récurrents transductifs comme ceux utilisés pour
le cas de l'étiquetage morphosyntaxique, on utilise également des
réseaux agglomérants dont le but est de prédire une étiquette $y$ pour
une séquence d'observables $x_1\ldots x_n$ comme des mots ou des caractères.

Les cas d'utilisations sont par exemple : catégoriser un mot inconnu à
partir de la séquence de caractères qui le composent 
ou catégoriser une phrase par une catégorie de sentiment.
La forme d'un tel réseau récurrent est la suivante:
\begin{align*}
\mathbf{y}_t &= \text{softmax}(\mathbf{W}_0 \mathbf{h}_t) &(t = n)\\
\mathbf{h}_t &= g(\mathbf{W}_1\mathbf{x}_t + \mathbf{W}_2
\mathbf{h}_{t-1}+\mathbf{b} )& (1 \leq t \leq n)
\end{align*}
Lorsque les $\mathbf{x}_t$ sont produits par des embeddings de mots ou
de caractères, le réseau prend alors la forme suivante:
\begin{align*}
\mathbf{y} &= \text{softmax}(\mathbf{W}_0 \mathbf{h}_t) & (t = n)\\
\mathbf{h}_t &= g(\mathbf{W}_1\mathbf{e}_t + \mathbf{W}_2
\mathbf{h}_{t-1}+\mathbf{b} ) &(1 \leq t \leq n)\\
\mathbf{e}_t &= \mathbf{E}\mathbf{x}_t &  (1 \leq t \leq n)
\end{align*}

Il faut remarquer que $\mathbf{y}$ n'est calculé q'une seule fois lors de la dernière
étape temporelle. Dans ce contexte, on interprète la couche cachée de la dernière étape temporelle
$\mathbf{h}_n$ comme une représentation vectorielle de la séquence
tout entière (un
embedding de séquence).

Ce type de modèle peut être utilisé tel quel dans différents
contextes~: comme par exemple pour catégoriser des phrases en analyse de sentiments.
On peut également utiliser un tel réseau sur des séquences de
caractères pour prédire la catégorie d'un mot inconnu ou encore
utiliser $\mathbf{h}_n$ comme embedding 'morphologique' de mot et le
donner comme embedding d'entrée à un modèle d'étiquetage
morphosyntaxique ou d'analyse syntaxique.

Dans la pratique, et pour les mêmes raisons que pour les modèles transductifs de séquences, les {\sc
  Rnn} sont instanciés par des {\sc Lstm} ou des {\sc Gru}.



\section{Différenciation automatique et graphe de calcul}

Les réseaux de neurones s'analysent comme une composition, en général complexe, de fonctions à paramètres et à valeurs vectorielles. Celles-ci sont fréquemment non linéaires.

L'optimisation de telles fonctions se résoud en général par descente de gradient. Le calcul du vecteur de dérivées partielles n'est en général pas réalisé analytiquement mais par une méthode de différentiation automatique qui s'appuie sur la notion de {\bf graphe de calcul}.

Un graphe de calcul est un graphe acyclique orienté dont les feuilles représentent soit des paramètres soit des données et dont les noeuds représentent des fonctions (ou des opérateurs). Le graphe de calcul est une manière commode de représenter informatiquement une fonction.
Pour illustrer, prenons l'exemple de la fonction~:
\begin{displaymath}
f(x) = \sigma(\alpha\, \text{tanh}(a x + b) +\beta)
\end{displaymath}
dont la donnée est le réel $x$ et les paramètres sont les réels $a,b,\alpha,\beta$. Le graphe de calcul est le suivant~:
\begin{center}
\begin{tikzpicture}
\node[circle,fill=red!20] (times1) at (1,1) {$\times$};
\node[circle,fill=red!20] (plus1) at (2.5,2) {$+$};
\node[circle,fill=red!20] (tanh) at (2.5,3) {\tiny tanh};
\node[circle,fill=red!20] (times2) at (0,4) {$\times$};
\node[circle,fill=red!20] (plus2) at (3,5) {$+$};
\node[circle,fill=red!20] (sigmoid) at (3,6) {$\sigma$};

\node[circle,fill=blue!20] (alpha) at (-2,3) {$\alpha$};
\node[circle,fill=blue!20] (beta) at (6,4) {$\beta$};
\node[circle,fill=blue!20] (a) at (0,0) {$a$};
\node[circle,fill=blue!20] (x) at (2,0) {$x$};
\node[circle,fill=blue!20] (b) at (4,1) {$b$};

\draw (times1) -- (a);
\draw (times1) -- (x);
\draw (plus1) -- (times1);
\draw (plus1) -- (b);
\draw (tanh) -- (plus1);
\draw (times2) -- (alpha);
\draw (times2) -- (tanh);
\draw (plus2) -- (times2);
\draw (plus2) -- (beta);
\draw (sigmoid) -- (plus2);
\end{tikzpicture}
\end{center}

\paragraph{Propagation avant} Un graphe de calcul peut être utilisé pour valuer une fonction si on connait les valeur des paramètres et qu'on reçoit une donnée. \'Evaluer une fonction à l'aide d'un graphe de calcul c'est utiliser l'algorithme de propagation avant.

Sur l'exemple précédent, en supposant la valuation des paramètres suivante~:
\begin{center}
\begin{tabular}{ll}\hline
$a$       & 1\\
$b$       & 2\\
$\alpha$  & 0.5\\
$\beta$   & -1\\\hline
$x$       & 1\\\hline
\end{tabular}
\end{center}
on obtient le graphe de calcul valué suivant~:
\begin{center}
\begin{tikzpicture}
\node[circle,fill=red!20] (times1) at (1,1) {$\times$};
\node[circle,fill=red!20] (plus1) at (2.5,2) {$+$};
\node[circle,fill=red!20] (tanh) at (2.5,3) {\tiny tanh};
\node[circle,fill=red!20] (times2) at (0,4) {$\times$};
\node[circle,fill=red!20] (plus2) at (3,5) {$+$};
\node[circle,fill=red!20] (sigmoid) at (3,6) {$\sigma$};

\node[circle,fill=blue!20] (alpha) at (-2,3) {$\alpha$};
\node[circle,fill=blue!20] (beta) at (6,4) {$\beta$};
\node[circle,fill=blue!20] (a) at (0,0) {$a$};
\node[circle,fill=blue!20] (x) at (2,0) {$x$};
\node[circle,fill=blue!20] (b) at (4,1) {$b$};

\node (aval) at (a.north west) {\bf\scriptsize 1};
\node (bval) at (b.north east) {\bf\scriptsize 2};
\node (xval) at (x.north east) {\bf\scriptsize 1};
\node (times1val) at (times1.north west) {\bf\scriptsize 1};
\node (plus1val) at (plus1.north east) {\bf\scriptsize 3};
\node (tanhval) at (tanh.north east) {\bf\scriptsize 0.99};
\node (alphaval) at (alpha.north west) {\bf\scriptsize 0.5};
\node (times2val) at (times2.north west) {\bf\scriptsize 0.5};
\node (betaval) at (beta.north east) {\bf\scriptsize -1};
\node (plus2val) at (plus2.north east) {\bf\scriptsize -0.5};
\node (sigmoidval) at (sigmoid.north east) {\bf\scriptsize 0.38};

\draw (times1) -- (a);
\draw (times1) -- (x);
\draw (plus1) -- (times1);
\draw (plus1) -- (b);
\draw (tanh) -- (plus1);
\draw (times2) -- (alpha);
\draw (times2) -- (tanh);
\draw (plus2) -- (times2);
\draw (plus2) -- (beta);
\draw (sigmoid) -- (plus2);
\end{tikzpicture}
\end{center}

\paragraph{Propagation arrière} L'algorithme de descente de gradient
demande à chaque itération de réévaluer le gradient de la fonction, c'est-à-dire le vecteur de dérivées partielles pour chacune des variables de la fonction objective. Le graphe de calcul permet également d'automatiser cette opération.

Pour en comprendre le fonctionnement, rappelons nous la règle de dérivation des fonctions composées~:
\begin{displaymath}
(f \circ g)' (x) = f'(g(x)) g'(x) 
\end{displaymath}
Celle-ci peut s'exprimer également en notation de Leibniz en donnant un nom à $g(x)$, comme par exemple $y=g(x)$~:
\begin{displaymath}
\frac{\delta f}{\delta x} =\frac{\delta f}{\delta y} \frac{\delta g}{\delta x}
\end{displaymath}
Ce rappel effectué, on propose maintenant de continuer notre exemple en dérivant d'abord analytiquement le gradient de la fonction par rapport à chacun des paramètres $a,b,\alpha,\beta$ en utilisant la règle de composition. Pour simplifier la notation, on propose d'abord de nommer les différentes sous-fonctions~:
\begin{align*}
    g &= \alpha\, \text{tanh}(a x + b) +\beta\\
    h &= \alpha\,\text{tanh}(a x + b) \\
    i &= \text{tanh}(a x + b)\\
    j &= a x + b\\
    k &= a x 
\end{align*}
On peut ainsi exprimer aisément les dérivées partielles pour les différents paramètres\footnote{Rappelons nous que la dérivée de la fonction sigmoide est la fonction $\sigma'(x) = \sigma(x)(1-\sigma(x))$ et que la dérivée de la fonction tangent hyperbolique est la fonction $tanh'(x) = 1-tanh(x)^2$ }~:
\begin{align*}
\frac{\partial f}{\partial \beta} = \frac{\partial \sigma}{\partial g} \frac{\partial + }{\partial \beta} &=  \sigma(g)(1-\sigma(g)) (0-1)\\
    &= \sigma(-0.5)(1-\sigma(-0.5)) (-1)\\
    &= -0.23\\
\frac{\partial f}{\partial \alpha} = \frac{\partial \sigma}{\partial g}\frac{\partial +}{\partial h}\frac{\partial \times}{\partial \alpha}  &=  \sigma(g)(1-\sigma(g)) i\\
&=\sigma(-0.5)(1-\sigma(-0.5)) 0.99 \\
&=0.23\\
 \frac{\partial f}{\partial b} = \frac{\partial \sigma}{\partial g}\frac{\partial +}{\partial h}\frac{\partial \times}{\partial i}\frac{\partial\, \text{tanh}}{\partial j}  \frac{\partial +}{\partial b}&=\sigma(g)(1-\sigma(g)) (1-\text{tanh}^2(j)) 1\\
 &= \sigma(-0.5)(1-\sigma(-0.5)) (1-\text{tanh}^2(3))\\
 &= 0.002\\
 \frac{\partial f}{\partial a} = \frac{\partial \sigma}{\partial g}\frac{\partial +}{\partial h}\frac{\partial \times}{\partial i}\frac{\partial\, \text{tanh}}{\partial j}  \frac{\partial +}{\partial k}\frac{\partial \times}{\partial a}&=\sigma(g)(1-\sigma(g)) (1-\text{tanh}^2(j)) x\\
 &=\sigma(-0.5)(1-\sigma(-0.5)) (1-\text{tanh}^2(3)) 1\\
 &=0.002
\end{align*}
On voit que le développement analytique, qui repose sur l'utilisation de la règle de dérivation des fonctions composées 
produit pour chaque paramètre une multiplication qui correspond au produit des dérivées des fonctions que l'on trouve sur le chemin qui mène de la racine de l'arbre à la feuille qui représente ce paramètre.

Une implémentation informatique de ce graphe de calcul pour calculer le vecteur gradient d'une fonction objective est une application  de l'{\bf algorithme de rétropropagation du gradient}. En général l'exécution de l'algorithme garde en mémoire les valeurs déjà calculées et organise le calcul en suivant une structure de graphe acyclique orienté pour éviter les reduplications, à la manière des algorithmes de programmation dynamique.

\begin{center}
\begin{tikzpicture}
\node[circle,fill=red!20] (times1) at (1,1) {$\times$};
\node[circle,fill=red!20] (plus1) at (2.5,2) {$+$};
\node[circle,fill=red!20] (tanh) at (2.5,3) {\tiny tanh};
\node[circle,fill=red!20] (times2) at (0,4) {$\times$};
\node[circle,fill=red!20] (plus2) at (3,5) {$+$};
\node[circle,fill=red!20] (sigmoid) at (3,6) {$\sigma$};

\node[circle,fill=blue!20] (alpha) at (-2,3) {$\alpha$};
\node[circle,fill=blue!20] (beta) at (6,4) {$\beta$};
\node[circle,fill=blue!20] (a) at (0,0) {$a$};
\node[circle,fill=blue!20] (x) at (2,0) {$x$};
\node[circle,fill=blue!20] (b) at (4,1) {$b$};

\node (aval) at (a.north west) {\bf\scriptsize 1};
\node (bval) at (b.north east) {\bf\scriptsize 2};
\node (xval) at (x.north east) {\bf\scriptsize 1};
\node (times1val) at (times1.north west) {\bf\scriptsize 1};
\node (plus1val) at (plus1.north east) {\bf\scriptsize 3};
\node (tanhval) at (tanh.north east) {\bf\scriptsize 0.99};
\node (alphaval) at (alpha.north west) {\bf\scriptsize 0.5};
\node (times2val) at (times2.north west) {\bf\scriptsize 0.5};
\node (betaval) at (beta.north east) {\bf\scriptsize -1};
\node (plus2val) at (plus2.north east) {\bf\scriptsize -0.5};
\node (sigmoidval) at (sigmoid.north east) {\bf\scriptsize 0.38};

\node (aback) at (a.south west) {\bf\scriptsize 0.002};
\node (bback) at (b.south east) {\bf\scriptsize 0.002};
\node (xback) at (x.south east) {\bf\scriptsize -};
\node (times1back) at (times1.south west) {\bf\scriptsize 0.002};
\node (plus1back) at (plus1.south east) {\bf\scriptsize 0.002};
\node (tanhback) at (tanh.south east) {\bf\scriptsize 0.002};
\node (alphaback) at (alpha.south west) {\bf\scriptsize 0.23};
\node (times2back) at (times2.south west) {\bf\scriptsize 0.23};
\node (betaback) at (beta.south east) {\bf\scriptsize -0.23};
\node (plus2back) at (plus2.south east) {\bf\scriptsize 0.23};
\node (sigmoidback) at (sigmoid.south east) {\bf\scriptsize 0.23};


\draw (times1) -- (a);
\draw (times1) -- (x);
\draw (plus1) -- (times1);
\draw (plus1) -- (b);
\draw (tanh) -- (plus1);
\draw (times2) -- (alpha);
\draw (times2) -- (tanh);
\draw (plus2) -- (times2);
\draw (plus2) -- (beta);
\draw (sigmoid) -- (plus2);
\end{tikzpicture}
\end{center}

On généralise ce premier exemple au cas d'un réseau de neurones quelconque en remplaçant les entrées et les sorties par des valeurs vectorielles plutôt que scalaires. Les paramètres prennent alors en général la forme de matrices (ou de vecteurs lorsqu'il s'agit des biais). Cette généralisation ne change rien au principe de l'algorithme de rétropropagation exposé ci-dessus.

L'exemple dévéloppé ici se réexprime sous forme vectorielle par un réseau du type perceptron multi-couche classique~:
\begin{displaymath}
f(\mathbf{x}) = \sigma(\mathbf{A}_1 \text{tanh}(\mathbf{A}_2\mathbf{x}+\mathbf{b}_2) + \mathbf{b}_1)
\end{displaymath}

\paragraph{Graphes de calculs dynamiques en NLP} ...


\section{Calculs massivement parallèles sur GPU}

Les modèles de Deep Learning contemporains se caractérisent par une certaine lenteur à l'apprentissage qui est notamment liée à la quantité considérable de paramètres dans les modèles.

\paragraph{Observation de départ}
On observe toutefois que les modèles de Deep Learning réalisent essentiellement des opérations sur des matrices (ou des Tenseurs\footnote{Un tenseur est une généralisation de vecteurs ou de matrices à un ordre supérieur.}) et que ces opérations se parallélisent très facilement. 

Pour illustrer rappelons nous qu'un modèle linéaire est un modèle de la forme 
\begin{displaymath}
y = \mathbf{w}^T \mathbf{x}
\end{displaymath}
c'est-à-dire un produit scalaire d'un vecteur ligne $\mathbf{w}$
qui représente les paramètres et d'un vecteur colonne $\mathbf{x}$ qui représente un exemple dans un jeu de données. Si on organise le jeu de données de $N$ exemples comme une matrice $\mathbf{X}$ de $N$ colonnes, le modèle linéaire réalise l'opération~:
\begin{displaymath}
\mathbf{y} = \mathbf{w}^T \mathbf{X}
\end{displaymath}
ce qui a pour effet de réaliser toutes les opérations de prédiction
d'un jeu de données en une seule opération. Conceptuellement cette opération matricielle se parallélise très simplement car elle correspond à $N$ opérations indépendantes de multiplication de $\mathbf{w}$ par les vecteurs $\mathbf{x}_1\ldots \mathbf{x}_N$.

C'est très exactement le type d'opérations qui sont réalisées très efficacement et en parallèle par un GPU moderne (en plus des opérations purement graphiques).

\paragraph{Architecture matérielle et usage du GPU} L'usage du GPU pose toutefois un problème pratique dont la cause provient de l'architecture même des ordinateurs. Schématiquement les ordinateurs suivent une architecture de von Neumann~:
\begin{center}
\begin{tikzpicture}

\node[draw] (C) at (2,0) {
\begin{tikzpicture}
\node[draw,fill=red!30] (CPU) at (0,0)  {CPU};
\node[draw,fill=blue!30!green!20] (M) at (0,1)  {Mémoire};
\draw[very thick] (CPU) -- (M);
\end{tikzpicture}
};
\node (ES) at (8,0) {\em Entrées/Sorties};
\node[draw,fill=blue!30] (GPU) at (5,-1) {GPU};
\draw[<->] (C) -- (ES);
\draw (C) -- (5,0) -- (GPU);
\end{tikzpicture}
\end{center}
On observe que suivant cette architecture le processeur est lié à la mémoire par un bus qui permet une communication rapide avec le CPU alors que le GPU fait partie des dispositifs d'entrée sortie (au même titre que la souris, le clavier ou la carte son pour ne citer que les principaux). Le bus qui connecte les appareils d'entrée/sortie à la mémoire ne permet par contre qu'une communication lente.

La conséquence pratique est que le GPU  autorise de réaliser des opérations matricielles très efficacement mais que le transfert de données depuis (et vers) la mémoire centrale est lent. 

Par conséquent la méthode de programmation avec GPU consiste à minimiser le transfert de données entre le GPU et l'unité centrale. Cela se fait en réalisant peu d'opérations impliquant de gros calculs plutôt qu'en multipliant des petits calculs qui répètent le transfert de données sur un bus lent.

\paragraph{La méthode du (mini-)batch en deep learning}
Comme la mémoire sur un GPU est limitée, on stockera typiquement le jeu de données dans la mémoire centrale de la machine et on transfère successivement des {\bf batchs} d'exemples pour lesquels on va réaliser les calculs de prédiction\footnote{Avec la plupart des librairies modernes, les paramètres du modèle résident en permanence sur le GPU, ce sont les vecteurs $\mathbf{x}$ de données et $\mathbf{y}$ de prédictions qui sont transférés.}.

Dans le cas du modèle linéaire, plutôt que de répéter successivement des opérations de la forme $\mathbf{w}^T\mathbf{x}_i$ pour chaque vecteur $\mathbf{x}_i$ d'un jeu de données on préfère réaliser des opérations de la forme $\mathbf{w}^T\mathbf{X}$ où $\mathbf{X}$ est un mini-batch d'exemples $\mathbf{x}_i\ldots \mathbf{x}_{i+B}$ ($B$ est la taille du mini-batch). 

Dans un contexte de deep learning, l'utilisation de mini-batchs généralise le cas d'exemple donné pour le modèle linéaire à des modèles d'apprentissage profond de structure beaucoup plus complexe. Toutefois, on ne peut en général pas utiliser des batchs comportant un trop grand nombre d'exemples (comme la totalité du jeu de données) pour éviter de saturer la mémoire du GPU.

\paragraph{Batcher des données structurées} Pour la modélisation du langage, le cas classique est que la donnée du problème de prédiction ne se réduit pas à un simple vecteur $\mathbf{x}$. Une ligne de données est une séquence de vecteurs d'embeddings $\mathbf{X} = \mathbf{x}_1\ldots \mathbf{x}_n$, un par mot. Par exemple, pour le tagging le jeu de données est typiquement une liste d'exemples $D = \mathop{(\mathbf{X}_i,\mathbf{Y}_i)}_{i=1}^N$ où $\mathbf{X}_i$ et $\mathbf{Y}_i$ représentent des séquences d'embeddings de mots et des séquences d'embeddings de catégories

Batcher des telles données fonctionnerait simplement  si tous les exemples avaient exactement le même nombre de mots~:
\newcommand{\greenvec}[2]{
\draw [fill=blue!30!green!30] (#1-0.5,#2) rectangle (#1-0.25,#2+0.25);
\draw [fill=blue!30!green!30] (#1-0.25,#2) rectangle (#1,#2+0.25);
\draw [fill=blue!30!green!30] (#1,#2) rectangle (#1+0.25,#2+0.25);
\draw [fill=blue!30!green!30] (#1+0.25,#2) rectangle (#1+0.5,#2+0.25);
}

\begin{center}
\begin{tikzpicture}
\node (w1) at (0,0) {$w_1$};
\node (w2) at (2,0) {$w_2$};
\node (dots) at (4,-0.25) {$\ldots$};
\node (wn) at (6,0) {$w_n$};
\greenvec{0}{-0.5} 
\greenvec{2}{-0.5} 
\greenvec{6}{-0.5} 
\greenvec{0}{-1} 
\greenvec{2}{-1} 
\greenvec{6}{-1} 
\greenvec{0}{-1.5} 
\greenvec{2}{-1.5} 
\greenvec{6}{-1.5} 
\end{tikzpicture}
\end{center}
Or la réalité est différente~: les textes ou les phrases sont de {\bf longueur variable}. De telle sorte que certains éléments du batch (plus courts) ont des vecteurs manquants (par comparaison avec les éléments les plus longs)~:

\newcommand{\redvec}[2]{
\draw [fill=red!30] (#1-0.5,#2) rectangle (#1-0.25,#2+0.25);
\draw [fill=red!30] (#1-0.25,#2) rectangle (#1,#2+0.25);
\draw [fill=red!30] (#1,#2) rectangle (#1+0.25,#2+0.25);
\draw [fill=red!30] (#1+0.25,#2) rectangle (#1+0.5,#2+0.25);
}

\begin{center}
\begin{tikzpicture}
\node (w1) at (0,0) {$w_1$};
\node (w2) at (2,0) {$w_2$};
\node (dots) at (4,-0.25) {$\ldots$};
\node (wn) at (6,0) {$w_{n-1}$};
\node (wn) at (8,0) {$w_n$};

\greenvec{0}{-0.5} 
\greenvec{2}{-0.5} 
\greenvec{6}{-0.5} 
\greenvec{8}{-0.5} 
\greenvec{0}{-1} 
\greenvec{2}{-1} 
\redvec{6}{-1} 
\redvec{8}{-1} 
\greenvec{0}{-1.5} 
\greenvec{2}{-1.5} 
\greenvec{6}{-1.5} 
\redvec{8}{-1.5} 
\end{tikzpicture}
\end{center}
Pour contourner ce problème, il est d'usage~:
\begin{itemize}
    \item D'ajouter des vecteurs factices (en général nuls) dans les positions manquantes. (Technique de {\bf padding})
    \item De tronquer les exemples du batch de telle sorte que toutes les séquences de mots aient la même longueur. Les mots supplémentaires sont simplement ignorés. (Technique de {\bf troncation})
\end{itemize}

Plus généralement, le calcul par batchs est facile à mettre en oeuvre si la structure du réseau est identique (statique) pour tous les exemples du jeu de données. La mise en oeuvre du calcul par batchs est plus complexe lorsque la structure du réseau varie d'exemple à exemple (on parle de modèle dynamique). C'est ce dernier cas qui est classique pour la modélisation du langage. 

Lorsque la structure de données est plus complexe qu'une simple séquence, le problème de batching n'a pas de solution généralement admise par la communauté. Par exemple si il s'agit d'arbres, une méthode consiste à coder l'arbre par une séquence d'actions de shift et de reduce (cf chapitre de Parsing) ce qui permet de se ramener au cas séquentiel.




\section{Préparation des données}
On remarque que modéliser des données langagières écrites demande de déployer un certain nombre de traitements sujets à erreur, commme par exemple le codage du vocabulaire sur des entiers, les traitements par batchs\ldots. On donne ici quelques indications sur le workflow typique lié au prétraitement des données d'un modèle pour le TAL ainsi que quelques points de repères pour éviter les erreurs.

Il est commode de voir un jeu de données comme un fichier tabulaire de type {\tt csv}. Chaque colonne correspond à une variable (ou champ) et chaque ligne à une observation dans les données, comme par exemple~:
\begin{center}
\begin{tabular}{ccc}\hline
Source    & Phrase                          & Article cible \\\hline
Wikipedia & Le chat mange la souris         &  chat\\
Wikipedia & Trump est président des USA     &  Trump\\
\ldots    &\ldots                            &\ldots\\\hline
\end{tabular}
\end{center}
\`A partir d'un jeu de données, on peut identifier différentes étapes de traitement qui reviennent régulièrement~:
\begin{itemize}
\item Pour les colonnes qui contiennent du texte libre, 
il faut d'abord penser à donner une segmentation à ce texte.
\item Le codage de chaque colonne sur des entiers. Il s'agit d'identifier la totalité du vocabulaire utilisé dans la colonne et de définir une fonction qui envoie les symboles sur des entiers. Il faut se poser la question des symboles inconnus (mots du vocabulaire d'une langue mais non vus dans les données) et éventuellement prévoir des symboles artificiels pour coder les mots inconnus, des symboles de début de phrase, de fin de phrase\ldots 
\item Il faut le cas échéant charger un dictionnaire d'embeddings qui permet d'associer les mots à des vecteurs de type embedding
\item Il faut le cas échéant penser à structurer le jeu de données en batchs. Si les données sont des phrases de longueur variables, il faut également réaliser des opérations de padding et de troncation
\end{itemize}
L'ensemble de ces opérations peut soit se programmer manuellement soit s'appuyer sur des librairies comme {\tt torchtext}, ce qui permet d'éviter d'introduire des erreurs potentiellement difficiles à détecter lors de ces étapes de préparation des données 

\section{Deep Learning sur le cloud}

Comme les modèles de deep learning mobilisent des moyens de calcul importants,
on réalise fréquemment les calculs sur le "cloud", c'est-à-dire sur des serveurs de calcul distants qui comportent un bon nombre de CPU, une mémoire suffisante et parfois des GPU. 

Parmi les plus connus on citera par exemple {\sc Amazon Web Services}  (\url{https://aws.amazon.com}) et {\sc Google Colab} (\url{https://colab.research.google.com}).
Dans le cadre de ce cours on utilisera {\sc Kaggle} (\url{https://www.kaggle.com}) qui permet également d'évaluer des projets. Une compétition {\sc Kaggle} est organisée autour d'un jeu de données sur lequel il faut résoudre un problème d'apprentissage. Dans le cadre de ce cours, la procédure pour participer est la suivante~:
\begin{itemize}
    \item On reçoit une invitation à la compétition par email. Cette invitation renseigne le lien de la compétition.
    \item Depuis la page d'accueil de la compétition, il faut créer une machine virtuelle (appelée {\bf Kernel}). Dans le cadre de ce cours, on créera toujours un notebook python.
    \begin{itemize}
        \item Le kernel est un notebook python. On peut entrer du code dans la partie notebook. On dispose d'une console qui simule un shell et on peut monitorer ou configurer l'usage de la machine virtuelle en consultant les onglets appropriés.
        \item Comme le code est entré dans un navigateur web, il y a risque de le perdre lorsqu'on ferme la fenêtre.
    Il est recommandé de cliquer régulièrement sur le bouton commit (en haut à droite) pour sauvegarder.
    \item Lorsqu'on utilise un kernel dans une compétition, les données liées à la compétition sont préinstallées dans un répertoire dédié (sous {\tt ../input/}). Il s'agit de données d'entrainement et de données de test. Ces dernières sont vierges d'annotations.
    \item Le code réalisé dans un kernel sera destiné essentiellement à créer un fichier {\tt csv} qui représente les prédictions du modèle d'apprentissage. Ce fichier aura en général la forme suivante~:
    \begin{center}
    \begin{tabular}{cc}\hline
    idx & prédiction\\\hline
      1 &    A\\
      2 &    B\\
      3 &    A\\
      \ldots\\\hline
      \end{tabular}
      \end{center}
    \end{itemize}
    \item Lorsque le noyau a produit un fichier {\tt csv} satisfaisant, on peut décider de soumettre le résultat à la compétition.
    Il faut pour cela :
    \begin{itemize}
        \item Effectuer un commit
        \item  se reconnecter à la page d'accueil\footnote{Depuis l'éditeur de code, cliquer sur le {\bf\color{blue} K} bleu en haut à gauche.}, suivre l'onglet {\em Kernels}, cliquer sur le nom du kernel dont vous souhaitez soumettre les prédictions et enfin cliquer sur le bouton de soumission dans la page résumant ce kernel (onglet ouptut data).
    \end{itemize}
    \item Il est possible d'observer facilement la structure des jeux de données utilisés. Depuis la page d'accueil de la compétition, suivre l'onglet {\em Data} et explorer.
\end{itemize}
Remarquons que les calculs exécutés dans un kernel sont limités. 
Un kernel doit terminer toute exécution en moins de six heures et la quantité de données qu'il est possible d'écrire dans le kernel est de l'ordre de quelques Gigabytes (5Gb). Il est également possible de choisir le processeur utilisé~: on peut utiliser soit 4 CPUs soit 1 GPU pour réaliser les calculs.



\chapter{Représentations}

En {\sc Tal}, on fait de l'analyse syntaxique et de la syntaxe non pas pour décider
de la grammaticalité des phrases mais pour leur donner une structure
destinée à en construire le sens.

La problématique d'analyse syntaxique en {\sc tal} diffère de
la problématique d'analyse syntaxique en compilation où seuls les
programmes syntaxiquement corrects sont analysés sémantiquement.
En {\sc tal} il y a volonté de robustesse, c'est-à-dire que tout
énoncé doit recevoir une interprétation sémantique.

Deux types de représentations syntaxiques sont utilisées~: les
représentations dites en dépendances et les représentations dites en
constituants.

Les représentations en constituants sont utilisées traditionellement en linguistique
pour représenter la strucuration des phrases en groupes de mots~:
\begin{center}
\Tree[.S  [.NP [.N  Pierre ] ] [.VN  [.V mange ] ] [.NP [.D une ] [.N salade ] ] ]
\end{center}
Elles sont aussi utilisées explicitement pour aider à la construction de la représentation sémantique 
en indiquant un parenthésage qui permet de décider comment associer les sous-phrases pour calculer compositionnellement le sens
(\ref{fig-bracketing})

\begin{figure}[htbp]
\begin{center}
\begin{tabular}{cc}\toprule
\Tree[.$\times$ [.$\times$ ( 3 [.+ ( 3 2 ) ] ) ]  4  ]
&
\Tree[.+ [.$\times$ ( 3 3 ) ] [.$\times$ 2 4 ]  ] \\\midrule
(3 $\times$ ( 3 + 2 ) ) $\times$ 4
&
(3 $\times$  3) + ( 2  $\times$ 4)\\
\bottomrule
\end{tabular}
\end{center}
\caption{\label{fig-bracketing} Le parenthésage permet de changer l'interprétation de la phrase}
\end{figure}


Les arbres en dépendances sont en général utilisés directement (en tous cas les relations qu'ils représentent)
pour extraire un contenu sémantique de la phrase, comme par exemple pour interfacer avec une base de données.
\begin{center}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
N        \& V         \& D    \& N\\
Pierre \& mange \& une \& salade\\
\end{deptext}
\depedge[hide label]{2}{1}{ }
\depedge[hide label]{2}{4}{ }
\depedge[hide label]{4}{3}{ }
\end{dependency}
\end{center}


\paragraph{Arbres en constituants} Les arbres en constituants sont généralement vus comme des traces de dérivation de grammaires \ac{cfg}.
En général la grammaire n'est pas définie explicitement car pour un ensemble de symboles non terminaux $N$ et un ensemble 
de mots $W$ on autorise toute règle de la forme~:
\begin{eqnarray*}
X_i &\rightarrow &X_j X_k \qquad \{X_i,X_j,X_k\} \in N^3\\
X_i &\rightarrow &X_k X_j \qquad \{X_i,X_j,X_k\} \in N^3\\
X_i & \rightarrow & w       \qquad w \in W
\end{eqnarray*}

Dans ce contexte le problème d'analyse syntaxique consiste à déterminer le (ou les) arbres d'analyse 
les plus plausibles parmi l'ensemble exponentiel des parenthésages possibles de la phrase.

Voir les arbres en constituants comme des traces de dérivations d'une grammaire libre de contexte (même laxiste) permet de préserver les définitions valables pour \ac{pcfg},
qui sert de référentiel commun utilisé pour ordonner les différentes arbres d'analyse est {\sc pcfg} à partir duquel sont dérivés les modèles d'apprentissage alternatifs.











\section{Arbres de dépendances}






\chapter{Analyse syntaxique en constituants}


L'analyse en constituants est une représentation de la structure des phrases relativement 
ancienne en linguistique formelle~: les constituants sont  un parenthésage des mots de la phrase 
qui peut servir à en calculer sa sémantique à l'aide de méthodes compositionnelles.

Traditionnellement les représentations en constituants sont vues comme des traces des opérations de réécriture successives 
réalisées par une grammaire générative indépendante du contexte. 
Une grammaire formelle définit un langage,  c'est-à-dire un ensemble de phrases dites grammaticales qu'il est possible de dériver de l'axiome 
par réécritures successives. Les séquences de mots qu'il n'est pas possible d'engendrer à l'aide de la grammaire sont dites non grammaticales.

Dans ce qui suit, on s'intéresse au problème d'analyse dit robuste. 
C'est-à-dire que la notion de grammaticalité est délaissée au profit d'un mécanisme d'analyse statistique
capable de donner une structure en arbre pour toute séquence de mots.

De plus on sait que le problème d'ambiguité est massif pour l'analyse syntaxique, les causes proviennent essentiellement de problèmes
liés à l'attachement de syntagmes prépositionnels et de résolution de portée de la coordination. C'est pour apporter une méthode de déterminisation
(ou de choix) des analyses que l'on s'intéresse à ajouter une composante statistique destinée à la désambiguisation.

\begin{figure}[htbp]
\begin{center}
\Tree [.S [.N Pierre ] [.V mange ] [.NP [.D une ] [.N salade ]  [.PP [.P avec ] [.NP [.D des ] [.N tomates ] ] ] ] ]
\end{center}
\caption{Un arbre de constituants}
\end{figure}

On introduit ici quelques algorithmes d'analyse syntaxique augmentés de pondérations statistiques
calculées par  des modèles discriminants. Ces algorithmes supposent que les arbres à manipuler sont 
sous-forme binaire (en forme normale de Chomsky). On commence donc par introduire ce type de transformation
avant de présenter l'algorithme de Cocke Kasami Younger comme une extension de
l'algorithme de Viterbi, l'algorithme de Knuth comme une extension de l'algorithme de Dijkstra et finalement
les méthodes d'analyse en constituants par transitions.

\section{Forme normale}

Dans ce qui suit, on suppose manipuler des arbres de constituants engendrés par une grammaire 
en forme normale de Chomsky ({\sc cnf})~: les arbres du treebank original sont transformés en arbres binaires et les résultats internes 
d'analyse sont débinarisés en dernière étape.
L'usage de cette transformation permet de simplifier la conception des algorithmes d'analyse.
Il ne s'agit que de construire des arbres binaires.

Une grammaire en forme normale de Chomsky est une grammaire
dont les règles ont nécessairement une des formes suivantes~:
\begin{eqnarray}
\label{r-binary} A&\rightarrow& B\quad C\\
\label{r-unary} A&\rightarrow& a
\end{eqnarray}
où $A,B, C \in N$ et $a \in \Sigma$.

\paragraph{Longueur des dérivations} On peut remarquer que le nombre d'étapes de dérivation pour construire une séquence de terminaux de longueur $n \leq 1$ à partir de l'axiome 
vaut  $\eta = 2n-1$ pour une grammaire en forme normale de Chomsky.
On montre cela en considérant deux cas.
Dans le cas où $n=1$, la seule opération de réécriture à partir de l'axiome fait intervenir la règle ({\ref{r-unary}}) $\eta = 1 = 2-1$.
Dans le cas où $n > 1$, la première opération de réécriture  à partir de l'axiome fait intervenir la règle ({\ref{r-binary}}),
ce qui crée une séquence de symboles de longeur 2. Toute opération de réécriture qui fait intervenir à nouveau la règle 
({\ref{r-binary}}) augmente la longueur de la séquence de symboles de 1. Par conséquent il faut $n-1$ étapes de dérivation pour produire une 
séquence de symboles non terminaux de longueur $n$. Comme il faut nécessairement utiliser $n$ fois la règle ({\ref{r-unary}}) pour produire les terminaux,
on a au total $2n-1$ étapes de dérivation pour produire la séquence à l'aide d'une grammaire en forme normale de Chomsky.

Cette propriété sur la longueur des dérivations est régulièrement réutilisée (parfois de manière très indirecte) pour borner le nombre d'étapes 
de dérivation des algorithmes d'analyse syntaxique présentés dans ce document.

\paragraph{Transformation des arbres}
Une des première étapes de traitement lors de la mise au point d'un analyseur statistique en constituants consiste à transformer le treebank original
en un treebank dont les arbres représentent des dérivations d'une grammaire en forme normale de Chomsky. 
Pour ce faire, on suppose en général que les arbres du treebank ont tous le même symbole racine et que ce symbole n'est pas utilisé pour catégoriser des noeuds autres
que la racine. 

Les deux opérations de transformation qu'il faut réaliser consistent (a) à supprimer les branches unaires qui n'introduisent pas
de non terminaux et (b) à réduire les branchements $n$-aires $(n > 2)$.

Soit la branche unaire qui est la séquence de symboles  $X_1, X_2 \ldots X_d$ telle que $X_i\in N$, 
l'algorithme de fermeture des symboles unaires consiste à remplacer cette branche par le nouveau symbole non terminal
$X_1+X_2+\ldots + X_n$ (où $+$ représente la concaténation). On illustre le procédé sur l'exemple donné en Figure \ref{fig-unaries}.

\begin{figure}[htbp]
\begin{center}
\begin{tabular}{cc}\toprule
\Tree[.S  [.$X_1$ [.$X_2$  [.$X_3$  a ] ] ] [.Y b ] ]
&
\Tree[.S  [.$X_1+X_2+X_3$ a ] [.Y b ] ]\\\midrule
Arbre original&Arbre en {\sc cnf}\\\bottomrule
\end{tabular}
\end{center}
\caption{\label{fig-unaries}Exemple de réduction des règles unaires.}
\end{figure}

Lorsque l'arbre en constituants présente des sous-arbres qui instancient des règles de la forme $r_0 = X\rightarrow A_1, A_2\ldots A_n$ avec $n > 2$,
l'algorithme de binarisation consiste à (1) remplacer $r_0$ par la règle $r_1 = X\rightarrow A_1 A_2+ \ldots +A_n$ 
en créant le nouveau non terminal  $A_2+ \ldots +A_n$ et à (2) introduire
la règle $r_2 = A_2+ \ldots +A_n \rightarrow A_2,\ldots , A_n$ sous ce nouveau non terminal. La transformation est récursive et s'applique à nouveau sur $r_2$
puis sur toute nouvelle $r_i$ nouvellement introduite dans l'arbre d'arité supérieure à 2. 
Cette méthode s'appelle la binarisation droite. On illustre le procédé sur l'exemple donné en Figure \ref{fig-markovization}.

Alternativement, on peut binariser par la gauche. Dans ce cas on remplace $r_0 = X\rightarrow A_1,\ldots , A_{n-1},A_n$ par une règle de la forme
$r_1 = X\rightarrow A_1 + \ldots + A_{n-1}, A_n$ et en introduisant la règle $r_2 = A_1 + \ldots + A_{n-1} \rightarrow A_1\ldots A_{n-1}$ 
et ce recursivement jusqu'à ce que la règle $r_i$ nouvellement introduite ait une arité de 2. 
Cette méthode s'appelle la binarisation gauche et on illustre le procédé sur l'exemple donné en Figure \ref{fig-markovization}.

\begin{figure}[htbp]
\begin{center}
\scalebox{0.75}{
\begin{tabular}{cccc}\toprule
\Tree[.X [.$A_1$ a ] [.$A_2$ a ] [.$A_3$ a ] [.$A_4$ a ] ]
&
\Tree[.X [.$A_1$ a ] [.$A_2+A_3+A_4$ [.$A_2$ a ] [.$A_3+A_4$  [.$A_3$ a ] [.$A_4$  a ] ]  ]  ]
&
\Tree[.X [.$A_1+A_2+A_3$  [.$A_1+A_2$ [.$A_1$ a ] [.$A_2$ a ] ] [.$A_3$  a ] ] [.$A_4$  a ] ]
&
\Tree[.X [.${\cal X}$  [.${\cal X}$ [.$A_1$ a ] [.$A_2$ a ] ] [.$A_3$  a ] ] [.$A_4$  a ] ]
\\
\midrule
Arbre original&Binarisation droite&Binarisation gauche&Markovisation gauche\\
\bottomrule
\end{tabular}
}
\end{center}
\caption{\label{fig-markovization}Exemples de binarisations}
\end{figure}
Des variantes pratiques de binarisation sont utilisées sous le nom de markovisation des arbres. 
Celles-ci consistent à réduire la quantité de symboles non terminaux artificiels créés par la procédure de binarisation.
On peut par exemple décider d'utiliser un symbole artificiel ${\cal X}$ correspondant à la racine du sous arbre binarisé
(c'est-à-dire au symbole en partie gauche de la règle $r_0$) en lieu et place des concaténations de symboles réalisées par la procédure exacte. On illustre le procédé sur l'exemple donné en Figure \ref{fig-markovization}.







\section{Algorithmes de programmation dynamique et forêt d'analyse}

\paragraph{Représentation} La représentation supposée par les algorithmes ascendants de Knuth et CKY est fondée sur la notion d'empan ({\em span}).
Une phrase $w_1 \ldots w_n$ est représentée par une séquence d'états $0\ldots n$ 
reliés par des transitions $(i,i+1)$ étiquetées  par le mot $w_{i+1}$. 
On notera une telle transition par le triplet $\langle i,i+1,w_{i+1} \rangle$.

Par exemple, on représente la phrase {\em le chat dort} comme suit~:
\begin{center}
\begin{tabular}{cccccccc}
0  &le &1 &chat &2 &dort& 3
\end{tabular}
\end{center}
et on représente que le mot {\em chat} couvre l'empan $(1,2)$ par le triplet $\langle 1,2,chat\rangle$. 
La notion de triplet (ou d'item d'analyse) se généralise également pour représenter des empans couverts par des symboles
non terminaux lors d'une analyse. Par exemple on notera $\langle 0,2, NP \rangle$ pour indiquer qu'un groupe nominal couvre l'empan 
$(0,2)$. De manière générale un item d'analyse a la forme~:
\begin{displaymath}
\langle i,j, X\rangle
\end{displaymath}
où $i,j$ représentent l'empan de l'item et $X$ est un mot ($X\in \Sigma$) ou un symbole non terminal ($X \in N$).

Les algorithmes asecendants combinent successivement des items contigus à l'aide d'une règle de réduction unique~:
\begin{equation}
\label{eq-cky-reduce}
\frac{\langle i,k, Y_1\rangle\quad\langle k,j,Y_2 \rangle}{\langle i,j, X\rangle} \qquad X \in N
\end{equation}
qui indique que l'arbre de racine $Y_1$ qui couvre l'empan $(i,k)$ se combine avec l'arbre de racine
$Y_2$ qui couvre l'empan contigu $(k,j)$ pour former l'arbre de racine $X$ qui couvre l'empan
$(i,j)$.
On peut résumer explicitement les opérations réalisées par ce type d'algorithme par le système déductif 
donné en figure \ref{fig-deductive}.
\begin{figure}[htbp]
\begin{center}
\begin{displaymath}
\begin{array}{lll}
\mathbf{init} & \langle i,i+1, w_{i+1} \rangle& 0\leq i < n\\
\mathbf{reduce}&\frac{\langle i,k, Y_1\rangle\quad\langle k,j,Y_2 \rangle}{\langle i,j, X\rangle} & X \in N\\
\mathbf{but}&\langle 0,n, X \rangle
\end{array}
\end{displaymath}
On suppose une phrase : $w_1\ldots w_n$
\end{center}
\caption{\label{fig-deductive}Système de déduction pour l'analyse ascendante}
\end{figure}


On peut remarquer que contrairement à la présentation classique de CKY, la règle de réduction donnée en (\ref{eq-cky-reduce})
ne suppose pas de règle de grammaire explicite (comme $X\rightarrow Y_1 Y_2$). 
Au contraire tout symbole $X\in N$ peut servir de symbole  racine pour le nouvel arbre ainsi créé.
 
\paragraph{Représenter l'ambiguité}
Une telle procédure d'analyse crée de l'ambiguité. 
Pour une même séquence de mots $w_0\ldots w_n$, on s'attend en théorie à  un nombre 
exponentiel d'arbres d'analyse.
La {\bf forêt} d'analyse est une structure de données qui permet de représenter formellement un tel ensemble d'analyses de manière compacte.
On illustre en Figure \ref{fig-forest} une forêt (à droite) qui encode les deux analyses données à gauche.
Formellement, 
une forêt correspond à un hypergraphe $H=\langle V,E \rangle$ dont les noeuds sont les items d'analyse $\langle i,j,X\rangle$ et dont les hyperarcs
sont des couples $(h,v_1\ldots v_k)$ où $h\in V$ et où $v_i \in V$.
Ainsi en figure \ref{fig-forest}, la forêt comporte six noeuds 
\begin{displaymath}
V = \{ \langle 0,3,X \rangle, \langle 0,2,X \rangle, \langle 1,3,X \rangle , \langle 0,1,w_1 \rangle,
 \langle 1,2,w_2 \rangle, \langle 2,3,w_3 \rangle \}
\end{displaymath}
et les hyperarcs~: 
\begin{eqnarray*}
E &= &\{( \langle 0,3,X \rangle, \langle 0,2,X \rangle  \langle 2,3,w_3 \rangle ),\\
&&( \langle 0,3,X \rangle, \langle 0,1,w_1 \rangle  \langle 1,3,X \rangle ),\\
&&( \langle 0,2,X \rangle, \langle 0,1,w_1 \rangle  \langle 1,2,w_2 \rangle ),\\
&&( \langle 1,3,X \rangle, \langle 1,2,w_2 \rangle  \langle 2,3,w_3 \rangle ),\\
&&( \langle 0,1,w_1 \rangle, \epsilon ),\\
&&( \langle 1,2,w_2 \rangle, \epsilon ),\\
&&( \langle 2,3,w_3 \rangle, \epsilon )\}
\end{eqnarray*}

 
\begin{figure}[htbp]
\begin{center}
\begin{tabular}{ccc}\toprule
\begin{forest}
 [X  [X [$w_1$,tier=word] [$w_2$,tier=word] ] [$w_3$,tier=word ] ]
\end{forest}
&
\begin{forest}
 [X  [$w_1$,tier=word] [X[$w_2$,tier=word] [$w_3$,tier=word ] ]  ]
\end{forest}
&
\begin{tikzpicture}
\node  (leftn) at (0,0) {$w_1$};
\node (centern)  at (1,0) {$w_2$};
\node (rightn) at (2,0) {$w_3$};

\node (xleft) at (0.25,1) {X};
\node (xright) at (1.75,1) {X};
\node (xtop) at (1,2) {X};
\draw[-] (xleft) --  (leftn);
\draw[-] (xleft) --  (centern);
\draw[-] (xtop) --  (xleft);
\draw[-] (xtop) --  (rightn);

\draw[-,dashed] (xtop) --  (leftn);
\draw[-,dashed] (xtop) --  (xright);
\draw[-,dashed] (xright) --  (rightn);
\draw[-,dashed] (xright) --  (centern);
\end{tikzpicture}\\\midrule
{\sc Analyse A}&{\sc Analyse B}&{\sc Forêt}
\\\bottomrule
\end{tabular}
\end{center}
\caption{\label{fig-forest}Représentation de l'ambiguité}
\end{figure}

On va voir que les algorithmes de Knuth et CKY sont deux méthodes de construction d'une forêt d'analyse
(ou d'hypergraphe pondéré) qui utilisent le système de déduction donné en figure \ref{fig-deductive})
mais qui construisent les noeuds et les hyperarcs en utilisant un ordre différent.
Pour celà on commence par définir formellement la notion d'hypergraphe telle qu'elle est utilisée en analyse syntaxique
\cite{huang-2008,gallo-1993}.

\subsection{Notion d'hypergraphe (et de forêt)}

\begin{definition}[Hypergraphe] Un hypergraphe (orienté)  $H = \langle V,E \rangle$ est un couple
où $V$ est un ensemble de noeuds et $E$ est un ensemble d'hyperarcs. Un hyperarc $e\in E$
est un couple $e=\langle h, v_1\ldots v_k \rangle$ où $h\in V$ est la tête et $v_1\ldots v_k \in V^k$ est la queue.
Dans le cas où l'hypergraphe est pondéré on définit une fonction de score $s :E\mapsto \mathbb{R}$ qui donne un score à chaque hyperarc.
De plus on note $head(e)$ la fonction qui renvoie la tête $h$ d'un hyperarc $e$ et $tail(e)$ la fonction qui renvoie la queue $v_1\ldots v_k$
d'un hyperarc $e$. On note  $|e| = k$  l'arité d'un hyperarc $e=\langle h, v_1\ldots v_k \rangle$.
\end{definition}

\begin{definition}[Arcs entrants]
L'ensemble $AE(v)$ des arcs entrants sur un noeud $v$ est l'ensemble $\{e \in E | v =  head(e) \}$.
\end{definition}

\begin{definition}[Arcs sortants]
L'ensemble $AS(v)$ des arcs sortants du noeud $v$ est l'ensemble $\{e \in E | v \in tail(e) \}$.
\end{definition}

On peut également définir une extension de la notion de chemin pour un graphe 
qui est appelée ici dérivation dans le cas des hypergraphes. Cette notion correspond également à la notion d'arbre syntaxique.

\begin{definition}[Dérivation]
Une dérivation $D(v)$ enracinée au noeud $v \in V$ se définit récursivement comme suit~: 
\begin{itemize}
\item {\bf Base:} Si $e \in AE(v)$ et que $|e| = 0$ alors $D(v) = \langle v,\epsilon\rangle$ est une dérivation de $v$.
\item {\bf Récurrence:} Si $e \in AE(v)$ et $|e| = k > 0$ alors $D(v) =
  \langle v, D(v_1)\ldots D(v_k) \rangle$ est une dérivation de $v$
  $(1\leq i \leq k)$.
\end{itemize}
\end{definition}
Comme plusieurs dérivations sont possibles pour un même noeud $v$ (cas d'ambiguité),
on notera ${\cal D}(v)$ l'ensemble des dérivations d'un noeud $v$. Voyons maintenant comment pondérer les dérivations.

\begin{definition}[Fonction de pondération]
La fonction de pondération $s:E\mapsto \mathbb{R}$ est une fonction qui attribue un score sous forme de valeur réelle
à un hyperarc $e$. 
\end{definition}
Dans la pratique pour un hyperarc $e=\langle h, v_1\ldots v_k \rangle$, la fonction de pondération attribue un score
à un hyperarc en ayant accès à la valeur de chacun des noeuds. Autrement dit, elle prend la forme $s(h,e_1,\ldots e_k)$.


Notons que dans le cas d'une {\sc Pcfg}, $s(e)$ sera une probabilité de
la forme $P(\alpha | A )$ pour une règle $A\rightarrow \alpha$ alors
que pour un modèle discriminant $s(e)$ se reformule avec un paramètre
additionel $\mathbf{x}$ qui représente la séquence de mots.
Dans ce dernier cas la fonction prend la forme $s(e,\mathbf{x}) =
\mathbf{w}^T \boldsymbol\Phi(e,\mathbf{x})$ pour un perceptron
structuré
et $s(e,\mathbf{x}) =
\psi(e,\mathbf{x}) = \text{exp}(\mathbf{w}^T \boldsymbol\Phi(e,\mathbf{x}))$ pour un {\sc Crf}.


\begin{definition}[Pondération d'une dérivation]
Le poids $w(D(v))$ d'une dérivation $D(v)$ enracinée au noeud $v$ se définit récursivement comme suit~: 
\begin{itemize}
\item {\bf Base:} Si $e \in AE(v)$ et que $|e| = 0$ alors $w(D(v))  = 1$. 
\item {\bf Récurrence:} Si $e \in AE(v)$ et que $|e| = k > 0$ alors
  $w(D(v)) =  s(e) \times \prod_{i=1}^k w(D(v_i))$ $(1\leq i \leq k)$.
\end{itemize}
\end{definition}
où les scores des $D_i$ dérivations qui mènent à $e$ sont multipliées
avec le score $s(e)$ de $e$\footnote{Il s'agit en général d'une multiplication mais parfois d'une addition
selon le semi-anneau considéré (cas du perceptron structuré par exemple).}.

\begin{definition}[Poids maximal d'un noeud]
Le poids maximal d'un noeud $\delta(v)$ est le poids de la meilleure dérivation qui mène à $v$~:
\begin{displaymath}
\delta(v) = 
\left\{
\begin{array}{ll}
1 & \text{si $v$ est un noeud source}\\
\mathop{\text{max}}_{D(v) \in {\cal D}(v)} w(D(v))&\text{sinon}
\end{array}\right.
\end{displaymath}
\end{definition}


\paragraph{Problème d'analyse syntaxique} 
Les deux algorithmes que nous présentons ci-dessous permettent de
résoudre le problème d'analyse syntaxique d'une phrase $w_1\ldots w_n$.
La résolution consiste à extraire la dérivation de poids maximal de tout item $\langle 0,n , X \rangle \quad (X\in N)$.
En considérant l'ensemble ${\cal D}(\mathbf{x}) = \bigcup_{X \in N} {\cal D} (\langle 0, n, X \rangle) $ de toutes les dérivations qui couvrent la phrase,
les algorithmes qui suivent permettent de résoudre le problème~:
\begin{equation}
\hat{D}(v) = \mathop{\text{argmax}}_{D(v) \in {\cal D}(\mathbf{x})} w(D(v))
\end{equation}
On peut finalement remarquer que les définitions qui précèdent 
ont pour conséquence que le score d'une dérivation $D$ se décompose comme le produit des scores de ses hyperarcs~:
\begin{equation}
w(D(v)) = \prod_{e\in D(v)} s(e) 
\end{equation}


\paragraph{Exemple de dérivation} Une dérivation est
 la contrepartie d'un arbre d'analyse (en général partiel) pour le traitement algorithmique.
Ainsi pour l'arbre:
\begin{center}
\Tree[.S [.NP [.D Le ]  [.N chat ] ] [.VN [.V dort ] ] ]
\end{center}
La dérivation sera : 
{\footnotesize
\begin{displaymath}
( \langle 0,3,S\rangle, ( \langle 0,2,NP \rangle , (\langle 0,1,D
\rangle , (\langle 0,1,Le \rangle, \epsilon )) (\langle 1,2,N \rangle
, (\langle 1,2, chat \rangle ,\epsilon )))   (\langle 2,3,VN \rangle ,
(\langle 2,3,V \rangle ,( \langle 2,3,dort \rangle , \epsilon ) )))
\end{displaymath}
}
ce que l'on peut alternativement écrire :
\begin{center}
\Tree[.$\langle 0,3,S\rangle$ [.$\langle 0,2,NP\rangle$ [.$\langle 0,1,D\rangle$ [. $\langle 0,1,Le\rangle$ $\epsilon$ ] ]   [.$\langle 1,2,N\rangle$ [.$\langle 1,2,chat\rangle$ $\epsilon$ ] ]  ]  [.$\langle 2,3,VN\rangle$ [.$\langle 2,3,V\rangle$ [.$\langle 2,3,dort\rangle$ $\epsilon$ ] ] ] ]
\end{center}

La pondération d'une dérivation consiste à faire le produit (selon le demi-anneau) des hyperarcs qui connectent les noeuds. 
On peut voir à partir de l'exemple que le procédé est analogue à la pondération d'une dérivation {\sc Pcfg}.

\begin{figure}[htbp]
\begin{center}
\scalebox{0.6}{
\begin{tabular}[h]{ccc}\toprule
\raisebox{2.25cm}{\Tree [.$\langle 0,3,X\rangle$   [.$\langle 0,2,X\rangle$   $\langle 0,1,w_1\rangle$ \edge[draw=none]; {\bf\color{red} 3}  $\langle 1,2,w_2\rangle$ ] \edge[draw=none]; {\bf\color{red} 2} $\langle 2,3,w_3\rangle$  ] }
&
\raisebox{2.25cm}{\Tree [.$\langle 0,3,X\rangle$  $\langle 0,1,w_1\rangle$ \edge[draw=none]; {\bf\color{red} 1}  [.$\langle 1,3,X\rangle$ $\langle 1,2,w_2\rangle$ \edge[draw=none]; {\bf\color{red} 2}  $\langle 2,3,w_3\rangle$  ] ] }
&
\begin{tikzpicture}
\node  (leftn) at (0,0) {$\langle 0,1, w_1\rangle $ {\color{red}:1}};
\node (centern)  at (2,0) {$\langle 1,2, w_2 \rangle$ {\color{red}:1} } ;
\node (rightn) at (4,0) {$\langle 2,3,  w_3 \rangle$ {\color{red}:1} };

\node (xleft) at (0,1) {$\langle 0,2, X\rangle$ {\color{red}:3}};
\node (xright) at (4,1) {$\langle 2,3,X\rangle$ {\color{red}:2}};
\node (xtop) at (2,2) {$\langle 0,3,X\rangle$ {\color{red}:6}};
\draw[-] (xleft) --  (leftn);
\draw[-] (xleft) --  (centern);
\draw[-] (xtop) --  (xleft);
\draw[-] (xtop) --  (rightn);

\draw[-,dashed] (xtop) --  (leftn);
\draw[-,dashed] (xtop) --  (xright);
\draw[-,dashed] (xright) --  (rightn);
\draw[-,dashed] (xright) --  (centern);
\end{tikzpicture}\\\midrule
{\sc Analyse A}&{\sc Analyse B}&{\sc Forêt}
\\\bottomrule
\end{tabular}}
\end{center} 
\caption{\label{fig-forest-delta} Calcul de $\delta (v)$ dans une forêt}
\end{figure}








\paragraph{Exemple de calcul de $\delta(v)$}
L'exemple donné en figure \ref{fig-forest-delta} illustre les interactions entre dérivations dans une même forêt notamment 
pour le calcul de $\delta(v)$. On donne en rouge, dans les deux figures de gauche, une pondération pour les différents hyperarcs. Celui-ci correspond à un score 
qui serait produit par une méthode d'apprentissage. La figure de droite, qui illustre une forêt à proprement parler, donne les $\delta(v)$ pour chacun des noeuds
de cette forêt. 





\subsection{Algorithme CKY}

L'algorithme CKY réalise les réductions en commençant par combiner les items qui couvrent les petits empans, en créeant itérativement des items qui 
couvrent des empans de plus en plus grands et ce jusqu'à créer un item qui couvre toute la phrase.
Formellement cet algorithme crée la forêt en suivant un ordre topologique sur les noeuds de cette forêt.
On définit l'ordre topologique sur un hypergraphe comme suit.

\begin{definition}[Graphe projeté]
Le graphe projeté d'un hypergraphe orienté $H=\langle V, E\rangle$ est le graphe orienté $G=\langle V,E'\rangle$
tel que $E' = \{(u,v) | \exists e \in AE(v) \land u \in tail(v) \}$. Si $H$ est acyclique alors $G$ est acyclique.
\end{definition}

\begin{definition}[Ordre topologique]
Un ordre topologique pour $H$ est tout ordonnancement total de ses noeuds 
qui est un ordre topologique pour son graphe projeté $G$.
\end{definition}

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}
\node  (leftn) at (0,0) {$\langle 0,1, w_1\rangle $};
\node (centern)  at (2,0) {$\langle 1,2, w_2 \rangle$} ;
\node (rightn) at (4,0) {$\langle 2,3,  w_3 \rangle$};

\node (xleft) at (0,1) {$\langle 0,2, X\rangle$};
\node (xright) at (4,1) {$\langle 2,3,X\rangle$};
\node (xtop) at (2,2) {$\langle 0,3,X\rangle$};
\draw[<-] (xleft) --  (leftn);
\draw[<-] (xleft) --  (centern);
\draw[<-] (xtop) --  (xleft);
\draw[<-] (xtop) --  (rightn);
\draw[<-] (xtop) --  (xright);
\draw[->] (centern) --  (xright);
\draw[->] (rightn) --  (xright);
\draw[->] (leftn) --  (xtop);
\end{tikzpicture}
\caption{Graphe projeté correspondant à la forêt de Figure \ref{fig-forest-delta}}
\end{center}
\end{figure}

L'algorithme prend alors la forme générale donnée en algorithme \ref{algo-cky}.
L'algorithme associe à chaque noeud $v$ le poids $\delta(v)$ de la meilleure dérivation qui mène à $v$.

\begin{algorithm}
\begin{algorithmic}[htbp]
\Function{Viterbi-Cky}{$w_1\ldots w_n$}
\For{$ 0 \leq i < n$}\Comment{Initialisation}
\State $v \gets \langle i,i+1,w_{i+1} \rangle$
\State $\delta(v) \gets 1$
\EndFor
\ForAll{$v \in V$ en suivant un ordre topologique}\Comment{Récurrence}
\State $\delta (v) \gets 0$
\For {$e\in AE(v)$}
\State $\langle h, v_1\ldots v_k\rangle \gets e$
\State $\delta(v) \gets \text{max} \left(\delta(v) , s(e) \times
\prod_{i=1}^k \delta(v_i)\right)$
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-cky} Algorithme Viterbi-CKY}
\end{algorithm}

L'algorithme est également souvent présenté en explicitant la table de programmation dynamique et en fixant un ordre topologique 
qui tire parti de la longueur des empans créés, comme illustré en algorithme \ref{algo-cky-verbose}.
Cette dernière version permet de voir que la complexité de l'algorithme est en ${\cal O}(n^3)$ car il comporte trois boucles de longueur $n$
dans le pire des cas.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi-Cky}{$w_1\ldots w_n$}
\For{$ 0 \leq i < n$}\Comment{Initialisation}
\State $v \gets \langle i,i+1,w_{i+1} \rangle$
\State $\delta(v) \gets 1$
\EndFor
\For{$1 < span \leq n $}\Comment{Récurrence}
\For{$0\leq i \leq n - span $}
\State $j \gets i+span$
\For{$X \in N$}\Comment{Boucle sur non terminaux}
\State $v \gets \langle i,j,X \rangle$
\State $\delta(v) \gets 0$
\For{$i < k < j$}\Comment{Applications de la règle de réduction}
\For{$ (Y_1,Y_2) \in N\times N$}
\State $v_1,v_2 \gets \langle i,k,Y_1 \rangle,\langle k,j,Y_2 \rangle$
\State $\delta(v) \gets \text{max}(\delta(v), \times(s(v,v_1,v_2),\delta(v_1),\delta(v_2))$
\EndFor
\EndFor
\EndFor
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-cky-verbose} Algorithme Viterbi-CKY (version classique binaire)}
\end{algorithm}

\begin{exo}[Historique]
Donner une extension de l'algorithme \ref{algo-cky-verbose} qui permet de renvoyer la dérivation de poids maximal.
\end{exo}


\paragraph{Estimation de paramètres}
L'algorithme CKY décompose les scores des dérivations comme suit~:
\begin{equation}
\label{cky-decomp}
w(D) = \prod_{e\in D} w(e) 
\end{equation}
ce type de décomposition permet d'entraîner des modèles structurés à large marge très facilement.
On donne un exemple pour l'algorithme du perceptron en Algorithme \ref{perceptron-cky} 
pour lequel (\ref{cky-decomp}) s'instancie comme suit~:
\begin{displaymath}
w(\mathbf{x},\mathbf{D}) = \sum_{e\in \mathbf{D}} \mathbf{w}^T \boldsymbol\Phi(e,\mathbf{x}) 
\end{displaymath}

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{CKY-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{D}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{\mathbf{D}} \gets \mathop{\text{argmax}}_{\mathbf{D}\in
  \mathbf{\cal D}(\mathbf{x})} 
\sum_{e\in \mathbf{D}} \mathbf{w}^T \boldsymbol\Phi(e,\mathbf{x}_i)$
\Comment{Parsing}
\If{$\hat{\mathbf{D}} \not = \mathbf{D}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[ \sum_{e\in \mathbf{D}} \boldsymbol\Phi(e,\mathbf{x}_i) 
       - \sum_{\hat{e} \in \hat{\mathbf{D}}} \boldsymbol\Phi(\hat{e},\mathbf{x}_i)   \right]$ 
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{perceptron-cky}Perceptron pour estimer les paramètres d'un système d'analyse
  CKY}
\end{algorithm}

L'estimation des paramètres pour un modèle {\sc crf} est plus complexe. 
Cela demande de déployer une contrepartie de l'algorithme
{\em forward backward} pour calculer le second terme du gradient. Il existe un algorithme appelé dedans-dehors
({\em inside-outside}) qui permet de calculer ce terme par programmation dynamique à partir de toute la forêt d'analyse. 
Cependant, il est en général peu utilisé tel quel car trop coûteux en temps de calcul pour des cas d'utilisation réels. 



\subsection{Algorithme de Knuth}

On présente ici l'algorithme de Knuth en utilisant le même système déductif que précedemment (Figure \ref{fig-deductive}).
L'algorithme de Knuth, ou algorithme de recherche du meilleur d'abord peut être vu comme
 une reformulation de l'algorithme de Dijkstra pour la recherche de court chemin sur des graphes pondérés.
On peut faire l'analogie entre cet algorithme et le problème traditionnel de recherche de court chemin~:
lorsqu'on combine deux chemins on s'attend à ce que le score du chemin global augmente.


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Knuth-parser}{$w_1\ldots w_n$}
\For{$ 0 \leq i < n$}\Comment{Initialisation}
\State $v \gets \langle i,i+1,w_{i+1} \rangle$
\State $\delta(v) \gets \bar{1}$
\State  \Call{RéordonnerClé}{$Q$,$v$}
\EndFor
\State   $rest(e) \gets |e| \quad (\forall e \in E)$ \Comment{Init arités hyperarcs}
\While{$Q \not = \emptyset$}
\State $v \gets $ \Call{Extract-Min}{$Q$}
\ForAll{$e \in AS(v)$}
\State $h, (v_1, v_2) \gets e$
\State $rest(e) \gets rest(e) - 1$
\If{$rest(e) = 0$}
\State $\delta(h) \gets \text{max}( \delta(h),  \times(s(v,v_1,v_2),\delta(v_1),\delta(v_2)))$
\State \Call{RéordonnerClé}{$Q$,$h$}
\EndIf
\EndFor
\EndWhile
\EndFunction
\end{algorithmic}
\caption{\label{algo-knuth} Algorithme de Knuth}
\end{algorithm}


Informellement l'algorithme de Knuth suppose que le score d'une dérivation augmente lorsqu'on la combine avec une autre dérivation.
Ce type de comportement est typiquement celui du demi-anneau tropical (et plus généralement des demi-anneaux qui satisfont 
la condition dite de supériorité)
Ce sont des poids qui se dérivent naturellement de probabilités 
($w = -\log(p)$) ou à des sorties de modèles de régression logistique multinomiale ou de réseaux de neurones
à couche de sortie softmax.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Knuth-parser}{$w_1\ldots w_n$}
\For{$ 0 \leq i < n$}\Comment{Initialisation}
\State $v \gets \langle i,i+1,w_{i+1} \rangle$
\State $\delta(v) \gets \bar{1}$
\State  \Call{RéordonnerClé}{$Q$,$v$}
\EndFor
\State   $rest(e) \gets |e| \quad (\forall e \in E)$ \Comment{Init arités hyperarcs}
\While{$Q \not = \emptyset$}
\State $v \gets $ \Call{Extract-Min}{$Q$}
\State $\langle i , k , L \rangle \gets v$
\For{$k\leq j \leq n$}
\ForAll {$(X_1,X_2) \in N\times N$}
\State $e \gets \langle i,j , X_1 \rangle , \langle i , k , L \rangle \langle k , j , X_2 \rangle$
\State $rest(e) \gets rest(e) - 1$
\If{$rest(e) = 0$}
\State $\delta(h) \gets \text{max}( \delta(h),  \times(s(v,v_1,v_2),\delta(v_1),\delta(v_2)))$
\State \Call{RéordonnerClé}{$Q$,$h$}
\EndIf
\EndFor
\EndFor
\State $\langle k , j , L \rangle \gets v$
\For{$0\leq i \leq k$}
\ForAll {$(X_1,X_2) \in N\times N$}
\State $e \gets \langle i,j , X_1 \rangle , \langle i , k , X_2 \rangle \langle k , j , L \rangle$
\State $rest(e) \gets rest(e) - 1$
\If{$rest(e) = 0$}
\State $\delta(h) \gets \text{max}( \delta(h),  \times(s(v,v_1,v_2),\delta(v_1),\delta(v_2)))$
\State \Call{RéordonnerClé}{$Q$,$h$}
\EndIf
\EndFor
\EndFor
\EndWhile
\EndFunction
\end{algorithmic}
\caption{\label{algo-knuth-verbose} Algorithme de Knuth (version binaire)}
\end{algorithm}


Plus formellement, la fonction de pondération doit satisfaire les conditions dites de monotonie et de supériorité.
\begin{definition}[Fonction de pondération monotone]
Une fonction $f: \mathbb{R}^d \mapsto \mathbb{R}$ est monotone pour la relation d'ordre $\preceq$ si pour tout $(x,x') \in \mathbb{R}^2$ 
\begin{displaymath}
x \preceq x' \qquad \Rightarrow\qquad f(\ldots,x,\ldots) \preceq f(\ldots,x',\ldots)
\end{displaymath}
\end{definition}
\begin{definition}[Fonction de pondération supérieure]
Une fonction $f: \mathbb{R}^d \mapsto \mathbb{R}$ est supérieure si le résultat de la fonction
est plus grand que chacun de ses arguments~:
\begin{displaymath}
x_i \preceq f(x_1 \ldots,x_i,\ldots x_m) \qquad (1\leq i \leq m )
\end{displaymath}
\end{definition}


L'algorithme de Knuth (Algorithme \ref{algo-knuth}) construit l'hypergraphe en expansant en priorité 
les noeuds les plus prometteurs, c'est-à-dire les noeuds de poids minimal.
L'ordre de priorité est géré par une file de priorité (file de Fibonacci).
Il faut remarquer que contrairement aux arcs d'un graphe, les hyperarcs ne peuvent être expansés 
si l'ensemble des noeuds de leur queue n'ont pas été engendrés. Pour cette raison l'algorithme maintient une table d'arité des hyperarcs
(noté $rest(e)$) qui enregistre combien de noeuds de la queue ont déjà été engendrés.

L'algorithme de Knuth est une contrepartie de l'algorithme de Dijkstra 
pour le cas des hypergraphes. Il a été utilisé et étudié sous des noms divers et notamment
{\em best first parsing} principalement 
pour mettre au point des heuristiques de recherche (exactes ou non) 
de la famille $A\star$ pour des modèles probabilistes génératifs.


{\bf TODO Dire qq part qu'il faut contraindre légèrement:  pas de root en temporaire, pas deux fils temporaires etc.}
\section{Analyse par transitions}

Les méthodes d’analyse par transition en constituants sont très anciennes
et ont pour origine la théorie de la compilation avec les algorithmes à décalage réduction (algorithme d'analyse {\sc lr} et {\sc glr})
ainsi que des formalisations d’algorithmes de planification (comme {\sc strips}) et de démonstration automatique.

L’ensemble de ces algorithmes travaillent avec une structure de donnée 
appelée configuration (ou état d'analyse) et qui est essentiellement un couple 
$\langle \mathbf{S},\mathbf{B} \rangle$ fait d’une pile et d’une file (ou buffer). 

Contrairement aux algorithmes présentés précédemment qui autorisent la programmation dynamique, ici
l’ensemble des configurations possibles est en général très vaste de telle sorte que mener une procédure exacte de recherche de solutions 
d’analyse est infaisable en pratique. Par conséquent les algorithmes présentés dans cette section sont en général 
associés à des méthodes de recherche inexactes de solution. 
Le caractère inexact de la méthode de recherche de solution est compensé 
par la richesse de l’information stockée dans les configurations, ce qui permet de prendre des décisions très bien informées localement.

On donne en figure \ref{fig-transition-cfg} un système de transitions pour l'analyse en constituants qui suppose des arbres binarisés 
suivant les méthodes décrites dans les sections précédentes. L'algorithme commence avec un buffer rempli pas la séquence de mots à analyser
et termine lorsque la pile ne contient plus qu'un seul élément et que la pile est vide. L'action de décalage insère en sommet de pile le tag du premier mot de la file
(tagging) alors que les actions de réduction remplacent les deux non terminaux au sommet de la pile par un nouveu 
non terminal $X$. Notons qu'il y a autant d'actions de décalage qu'il y a de tags et autant d'actions de reduction qu'il y a de non terminaux ($x\in \Sigma$).

\begin{figure}[htbp]
\begin{displaymath}
\begin{array}{rccll}
\mathbf{init}  &\langle \epsilon , w_0 \ldots w_n \rangle\\
\mathbf{but}  & \langle X ,\epsilon  \rangle & &&X\in N \\
\mathbf{shift}(X) & \langle \mathbf{S} ,  w_i | \mathbf{B}  \rangle
&\Rightarrow &\langle \mathbf{S} | X ,  \mathbf{B}    \rangle & X\in Tags\\
\mathbf{reduce}(X) &\langle \mathbf{S}| X_i | X_j , \mathbf{B}\rangle 
&\Rightarrow& \langle \mathbf{S}| X , \mathbf{B}  \rangle&X \in N
\end{array}
\end{displaymath}
\caption{\label{fig-transition-cfg}Un système de transitions pour l'analyse en constituants}
\end{figure}

L’algorithme est fondamentalement non déterministe. 
Il est par conséquent habituel de l’augmenter (1) d’une méthode de pondération des hypothèses et 
(2) d’une méthode de recherche de solutions approximative.

\paragraph{Dérivations et pondérations}
Un pas de dérivation est le passage d’une configuration $c_i$ à  une configuration $c_{i+1}$ 
en utilisant une transition (ou action) parmi les $|X|$ actions de décalage  et les $|X|$ actions de réduction.
On peut éventuellement ajouter une action {\bf stop}  qui indique la fin de l'analyse.
Une dérivation est une séquence $\mathbf{d} = (c_0,t_0) (c_1,t_1) \ldots (c_m,t_m)$
de couples associant des configurations à des actions à exécuter. Lorsque la grammaire est en {\sc cnf}
une dérivation pour le système de transitions décrit en figure \ref{fig-transition-cfg} a une longueur $m = 2n-1$.
Le score global d'une dérivation se calcule en décomposant le score global par le produit des scores locaux~:
\begin{equation}
\Psi(\mathbf{d}) = \sum_{i=0}^m \psi (c_i,t_i,\mathbf{x})
\end{equation}
où $\mathbf{x}$ représente la séquence de mots à analyser. Le problème d'analyse syntaxique consiste à résoudre~:
\begin{equation}
\hat{\mathbf{d}} = \mathop{\text{argmax}}_{\mathbf{d} \in \mathbf{D}(\mathbf{x})} \Psi(\mathbf{d})
\end{equation}

Les dérivations complètes du système de transitions ont comme
propriété que leur longueur est de $2n-1$ pas de dérivation pour une
phrase de $w_0\ldots w_n$ mots~:  pour obtenir une analyse complète,
il faut réaliser $n$ décalages et $n-1$ opérations de réduction.
Lorsqu'on ajoute une action {\bf stop} la longueur de la dérivation
vaut $2n$.

Cette propriété facilite l'usage du système de transitions en
combinaison avec une méthode de recherche de solutions en faisceau.
En effet, on observe empriquement que le score d'une dérivation tel
que donné par un modèle discriminant est à peu près linéairement
corrélé à sa longueur~: plus une dérivation est longue, plus son score
est élevé. Ici, comme toutes les dérivations concurrentes ont la même
longueur, ce problème de biais lié à la longueur ne se manifeste pas
(contrairement à la plupart des systèmes de transitions présentés par la suite).


\begin{algorithm}[htbp]
\begin{algorithmic}[0]
\Function{ConstituantsBeamParse}{$\mathbf{x}$,K}
\State ${\cal B} \gets \langle \epsilon, w_0\ldots w_n,\emptyset\rangle$
\For  {$0\leq i < 2n-1$}
\For {$c \in \mathop{\text{K-argmax}}_{c \in {\cal B}} \delta(c)$}
\For{$t \in T$}\Comment{$T$ est l' ensemble des actions}
\State $c' \gets t(c)$
\State $\delta(c') \gets \delta(c) + \psi(c,t,\mathbf{x})$
\State ${\cal B}' \gets {\cal B}\cup c'$
\EndFor
\EndFor
\State ${\cal B} \gets {\cal B}'$
\EndFor
\State \Return $\mathop{\text{argmax}}_{c\in \cal B} \delta(c)$
\EndFunction
\end{algorithmic}
\caption{\label{algo-cfg-beam}Algorithme d'analyse en constituants en
faisceau}
\end{algorithm}



\paragraph{Estimation des paramètres} Les données d'entrainement pour l'analyse en constituants se présentent
naturellement sous la forme d'un treebank. La première étape de traitement des données consiste à 
mettre le treebank en forme normale de Chomsky. 
La seconde étape de traitement consiste à transformer les arbres en dérivations de référence à l'aide d'une fonction oracle
de telle sorte que le jeu de données ait la forme $\mathop{(\mathbf{x}_i,\mathbf{d}_i)}_{i=1}^N$ où $\mathbf{x}_i$ est une séquence de mots
et $\mathbf{d}_i$ une dérivation pour l'arbre de référence.

La fonction oracle simule une analyse en ayant pour information supplémentaire $V$ l'ensemble des noeuds de l'hypergraphe qui 
correspond à l'arbre d'analyse de référence. \`A chaque étape de dérivation, l'action suivie par l'oracle est donnée par l'algorithme \ref{algo-oracle-cfg}.
\begin{algorithm}
\begin{algorithmic}
\Function{StaticOracle}{$\mathbf{S}$,$\mathbf{B}$,$V$}
\If {$S | ( i , k ,X_1) | ( k , j , X_2)$} \Comment{Il y a au moins un élément dans $S$}
    \If {$(i,j,X_0) \in V$}
        \State \Return {\bf reduce}($X_0$)
\EndIf
\EndIf
\If{ $w_i | B \not = \epsilon$} \Comment{Il y a au moins un élément $w_i$ dans $B$}
   \If{$(i,i+1,T) \in V$}
        \State \Return {\bf shift}($T$)
\EndIf
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-oracle-cfg}Oracle statique pour l'analyse en constituants par transitions }
\end{algorithm}

L'estimation des paramètres à partir des données se fait en comparant les dérivations de référence produites par la fonction oracle
aux prédictions de l'analyseur. 
L'estimation se fait en général avec un modèle à large marge ou un modèle local car un modèle {\sc crf}  
exige de calculer l'ensemble de dérivations pour obtenir le facteur de normalisation. Ce calcul est en général infaisable exhaustivement avec un système 
de transitions.  On donne ici un exemple de procédure d'estimation avec l'algorithme du perceptron 
en algorithme \ref{perceptron-cfg}.

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{constituants-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{d}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{\mathbf{d}} \gets \mathop{\text{argmax}}_{\mathbf{d}\in
  \mathbf{D}(\mathbf{x})} 
\sum_{j = 0}^m \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,c_j,t_j)$
\Comment{Parsing}
\If{$\hat{\mathbf{d}} \not = \mathbf{d}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[ \sum_{j=0}^m \boldsymbol\Phi(\mathbf{x}_i,c_j,t_j) 
       - \sum_{j=0}^m \boldsymbol\Phi(\mathbf{x}_i,\hat{c}_j,\hat{t}_j)   \right]$ 
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{perceptron-cfg}Perceptron pour un système d'analyse
  en constituants par transitions}
\end{algorithm}


\paragraph{Problème d'approximation par recherche en faisceau}
L' algorithme \ref{perceptron-AS} est en général utilisé avec un
algorithme de recherche en faisceau, ce qui a pour conséquence que la
meilleure analyse prédite n'est pas nécessairement celle qui a le meilleur
poids pour le modèle (celle-ci peut avoir été sortie prématurément du faisceau).

Dans ce cas de figure, il est donc possible que l'algorithme
d'estimation réalise une mise à jour des poids alors que sans
l'approximation introduite par le faisceau
le modèle aurait prédit la bonne analyse. Ce comportement peut
perturber la descente de gradient jusqu'à causer une divergence.

Pour garantir que la descente de gradient converge il faut garantir
que la mise à jour a lieu lorsqu'il y a bien une violation effective de la marge
et que celle-ci ne provient pas de l'approximation en faisceau.

Pour cette raison on s'autorise dans la pratique à réaliser la mise à
jour sur des sous-séquences de dérivation pour lesquelles on a la
garantie que la marge est effectivement violée indépendamment des
approximations introduites par le faisceau. Autrement dit une mise à
jour valide respecte la condition suivante\footnote{
La mise à jour invalide qui consiste à comparer la meilleure analyse complète
dans le faisceau en fin d'analyse avec la référence ne vérifie pas cette condition dans tous les cas. 
}~:
\begin{equation}
\Psi(\tilde{\mathbf{y}}^*_{0\ldots k}) > \Psi(\mathbf{y}_{0\ldots k})
\end{equation}
La méthode la plus utilisée en pratique est la mise à jour rapide
({\bf early update}) où la mise à jour est réalisée sur des
sous-dérivations dont le préfixe $0\ldots k$ correspond à l'étape de
dérivation où la dérivation de référence sort du faisceau. Une méthode
alternative est la mise à jour à violation maximale de la marge ({\bf max violation update}). 
Dans ce cas on choisit $k$ tel que 
\begin{displaymath}
k = \mathop{\text{argmax}}_{0 \leq k
 < 2n-1}\Psi(\tilde{\mathbf{y}}^*_{0\ldots k}) -
\Psi(\mathbf{y}_{0\ldots k})
\end{displaymath}



\section{Analyse lexicalisée}

L'analyse en constituants est parfois utilisée dans un cadre d'analyse dite lexicalisée. 
Dans ce contexte les arbres sont augmentés d'informations qui permettent d'identifier les têtes syntaxiques.
On parle d'annotations en têtes et d'arbres annotés par les têtes.

La lexicalisation est utilisée pour donner des indices destinés à aider à la désambiguisation lors de l'analyse.
On illustre l'idée en Figure \ref{fig-lexicalisation}. Celle-ci illustre un problème dit d'attachement de groupe prépositionnel.
La structure illustrée en (a) suggère que le dépendant {\em tomates} est à mettre en relation avec {\em salade} (les tomates sont des ingrédients de 
la salade) alors que la structure (b) suggère que le dépendant {\em couvert} est à mettre en relation avec le verbe  {\em manger} (les couverts
 sont des instruments pour manger). 

\begin{figure}[htbp]
\begin{center}
\scalebox{0.75}{ 
(a) \Tree [.S(mange) [.N(Pierre) Pierre ] [.V(mange) mange ] [.NP(salade) [.D(une) une ] [.N(salade) salade ]  [.PP(tomates) [.P(avec) avec ] [.NP(tomates) [.D(des) des ] [.N(tomates) tomates ] ] ] ] ]
}
\scalebox{0.75}{
(b) \Tree [.S(mange) [.N(Pierre) Pierre ] [.V(mange) mange ] [.NP(salade) [.D(une) une ] [.N(salade) salade ] ] [.PP(couverts) [.P(couverts) avec ] [.NP(couverts) [.D(des) des ] [.N(couverts) couverts ] ] ] ]
}
\end{center}
\caption{\label{fig-lexicalisation}Arbres lexicalisés}
\end{figure}

D'un point de vue formel, les deux phrases peuvent (a) et (b) recevoir l'une ou l'autre analyse. La décision de structure se prend
 sur base de la relation entre le groupe prépositionnel et son gouverneur.
Comme la représentation est lexicalisée on peut voir que les relations de dépendances critiques (salade, tomates) et (manger,couverts)
sont explicitées, ce qui donne à l'algorithme d'analyse la possibilité de réaliser le choix approprié.

La plupart des treebanks existants ne donnent pas une telle annotation de têtes.
Celle-ci est souvent ajoutée par une heuristique qui se formalise par une table de propagation des têtes.
Et l'analyse lexicalisée est formalisée comme une variante des algorithmes qui précèdent en utilisant une représentation 
binarisée de la grammaire qui est une variante de la forme normale de Chomsky,
parfois appelée {\sc 2-lcfg} et dont les règles sont de la forme suivante~:
\begin{eqnarray*}
A [h] &\rightarrow & B[h]\quad C[w]\\
A [h] &\rightarrow & B[w]\quad C[h]\\
A[h] &\rightarrow & h
\end{eqnarray*}
Les algorithmes présentés précédemment se généralisent au cas lexicalisé (programmation dynamique et transitions). En substance les items d'analyse 
comportent un indice supplémentaire $\langle i,j,h, X\rangle$ qui indique la position de la tête dans cet item.
De plus, commme il y a deux types de règles binaires~: l'une assignant comme tête du nouveau syntagme la tête de son fils gauche, l'autre la tête de son fils droit.
Par contre la conception naïve d'algorithmes pour ces systèmes à un indice supplémentaire mène à des algorithmes dont la complexité est en 
${\cal O}(n^5)$.

Comme on peut le remarquer les arbres d'analyse en constituants lexicalisés encodent des 
arbres de dépendances projectifs. On propose donc d'illustrer ces différents aspects
dans le chapitre consacré à l'analyse en dépendances.


\chapter{Analyse syntaxique en dépendances}

\section{Arbres de dépendances}

Un graphe de dépendances est un graphe $G = \langle V,E \rangle $
où :
\begin{itemize}
\item $W$ est un ensemble de noeuds muni d'une relation d'ordre $\prec$
\item $E \subseteq V\times V$  est un ensemble d'arcs 
\end{itemize}

La relation d'ordre sur les noeuds est la relation d'ordre sur les
entiers qui indicent les noeuds.
$E^*$ dénote la fermeture réflexive transitive de $E$. Cette relation
permet de capturer les relations de dominance entre noeuds qui sont indirectes.

Un arc $(i,j) \in E$ représente une relation de dépendance non typée entre
deux noeuds. Celle-ci est
également notée $i \rightarrow j$. 
On note $i\stackrel{*}{\rightarrow} j$ un élément de $E^*$

En pratique, les noeuds $w_i \in W$ sont étiquetés par des mots et les
arcs $(i,j) \in E$ sont étiquetés par des types qui représentent les
fonctions syntaxiques. Ces aspects pratiques sont secondaires pour les
problèmes algorithmiques et seront largement ignorés dans la suite de ce chapitre.

  
\paragraph{Propriétés}
Les arbres de dépendances sont des graphes $G = \langle W,E \rangle$ qui satisfont les
contraintes suivantes~:
\begin{enumerate}
\item $G$ est connexe. 
\begin{displaymath}
 i\in W \quad\Rightarrow\quad \exists_j (i \rightarrow j) \in E \lor
  (j\rightarrow i) \in E
\end{displaymath}
\item $G$ est acyclique. 
\begin{displaymath}
i \rightarrow j\in E \quad\Rightarrow\quad 
  j \stackrel{*}{\rightarrow} i \not \in E^*
\end{displaymath}
\item Chaque  noeud de $G$  a au plus un arc entrant~: 
\begin{displaymath}
i\rightarrow j  \in E \quad\Rightarrow\quad \lnot \exists k  (k\rightarrow j)\in E
\end{displaymath}
\item\label{it:projectif} $G$ est projectif~: 
\begin{displaymath}
 i\rightarrow j \in E \quad\Rightarrow\quad 
\forall_{k:i \prec k \prec j}  (i\stackrel{*}{\rightarrow} k)
\end{displaymath}
\end{enumerate}
La condition (\ref{it:projectif}) est parfois relâchée pour traiter
les langues à ordre des mots libre.


\section{Analyse par transitions}

Les méthodes d'analyse en dépendances par transitions sont dérivées
des méthodes d'analyse par décalage réduction utilisées pour l'analyse
en constituants et des formalisations d'algorithmes de planification
et de démonstration automatique.

L'ensemble de ces algorithmes travaille avec une structure de donnée
appelée {\bf configuration} (ou état) et qui est essentiellement un couple $\langle
\mathbf{S} , \mathbf{B}\rangle$ fait d'une pile et d'une file (ou
buffer). L'ensemble des configurations possibles est en général très
vaste de telle sorte que mener une procédure exacte de recherche de
solutions d'analyse est en général infaisable. Par conséquent les
algorithmes présentés dans cette section sont en général associés à
des méthodes de recherche inexactes de solution. Le caractère inexact
de la méthode de recherche de solution est compensé par la richesse de
l'information stockée dans les configurations, ce qui permet de
prendre des décisions très bien informées localement.

\subsection{Système Arc-standard}

Le système arc-standard est un modèle d'analyse dont les configurations
sont des triplets $\langle \mathbf{S},\mathbf{B} ,  A\rangle$ où
$\mathbf{S}$ est une pile, $\mathbf{B}$ une file et $A$ un ensemble d'arcs.
La donnée à analyser $\mathbf{x} = w_0\ldots w_n$ est une séquence de mots
dont le mot $w_0$ est par convention un mot artificiel qui représente
la racine de l'arbre.

L'algorithme (Figure \ref{fig-AS}) commence avec un état initial où la
pile est vide et la file remplie de la séquence de mots. Il termine
lorsque la pile ne contient plus que la racine de l'arbre et que le
buffer est vide. Les actions arc gauche ({\bf left-arc}) et ({\bf
  right-arc}) sont des contreparties de l'action de réduction d'un
analyseur à décalage réduction. L'action de décalage est la
contrepartie fidèle d'une action de décalage traditionnelle.



\begin{figure}[htbp]
\begin{displaymath}
\begin{array}{rccll}
\mathbf{init}  &\langle \epsilon , w_0 \ldots w_n ,\emptyset \rangle\\
\mathbf{but}  & \langle w_0 ,\epsilon , A \rangle\\
\mathbf{shift} & \langle \mathbf{S} ,  w_i | \mathbf{B} , A   \rangle
&\Rightarrow &\langle \mathbf{S} | w_i ,  \mathbf{B} , A   \rangle\\
\mathbf{left-arc} &\langle \mathbf{S}|w_i | w_j , \mathbf{B} , A
\rangle &\Rightarrow& \langle \mathbf{S}| w_j , \mathbf{B} , A \cup \{
j\rightarrow i \}   \rangle & (i\not = w_0)\\
\mathbf{right-arc }  &\langle \mathbf{S}|w_i | w_j , \mathbf{B} , A   \rangle
&\Rightarrow & 
\langle \mathbf{S}| w_i , \mathbf{B} , A \cup \{
i \rightarrow j \}   \rangle
\end{array}
\end{displaymath}
\caption{\label{fig-AS}Le système de transitions arc standard}
\end{figure}


Les actions arc-gauche et arc-droit sont augmentées d'une procédure
qui collecte les arcs créés en cours d'analyse (représentés par
l'ensemble $A$) ce qui permet d'extraire trivialement l'arbre de
dépendance en fin d'analyse.

L'algorithme est fondamentalement non déterministe. Il est par
conséquent habituel de l'augmenter (1) d'une méthode de pondération des
hypothèses et (2) d'une méthode de recherche de solutions
approximative (en général non exhaustive en faisceau).

\begin{figure}[htbp]

\scalebox{0.7}
{\begin{tabular}{llll}\toprule
{\sc Arcs} & {\sc Pile} & {\sc File}&{\sc Action}\\\midrule
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\end{dependency}}
&{\bf root}
&j' ,  ai ,  réservé , un , vol , pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \&  j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\end{dependency}
}
&{\bf root} , j'
& ai ,  réservé , un , vol , pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\end{dependency}
}
&{\bf root} , j',ai
&réservé , un , vol , pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\end{dependency}}
&{\bf root} , j', ai, réservé 
& un , vol , pour , Sophie
&left-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\end{dependency}
}
&{\bf root} , j', réservé 
& un , vol , pour , Sophie
&left-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\end{dependency}
}
&{\bf root} , réservé 
& un , vol , pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\end{dependency}
}
&{\bf root} , réservé , un
& vol , pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\end{dependency}
}
&{\bf root} , réservé , un, vol
&pour , Sophie
&left-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\end{dependency}
}
&{\bf root} , réservé , vol
&pour , Sophie
&right-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\end{dependency}
}
&{\bf root} , réservé
&pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\end{dependency}
}
&{\bf root} , réservé , pour 
&Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\end{dependency}
}
&{\bf root} , réservé , pour , Sophie
& $\epsilon$
&right-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\depedge{7}{8}{}
\end{dependency}
}
&{\bf root} , réservé , pour 
& $\epsilon$
&right-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\depedge{7}{8}{}
\depedge{4}{7}{}
\end{dependency}
}
&{\bf root} , réservé
& $\epsilon$
&right-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\depedge{7}{8}{}
\depedge{4}{7}{}
\depedge{1}{4}{}
\end{dependency}
}
&{\bf root} 
& $\epsilon$
&goal!\\
\bottomrule
\end{tabular}}
\caption{Exemple de dérivation arc-standard}
\end{figure}




\paragraph{Dérivations et pondérations} 
Un pas de dérivation est le passage d'une configuration $c_i$ à une
configuration $c_{i+1}$ en utilisant une transition (ou action) $t\in
\{shift, left-arc,right-arc, stop\}$. L'action {\bf stop} est exécutée
uniquement pour terminer l'analyse lorsque le buffer est vide et que
la pile ne peut plus être réduite.

Une séquence de dérivation, ou {\bf dérivation}, est une séquence de la
forme $\mathbf{d} = (c_0, t_0) \ldots (c_m,t_m)$. On pondère une dérivation en
faisant l'hypothèse que son score se décompose par la somme~:
\begin{equation}
\Psi(\mathbf{d}) = \sum_{i=0}^m  \psi(c_i,t_i,\mathbf{x})
\end{equation}
où $\mathbf{x}$ représente la séquence de mots à analyser.
Le problème d'analyse syntaxique consiste en général à résoudre~:
\begin{equation}
{\mathbf{\hat{d}}} = \mathop{\text{argmax}}_{\mathbf{d} \in \mathbf{D}(\mathbf{x})} \Psi(\mathbf{d}) 
\end{equation}
où $\mathbf{D}(\mathbf{x})$ représente l'ensemble des dérivations possibles pour
la phrase à analyser.

Les dérivations complètes du système de transition arc-standard ont comme
propriété que leur longueur est de $2n-1$ pas de dérivation pour une
phrase de $w_0\ldots w_n$ mots~:  pour obtenir une analyse complète,
il faut réaliser $n$ décalages et $n-1$ opérations d'arcs (gauche ou
droite).
Lorsqu'on ajoute une action {\bf stop} la longueur de la dérivation
vaut $2n$.

Cette propriété facilite l'usage du système arc-standard en
combinaison avec une méthode de recherche de solutions en faisceau.
En effet, on observe empriquement que le score d'une dérivation tel
que donné par un modèle discriminant est à peu près linéairement
corrélé à sa longueur~: plus une dérivation est longue, plus son score
est élevé. Ici, comme toutes les dérivations concurrentes ont la même
longueur, ce problème de biais lié à la longueur ne se manifeste pas
(contrairement à la plupart des systèmes de transitions présentés par la suite).

\begin{algorithm}[htbp]
\begin{algorithmic}[0]
\Function{ArcStandardBeamParse}{$\mathbf{x}$,K}
\State ${\cal B} \gets \langle \epsilon, w_0\ldots w_n,\emptyset\rangle$
\For  {$0\leq i < 2n-1$}
\For {$c \in \mathop{\text{K-argmax}}_{c \in {\cal B}} \delta(c)$}
\For{$t \in T$}\Comment{$T$ est l' ensemble des actions}
\State $c' \gets t(c)$
\State $\delta(c') \gets \delta(c) + \psi(c,t,\mathbf{x})$
\State ${\cal B}' \gets {\cal B}\cup c'$
\EndFor
\EndFor
\State ${\cal B} \gets {\cal B}'$
\EndFor
\State \Return $\mathop{\text{argmax}}_{c\in \cal B} \delta(c)$
\EndFunction
\end{algorithmic}
\caption{\label{algo-arc-standard}Algorithme d'analyse Arc Standard en
faisceau}
\end{algorithm}


\paragraph{Estimation des paramètres}
L'estimation des paramètres se réalise à partir d'un 
corpus annoté $C = \mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$ qui est un
exemplaire de $N$ phrases où chaque séquence de mots $\mathbf{x}_i$
est associée à un arbre de référence $\mathbf{y}_i$.

La procédure d'apprentissage consiste à estimer un vecteur de
paramètres $\mathbf{w}$ de telle sorte que les dérivations prédites par
l'algorithme sont les plus similaires aux dérivations de référence.
Comme les données sont naturellement des couples
$(\mathbf{x}_i,\mathbf{y}_i)$, il faut transformer les arbres de
référence $\mathbf{y}_i$ en dérivations.
On réalise cette opération à l'aide d'un {\bf oracle} statique
(Algorithme \ref{algo-AS-oracle}) qui permet de simuler l'analyse de référence en utilisant
comme donnée $A$ l'ensemble des arcs de l'arbre de référence. L'oracle
permet également de mettre en évidence l'idée bottom-up du système arc-standard~: la
création d'un arc vers un noeud $i$ exige que tous les dépendants 
de $i$ soient déjà identifiés.

\begin{algorithm}
\scriptsize
\begin{algorithmic}[0]
\Function{ArcStandardStaticOracle}{$\mathbf{S},\mathbf{B},A, A_{ref}$}
\If{ $\mathbf{S} | i | j $} \Comment{Il y a au moins 2 éléments sur la
pile}
\If{$i\rightarrow j \in A_{ref}$ %{\bf and} $j\not = 0$
 {\bf and}
  $\forall k (j \rightarrow k \in A_{ref} \Rightarrow  j \rightarrow k \in A)$}
\State \Return $\mathbf{right-arc}$
\ElsIf{$j\rightarrow i \in A_{ref}$ {\bf and} $i\not = 0$ {\bf and} 
 $\forall k (i \rightarrow k \in A_{ref} \Rightarrow  i \rightarrow k \in A)$}
\State \Return $\mathbf{left-arc}$
\EndIf
\EndIf
\If{$\mathbf{B} \not = \epsilon$} \Comment{Il y a au moins un élément
  dans la file}
\State\Return $\mathbf{shift}$
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-AS-oracle} Oracle statique pour le système arc
  standard}
%http://demo.clab.cs.cmu.edu/fa2015-11711/images/b/b1/TbparsingSmallCorrection.pdf
\end{algorithm}
Le jeu de données transformé où les arbres $\mathbf{y}_i$ sont
transformés en dérivation $\mathbf{d}_i$ prend alors la forme suivante.
$C = \mathop{(\mathbf{x}_i,\mathbf{d}_i)}^N_{i=1}$. L'estimation des
paramètres se fait en général avec un modèle à large marge car
l'utilisation d'un {\sc crf} exige un facteur de
normalisation qui demande de calculer l'ensemble des dérivations
possibles pour une phrase donnée, ce qui est trop coûteux en temps de calcul.
On donne ici une méthode d'estimation à l'aide de l'algorithme du
perceptron (Algorithme \ref{perceptron-AS}).

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{arc-standard-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{d}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{\mathbf{d}} \gets \mathop{\text{argmax}}_{\mathbf{d}\in
  \mathbf{D}(\mathbf{x})} 
\sum_{j = 0}^m \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,c_j,t_j)$
\Comment{Parsing}
\If{$\hat{\mathbf{d}} \not = \mathbf{d}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[ \sum_{j=0}^m \boldsymbol\Phi(\mathbf{x}_i,c_j,t_j) 
       - \sum_{j=0}^m \boldsymbol\Phi(\mathbf{x}_i,\hat{c}_j,\hat{t}_j)   \right]$ 
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{perceptron-AS}Perceptron pour un système d'analyse
  en dépendances par transitions}
\end{algorithm}


\paragraph{Unicité de l'oracle}
L'analyse par transitions suppose que chaque arbre de dépendance de
référence $\mathbf{y}_i$ peut être transformé en une unique dérivation de
référence $\mathbf{d}_i$. Autrement dit, on suppose implicitement une fonction de la forme
$A \mapsto D$. 

On peut toutefois remarquer que cette fonction n'est pas déterministe pour le
système de transitions arc-standard~: plusieurs dérivations peuvent
représenter le même arbre de dépendances.

\begin{figure}[htbp]
\begin{center}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
$w_0$ \& $w_1$ \& $w_2$ \& $w_3$\\
\end{deptext}
\depedge[hide label]{1}{3}{ }
\depedge[hide label]{3}{2}{ }
 \depedge[hide label]{3}{4}{ }
\end{dependency}

\begin{tabular}{l|cccccc}\toprule
Dérivation A&S&S&LA&S&RA&RA\\
Dérivation B & S&S&S&RA&LA&RA\\\bottomrule
\end{tabular}
\end{center}
\caption{Dérivations multiples pour un arbre de dépendances avec le
  système arc-standard}
\end{figure}

Cette observation illustre un problème du système arc-standard. On
apprend un modèle qui apprend à prédire un sous-ensemble des
dérivations qui correspondent aux arbres de référence.

 \paragraph{Problème d'approximation par recherche en faisceau}
L' algorithme \ref{perceptron-AS} est en général utilisé avec un
algorithme de recherche en faisceau, ce qui a pour conséquence que la
meilleure analyse prédite n'est pas nécessairement celle qui a le meilleur
poids pour le modèle (celle-ci peut avoir été sortie prématurément du faisceau).

Dans ce cas de figure, il est donc possible que l'algorithme
d'estimation réalise une mise à jour des poids alors que sans
l'approximation introduite par le faisceau
le modèle aurait prédit la bonne analyse. Ce comportement peut
perturber la descente de gradient jusqu'à causer une divergence.

Pour garantir que la descente de gradient converge il faut garantir
que la mise à jour a lieu lorsqu'il y a bien une violation effective de la marge
et que celle-ci ne provient pas de l'approximation en faisceau.

Pour cette raison on s'autorise dans la pratique à réaliser la mise à
jour sur des sous-séquences de dérivation pour lesquelles on a la
garantie que la marge est effectivement violée indépendamment des
approximations introduites par le faisceau. Autrement dit une mise à
jour valide respecte la condition suivante\footnote{
La mise à jour invalide qui consiste à comparer la meilleure analyse complète
dans le faisceau en fin d'analyse avec la référence ne vérifie pas cette condition dans tous les cas. 
}~:
\begin{equation}
\Psi(\tilde{\mathbf{y}}^*_{0\ldots k}) > \Psi(\mathbf{y}_{0\ldots k})
\end{equation}
La méthode la plus utilisée en pratique est la mise à jour rapide
({\bf early update}) où la mise à jour est réalisée sur des
sous-dérivations dont le préfixe $0\ldots k$ correspond à l'étape de
dérivation où la dérivation de référence sort du faisceau. Une méthode
alternative est la mise à jour à violation maximale de la marge ({\bf max violation update}). 
Dans ce cas on choisit $k$ tel que 
\begin{displaymath}
k = \mathop{\text{argmax}}_{0 \leq k
 < 2n-1}\Psi(\tilde{\mathbf{y}}^*_{0\ldots k}) -
\Psi(\mathbf{y}_{0\ldots k})
\end{displaymath}

\subsection{Système Arc-eager}

Le système arc-eager est un modèle d'analyse dont les configurations
sont des triplets $\langle \mathbf{S},\mathbf{B} ,  A\rangle$ où
$\mathbf{S}$ est une pile, $\mathbf{B}$ une file et $A$ un ensemble d'arcs.
La donnée à analyser $\mathbf{x} = w_0\ldots w_n$ est une séquence de mots
dont le mot $w_0$ est par convention un mot artificiel qui représente
la racine de l'arbre.

L'algorithme (Figure \ref{fig-AE}) commence avec un état initial où la
pile est vide et la file remplie de la séquence de mots. Il termine
lorsque le buffer est vide. Contrairement au système arc-standard, ici
le système essaye d'attacher les nouveaux mots le plus rapidement possible dans
la structure~: les transitions left-arc et right-arc attachent le
premier mot du buffer à la structure avant même qu'il ait été placé
sur la pile. La transition de réduction qui supprime la tête de pile
indique que le mot ne fera plus partie d'une relation de dépendance
par la suite.  Quant à la transition de décalage, elle est plus classique. 
\begin{figure}[htbp]
\begin{displaymath}
\begin{array}{rccll}
\mathbf{init}  &\langle w_0 ,  w_1 \ldots w_n ,\emptyset \rangle\\
\mathbf{but}  & \langle \mathbf{S} ,\epsilon , A \rangle\\
\mathbf{shift} & \langle \mathbf{S} ,  w_i | \mathbf{B} , A   \rangle
&\Rightarrow &\langle \mathbf{S} | w_i ,  \mathbf{B} , A   \rangle\\
\mathbf{left-arc} &\langle \mathbf{S}| w_i , w_j|\mathbf{B} , A
\rangle &\Rightarrow& \langle \mathbf{S}, w_j | \mathbf{B} , A \cup \{
j\rightarrow i \}   \rangle & (i\not = w_0 \text{ et } \lnot \exists k
(k\rightarrow i \in A) )\\
\mathbf{right-arc }  &\langle \mathbf{S}|w_i , w_j | \mathbf{B} , A   \rangle
&\Rightarrow & 
\langle \mathbf{S}| w_i | w_j , \mathbf{B} , A \cup \{
i \rightarrow j \}   \rangle
&\lnot\exists k (k\rightarrow j \in A)\\
\mathbf{reduce}&\langle \mathbf{S}|w_i , \mathbf{B} , A   \rangle
&\Rightarrow & 
\langle \mathbf{S} , \mathbf{B} , A   \rangle & 
\exists k (k\rightarrow i \in A)
\end{array}
\end{displaymath}
\caption{\label{fig-AE}Le système de transitions arc eager}
\end{figure}

Le système arc-eager offre des garanties plus faibles que
arc-standard~: le but est satisfait dès que le buffer est vide. 
En particulier il ne garantit pas que l'analyse renvoie
un arbre de dépendances unique. Il renvoie en général une forêt~:
plusieurs racines sont possibles. Il est par conséquent classique
d'ajouter une étape de finalisation dans les implémentations qui
relie l'ensemble des racines résultantes à $w_0$.


\begin{figure}[htbp]

\scalebox{0.7}
{\begin{tabular}{llll}\toprule
{\sc Arcs} & {\sc Pile} & {\sc File}&{\sc Action}\\\midrule
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\end{dependency}}
&{\bf root}
&j' ,  ai ,  réservé , un , vol , pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\end{dependency}}
&{\bf root} , j' 
&  ai ,  réservé , un , vol , pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\end{dependency}}
&{\bf root} , j' , ai 
&  réservé , un , vol , pour , Sophie
&left-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\end{dependency}}
&{\bf root} , j'  
&  réservé , un , vol , pour , Sophie
&left-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\end{dependency}}
&{\bf root}  
&  réservé , un , vol , pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\end{dependency}}
&{\bf root} , réservé 
&  un , vol , pour , Sophie
&shift\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\end{dependency}}
&{\bf root} , réservé ,  un ,
& vol , pour , Sophie
&left-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\end{dependency}}
&{\bf root} , réservé ,
& vol , pour , Sophie
&right-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\end{dependency}}
&{\bf root} , réservé , vol
& pour , Sophie
&reduce\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\end{dependency}}
&{\bf root} , réservé
& pour , Sophie
&right-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\depedge{4}{7}{}
\end{dependency}}
&{\bf root} , réservé ,  pour 
&Sophie
&right-arc\\
\raisebox{-0.25cm}{
\begin{dependency}[theme=simple]
\begin{deptext}
{\bf root} \& j' \& ai \& réservé \& un \& vol \& pour \& Sophie\\  
\end{deptext}
\depedge{4}{3}{}
\depedge{4}{2}{}
\depedge{6}{5}{}
\depedge{4}{6}{}
\depedge{4}{7}{}
\depedge{7}{8}{}
\end{dependency}}
&{\bf root} , réservé ,  pour , Sophie
& $\epsilon$
&terminate (or reduce) \\
\bottomrule
\end{tabular}}

\end{figure}

\paragraph{Dérivations et pondérations} 
Un pas de dérivation est le passage d'une configuration $c_i$ à une
configuration $c_{i+1}$ en utilisant une transition (ou action) $t\in
\{shift, left-arc,right-arc, reduce,stop\}$. L'action {\bf stop} est exécutée
uniquement pour terminer l'analyse lorsque le buffer est vide.

Une séquence de dérivation, ou {\bf dérivation}, est une séquence de la
forme $\mathbf{d} = (c_0, t_0) \ldots (c_m,t_m)$. On pondère une dérivation en
faisant l'hypothèse que son score se décompose par la somme~:
\begin{equation}
\Psi(\mathbf{d}) = \sum_{i=0}^m  \psi(c_i,t_i,\mathbf{x})
\end{equation}
où $\mathbf{x}$ représente la séquence de mots à analyser.
Le problème d'analyse syntaxique consiste en général à résoudre~:
\begin{equation}
{\mathbf{\hat{d}}} = \mathop{\text{argmax}}_{\mathbf{d} \in \mathbf{D}(\mathbf{x})} \Psi(\mathbf{d}) 
\end{equation}
où $\mathbf{D}(\mathbf{x})$ représente l'ensemble des dérivations possibles pour
la phrase à analyser.

Les dérivations complètes du système de transition arc-eager ont comme
propriété que leur longueur vaut {\bf au plus} $2n-1$ pas de dérivation pour une
phrase de $w_0\ldots w_n$ mots~: il est en effet possible de terminer
une analyse en $n$ étapes (après $n$ décalages tous les mots sont
racines d'un arbre différent et l'analyse est potentiellement terminée). 
 
Cette propriété complique l'usage du système arc-eager en
combinaison avec une méthode de recherche de solutions en faisceau.
En effet il faut pouvoir comparer des dérivations de longueurs
différentes, ce qui est généralement problématique tant pour la 
gestion du faisceau que de la gestion de la corrélation entre longueur
de la séquence et score de la dérivation.
Pour ces raisons, le système arc-eager est habituellement utilisé avec
un modèle de recherche de solutions qui est glouton et une
approximation par des modèles statistiques locaux.
Il faut finalement remarquer que dans le contexte où le modèle est glouton, la
procédure d'analyse syntaxique est particulièrement simple (Algorithme
\ref{algo-arceager}).
\begin{algorithm}[htbp]
\begin{algorithmic}[0]
\Function{ArcEagerGreedyParse}{$\mathbf{x}$}
\State $c \gets \langle w_0, w_1\ldots w_n,\emptyset\rangle$
\While {$c_{buffer} \not = \emptyset$}
\State $t \gets \mathop{\text{argmax}}_{t\in T} \psi(c,t,\mathbf{x})$
\Comment{$T$ est l'ensemble des actions}
\State $c \gets t(c)$
\EndWhile
\State \Return $c$
\EndFunction
\end{algorithmic}
\caption{\label{algo-arceager}Algorithme d'analyse Arc Eager glouton}
\end{algorithm}




\paragraph{Estimation des paramètres par modèle local}
L'estimation des paramètres se réalise à partir d'un 
corpus annoté $C = \mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$ qui est un
exemplaire de $N$ phrases où chaque séquence de mots $\mathbf{x}_i$
est associée à un arbre de référence $\mathbf{y}_i$.

Dans le contexte d'un modèle local, la procédure d'apprentissage consiste à estimer un vecteur de
paramètres $\mathbf{w}$ de telle sorte que pour chaque configuration
d'analyse identifiable dans les données de référence, la prédiction de
l'algorithme soit la plus similaire à l'action de référence trouvée
dans les données. Cette procédure suppose de transformer un treebank
$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$
en une séquence de couples $\mathop{(x_i,y_i)}_{i=1}^{N'}$
de configurations $x_i$ et d'actions $y_i$ à prédire.

On réalise cette opération à l'aide d'un {\bf oracle} statique
(Algorithme \ref{algo-AE-oracle}) qui permet de simuler l'analyse de référence en utilisant
comme donnée $A$ l'ensemble des arcs de l'arbre de référence. 

\begin{algorithm}
\scriptsize
\begin{algorithmic}[0]
\Function{ArcEagerStaticOracle}{$\mathbf{S},\mathbf{B},A, A_{ref}$}
\If{ $\mathbf{S} | i  $ {\bf and} $j | \mathbf{B}$} \Comment{Il y a au moins 1 élément sur la
pile et 1 sur la file}
\If{$j\rightarrow i \in A_{ref}$ {\bf and} $i\not = 0$}
\State \Return $\mathbf{left-arc}$
\ElsIf{$i\rightarrow j \in A_{ref}$}
\State \Return $\mathbf{right-arc}$
\EndIf
\EndIf
\If {$\mathbf{S} | i$}\Comment{Il y a au moins 1 élément sur la pile}\
\If{$\exists k (k\rightarrow i \in A)$ {\bf and} $\forall
  k' (i\rightarrow k') \in A_{ref} \Rightarrow (i\rightarrow k') \in A$}
\State \Return $\mathbf{reduce}$
\EndIf
\EndIf
\If {$j | \mathbf{B}$}\Comment{Il y a au moins 1 élément dans le
  buffer}\State\Return $\mathbf{shift}$
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-AE-oracle} Oracle statique pour le système arc
  eager}
\end{algorithm}
Le jeu de données transformé où les arbres $\mathbf{y}_i$ sont
transformés en une séquence de couples $\mathop{(x_i,t_i)}_{i=1}^N$
est utilisé pour entraîner tout modèle d'apprentissage approprié~:
modèle à large marge local, modèle de régression logistique
multinomiale ou réseau de neurones. Contrairement aux modèles
structurés présentés précédemment, calculer le facteur de
normalisation pour les modèles logistiques ne pose pas de problème
particulier dans le cas des modèles locaux. On donne ici un exemple
d'algorithme d'estimation
de paramètres  à l'aide de l'algorithme du
perceptron (Algorithme \ref{perceptron-AE}).

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{arc-eager-local-perceptron}{$\mathop{(x_i,t_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{t} \gets \mathop{\text{argmax}}_{t\in
  T}  \mathbf{w}^T \boldsymbol\Phi(c_i,t)$
\If{$\hat{t} \not = t_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[ \boldsymbol\Phi(c_j,t_j) 
       - \boldsymbol\Phi(c_j,\hat{t})   \right]$ 
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{perceptron-AE}Perceptron pour un système à
  apprentissage local}
\end{algorithm}

\paragraph{Unicité de la dérivation et oracles dynamiques}

La procédure d'apprentissage local avec oracle statique 
consiste à transformer un treebank $\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$
en une séquence de couples $\mathop{(x_i,y_i)}_{i=1}^{N'}$
de configurations $x_i$ et d'actions $y_i$ à prédire.

Cette transformation pose deux types de problèmes. D'une part, on
suppose (a) qu'il existe une et une seule dérivation qui correspond à un
arbre de dépendances, ce qui n'est pas toujours vrai (Figure \ref{fig-multi-deriv}). D'autre part (b) le modèle statistique est
entraîné uniquement sur des couples configurations et actions
$(x_i,y_i)$ de référence~: lorsque l'analyseur a commis une erreur en
cours d'analyse, il se trouve potentiellement face à de nouvelles
configurations qu'il n'aura jamais vues lors de
l'apprentissage du modèle statistique.

L'idée des oracles dynamiques consiste à corriger (a) et (b)
en  fournissant à la procédure d'apprentissage 
des couples $(x_i,y_i)$ qui proviennent des multiples dérivations
potentielles de l'arbre de référence ou de couples issus de
dérivations légèrement erronnées qui simulent l'état de l'analyseur lorsqu'il a commis
une ou plusieurs erreurs d'analyse. Le but est de fournir à l'analyseur des données qui
lui permettent d'éviter la propagation d'erreurs.

\begin{figure}[htbp]
\begin{center}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
$w_0$ \& $w_1$ \& $w_2$ \& $w_3$\& $w_4$ \& $w_5$ \& $w_6$ \\
\end{deptext}
\depedge[hide label]{1}{3}{ }
\depedge[hide label]{3}{2}{ }
 \depedge[hide label]{3}{4}{ }
 \depedge[hide label]{3}{4}{ }
 \depedge[hide label]{3}{6}{ }
 \depedge[hide label]{3}{7}{ }
 \depedge[hide label]{6}{5}{ }
\end{dependency}
\begin{tabular}{l|ccccccccccc}\toprule
Dérivation A&S&LA&RA&RA&S&LA&R&RA&R&RA\\
Dérivation B&S&LA&RA&RA&R&S&LA&RA&R&RA\\\bottomrule
\end{tabular}
\end{center}
\caption{\label{fig-multi-deriv}Dérivations multiples pour un arbre de dépendances}
\end{figure}

Un {\bf oracle dynamique} est une fonction qui étant donnée une
configuration d'analyse et un arbre de référence donne l'ensemble des meilleures
actions à réaliser pour minimiser l'erreur d'analyse.

En notant $A_{ref}$ l'ensemble des arcs d'un arbre de dépendances de
référence et $A$ l'ensemble des arcs d'une configuration donnée, on
définit~:
\begin{equation}
{\cal L} (A_{ref},A) = |A_{ref} - A|
\end{equation}
Ce coût représente le nombre d'arcs de référence $A_{ref}$ qui sont
absents de l'ensemble  $A$ des arcs de la configuration. 
De plus, on dit qu'un ensemble d'arcs $A$ est atteignable depuis une
configuration $c = \langle \mathbf{S},\mathbf{B},A'\rangle$, ce que
l'on note $c\rightsquigarrow A$, si et seulement si il existe
une séquence de transitions qui mène de $c$ à $c' = \langle \mathbf{S}',\mathbf{B}',A\rangle$
\'Etant donnée une configuration $c$, une action $t$ et un arbre de
référence $A_{ref}$, on définit le coût d'exécution d'une action comme 
suit~:
\begin{equation}
\label{eq-odyn-objective}
{\cal C}(c,t,A_{ref}) = \left(\mathop{\text{min}}_{A:t(c)\rightsquigarrow A} {\cal
  L}(A_{ref},A) \right)- \left(\mathop{\text{min}}_{A:c\rightsquigarrow A} {\cal
  L}(A_{ref},A)  \right) 
\end{equation}
Autrement dit, le coût d'une transition représente la différence de
coût entre le meilleur arbre atteignable après avoir exécuté l'action $t$
et le meilleur arbre atteignable avant d'avoir exécuté l'action
$t$. Dans le cas d'une analyse en dépendances cela correspond 

Remarquons qu'il existe au moins une transition $t$ pour laquelle 
${\cal C}(c,t,A_{ref}) = 0$. La raison est que si $A$ est atteignable
depuis $c$ alors il existe nécessairement une transition qui permet
d'y arriver. On peut donc définir la fonction indicatrice suivante~:
\begin{equation}
\label{eq-zerocost}
o(c,t,A_{ref}) = \left\{
\begin{array}{ll}
1 & \text{si } {\cal C}(c,t,A_{ref}) = 0\\
0 & \text{sinon} 
\end{array}\right.
\end{equation}
\'Etant donnée une configuration d'analyse $c$, 
l'ensemble des actions qui minimisent les erreurs d'analyse est
l'ensemble des actions pour lequel (\ref{eq-zerocost}) est vrai, c'est-à-dire 
 l'ensemble $Z = \{ t |  o(c,t,A_{ref})  = 1\}$. On peut se convaincre
 que $Z$ est un ensemble de plus d'un élément en considérant la figure \ref{fig-multi-deriv}.

\begin{algorithm}[htbp]
\scriptsize
\begin{algorithmic}[0]
\Function{Dynamic-Perceptron-Arc-Eager}{$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}_{i=1}^N,E$}
\State $\mathbf{w} \gets \mathbf{0}$
\For{$1\leq e \leq E$}
\For{$1\leq i \leq N$}
\State $A_{ref} \gets$ \Call{Arcs}{$\mathbf{y}_i$}
\State $w_0\ldots w_n \gets \mathbf{x}_i$
\State $c \gets \langle w_0 , w_1\ldots w_n, \epsilon \rangle $
\While {$c_{buffer} \not = \emptyset$}
\State $\hat{t} = \mathop{\text{argmax}}_{t\in T} \mathbf{w}^T \boldsymbol\Phi(c,t)$
\State $Z \gets \{t | o(c,t,A_{ref}) = 1\}$
\State $t_o \gets \mathop{\text{argmax}}_{t\in Z} \mathbf{w}^T \boldsymbol\Phi(c,t)$
\If{$\hat{t} \not\in Z$}
\State $\mathbf{w} \gets  \mathbf{w} + \boldsymbol\Phi(c,t_o) - \boldsymbol\Phi(c,\hat{t}) $
\EndIf
\State $t \gets  $\Call{Choose}{$e$,$\hat{t}$,$Z$}
\State $c\gets t(c)$
\EndWhile
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-dynamic-oracle}Apprentissage par oracle dynamique pour un système arc eager pondéré par un perceptron}
\end{algorithm}
L'oracle dynamique est une fonction capable de nous dire quelles
actions sont optimales dans une configuration donnée. On peut donc
l'utiliser dans un scénario d'apprentissage comme illustré en
Algorithme \ref{algo-dynamic-oracle} pour le cas du perceptron.
La fonction de choix (notée {\sc Choose})  choisira $\hat{t}$ si $t\in
Z$, sinon elle choisira un élément aléatoirement dans $Z$.

On peut également modifier la fonction de choix pour faire explorer
lors de l'apprentissage des configurations d'erreur. Dans ce contexte
on décidera d'une stratégie d'exploration approriée des configurations
d'erreur. Par exemple on pourra choisir une action $\hat{t} \not\in Z$
 après un certain nombre d'époques et en fixant une certaine
 probabilité de choisir entre l'action erronée ou sa correction prise
 dans l'ensemble $Z$.

\paragraph{Oracle dynamique pour le système arc-eager}
La difficulté pour créer un oracle dynamique réside dans la résolution
des problèmes de minimisation en équation (\ref{eq-odyn-objective})~:
déterminer le meilleur arbre atteignable depuis une configuration $c =
\langle \mathbf{S},\mathbf{B},A\rangle$ donnée n'est pas un problème
algorithmiquement trivial pour la plupart
des systèmes de transitions.

Le système de transitions arc-eager a la propriété d'être
{\sl arc-decomposable}, ce qui permet d'évaluer cette équation très
efficacement. Pour comprendre cette propriété on définit au préalable deux notions,
l'{\sl arc-reachability} et la {\sl tree-reachability}.
On dit d'un ensemble d'arcs $A$ qu'il est atteignable ({\sl
  tree-reachable}) depuis $c$ si et
seulement si une séquence de transitions mène de $c$ à une
configuration $c' = \langle \mathbf{S}',\mathbf{B}',A'\rangle$
telle que $A= A'$. 
On dit d'un arc $i \rightarrow j$ (resp. $j\rightarrow i$) qu'il est atteignable en $c$ si 
$i \rightarrow j \in A$ ou que $i \in \mathbf{S} \cup \mathbf{B}$
et $j \in \mathbf{B}$.
On dit d'un système de transitions qu'il est arc décomposable si le
problème de {\sl tree reachability} se réduit au problème d'{\sl arc reachability}.

Un système arc décomposable a donc des propriétés qui permettent très
facilement de détecter si un arc de référence est perdu en suivant une
transition, 
ce qui permet d'évaluer (\ref{eq-odyn-objective}) avec un faible coût
en calculs. Contrairement au système arc-eager, le système arc
standard ne possède
pas cette propriété de décomposabilité, ce qui explique pourquoi c'est
le premier qui est utilisé principalement avec des oracles dynamiques.

\`A partir de là, on peut ainsi dériver un oracle dynamique pour le
système arc-eager (Figure \ref{fig-eager-dynamic}). Considérons une configuration  $c = \langle
\mathbf{S}|i, j|\mathbf{B},A\rangle$ et un ensemble d'arcs de
référence $A_{ref}$. 


\begin{figure}[htbp]
\begin{tabular}{lcl}\toprule
\multicolumn{3}{c}{$c = \langle \mathbf{S}|i,j|\mathbf{B},A\rangle$}\\\midrule
$o(c,LA,A_{ref})$ &=&
$\left\{ 
\begin{array}{ll}
0 &\text{si }\exists k \in \mathbf{B} |  i \rightarrow  k \in A_{ref} \lor  k
\rightarrow  i \in A_{ref}  \\
1 & \text{sinon}
\end{array}
\right.$\\
$o(c,RA,A_{ref})$ &=&
$\left\{ 
\begin{array}{ll}
0 &\text{si }\exists k \in \mathbf{B}\cup \mathbf{S} |  k \rightarrow
j \in A_{ref}  \lor \exists k \in \mathbf{S} |  j \rightarrow  k \in A_{ref}  \\
1 & \text{sinon}
\end{array}
\right.$\\
$o(c,R,A_{ref})$ &=&
$\left\{ 
\begin{array}{ll}
0 &\text{si } \exists k \in \mathbf{B} |  i \rightarrow  k \in A_{ref}  \\
1 & \text{sinon}
\end{array}
\right.$\\
$o(c,S,A_{ref})$ &=&
$\left\{ 
\begin{array}{ll}
0 &\text{si }\exists k \in \mathbf{S} |  k \rightarrow
j \in A_{ref}  \lor \exists k \in \mathbf{S} |  j \rightarrow  k \in A_{ref}  \\
1 & \text{sinon}
\end{array}
\right.$\\
\\\bottomrule
\end{tabular}
\caption{\label{fig-eager-dynamic}Oracle dynamique pour le système arc-eager}
\end{figure}



L'action left-arc crée un arc
$j\rightarrow i$ et enlève $i$ de la pile. Cela signifie que tout arc
$i\rightarrow k (k \in \mathbf{B})$ ou $k\rightarrow i (k \in
\mathbf{B})$ devient inaccessible. Le coût est le nombre d'arcs de ce
type qui existent dans $A_{ref}$.

L'action right-arc crée un arc $i\rightarrow j$ et empile $j$. Cela
signifie que $j$ ne peut plus dominer un dépendant dans $\mathbf{S}$ 
et que $j$ ne peut plus devenir dépendant d'aucun autre mot dans
$\mathbf{S}$ et $\mathbf{B}$ (vu qu'un mot ne peut avoir qu'une
tête).  Le coût est le nombre d'arcs de ce type qui existent dans $A_{ref}$.

L'action de réduction qui dépile $i$ signifie que plus aucun arc de la
forme $i\rightarrow k (k \in \mathbf{B})$ ne peut plus être créé. 
Le coût est le nombre d'arcs de ce type qui existent dans
$A_{ref}$\footnote{Les arcs de la forme $k\rightarrow i$ ne peuvent
  plus être créés non plus, mais ils sont déjà pris en compte par les
  autres règles.}.

L'action de décalage signifie que $j$ ne pourra plus être mis en
relation de dépendance avec des éléments de la pile. Le coût est le
nombre d'arcs de ce type qui existent dans $A_{ref}$.



\subsection{Modèle de Covington}

Idée : $\mathbf{S}_1$ = mots déjà traités
$\mathbf{S}_2$ = liste qui contient successivement les candidats à
attacher à $w_j$


\begin{figure}[htbp]
\begin{displaymath}
\begin{array}{rccll}
\mathbf{init}  &\langle \epsilon , \epsilon , w_0 \ldots w_n ,\emptyset \rangle\\
\mathbf{but}  & \langle \epsilon , w_0|\mathbf{S}_2 , w_n, A \rangle && (to check)\\
\mathbf{shift} & \langle \mathbf{S}_1, \mathbf{S}_2 ,  w_i | \mathbf{B} , A   \rangle
&\Rightarrow &\langle  \mathbf{S}_1\mathbf{S}_2 | w_i , \epsilon ,
\mathbf{B} , A   \rangle\\

\mathbf{no-arc}& \langle \mathbf{S}_1 | w_i , \mathbf{S}_2 , \mathbf{B} , A \rangle 
&\Rightarrow &\langle \mathbf{S}_1 ,  w_i |\mathbf{S}_2 ,\mathbf{B} , A\rangle \\

\mathbf{left-arc}& \langle \mathbf{S}_1 | w_i , \mathbf{S}_2 , w_j | \mathbf{B} , A \rangle 
&\Rightarrow &\langle \mathbf{S}_1 ,  w_i |\mathbf{S}_2 ,w_j|\mathbf{B} ,
A \cup \{j\rightarrow i\}\rangle  
(\lnot\exists k (k\rightarrow i  \in A) \land i \stackrel{*}{\rightarrow } j \not\in A*) \\

\mathbf{right-arc}& \langle \mathbf{S}_1 | w_i , \mathbf{S}_2 , w_j | \mathbf{B} , A \rangle 
&\Rightarrow &\langle \mathbf{S}_1 ,  w_i |\mathbf{S}_2 ,w_j|\mathbf{B} ,
A \cup \{i\rightarrow j\}\rangle 
(\lnot\exists k (k\rightarrow j  \in A) \land j \stackrel{*}{\rightarrow } i \not\in A*)
\end{array}
\end{displaymath}
\caption{\label{fig-covington}Le système de transitions à pile partagée}
\end{figure}


\section{Analyse CKY}
\subsection{La version naïve}

On peut envisager adapter l'algorithme {\sc cky} au cas de l'analyse
en dépendances de manière directe et naïve. C'est ce que nous
présentons dans ce qui suit. Cette première solution pose toutefois un
problème de complexité car les analyses sont produites en ${\cal O}(n^5)$. On donne en section
\ref{sec-arc-factored} une version moins naïve qui produit des
analyses projectives en ${\cal O}(n^3)$ et qui est la version
utilisée dans les implémentations habituelles.

Sous forme déductive, les items de l'algorithme sont des triplets 
de la forme $\langle i,j,h \rangle$ où $i$ est l'indice de l'extrémité
gauche de l'empan, $j$ l'indice de l'extrémité droite de l'empan et
$h \, (i\leq h \leq j)$ est la position de la tête dans la séquence de
mots $\mathbf{x} = w_1\ldots w_n$ à analyser. 
En suivant le principe classique de l'algorithme {\sc cky}, l'algorithme
donné ici commence en supposant que chaque mot définit son propre empan puis
essaye de combiner des empans contigus en empans de plus en plus
larges en utilisant deux actions de réductions qui se distinguent par
leur manière d'assigner la tête au nouvel empan. On résume cet
algorithme sous forme de système déductif en figure \ref{fig-cky-dep}.
\begin{figure}[htbp]

\begin{eqnarray*}
\mathbf{init}  &\frac{\, }{\langle i, i+1, w_i \rangle} & (0\leq i <
n)\\
\mathbf{but}  &\langle 0,n, h \rangle \\
\mathbf{reduce}(\curvearrowleft) &
\frac{\langle i,k,h \rangle\quad \langle k,j,h' \rangle}
{\langle i,j,h\rangle}\\
\mathbf{reduce}(\curvearrowright) &
\frac{\langle i,k,h \rangle\quad \langle k,j,h' \rangle}
{\langle i,j,h'\rangle} 
\end{eqnarray*}

\caption{\label{fig-cky-dep} Algorithme {\sc cky} pour l'analyse en dépendances}
\end{figure}
On peut remarquer que chacune des règles de réduction (gauche et droite) fait intervenir 5
indices libres ce qui suggère une complexité en ${\cal O}(n^5)$.


\paragraph{Estimation des poids}
Cet algorithme peut être pondéré par tout modèle discriminant.
L'estimation des poids pour un modèle {\sc crf} demande de déployer 
des récurrences dedans dehors ({\em inside-outside}) et est difficile à rendre efficace à l'usage. Les modèles à large marge sont en
principe plus faciles à utiliser mais cet algorithme naïf n'est en
général pas utilisé en pratique. C'est l'algorithme par factorisation
des arcs présenté ci-dessous qui est utilisé en pratique.

\subsection{Factorisation en arcs}
\label{sec-arc-factored}
L'algorithme d'analyse en dépendances par factorisation des arcs ({\em arc factored parser}, Algorithme \ref{algo-eisner})
peut-être vu comme une reformulation de l'algorithme {\sc cky} au cas des dépendances projectives.
L'algorithme cherche à construire itérativement des sous-arbres qui couvrent des empans de plus en plus grands
et s'arrête lorsqu'il a construit le meilleur sous-arbre pour  un empan qui couvre toute la phrase à analyser.

Pour un empan $(i,j)$ l'algorithme construit les {\bf sous-arbres incomplets} ($\bot$) qui couvrent cet empan, qu'ils commencent en $i$ ou en $j$
en créant les arcs correspondants. Cette première étape cherche à construire des arbres dont un arc $i\rightarrow j$ ou $j\rightarrow i$
couvre l'intégralité de l'empan. Dans un second temps, l'algorithme cherche à produire des {\bf sous-arbres complets} ($\top$) en combinant
 un arbre incomplet avec un arbre complet qui couvre un empan plus petit, ce qui permet de couvrir l'empan avec des relations de dépendances indirectes de la forme $i\stackrel{*}{\rightarrow} j$ ou
$j\stackrel{*}{\rightarrow} i$.

\begin{algorithm}[htbp]

\scriptsize
\begin{algorithmic}[0]
\Function{ArcFactored}{$\mathbf{x}$,n}
\State C[i][i][d][c] $\gets 0.0 \quad 0 \leq i \leq n, d\in
\{\curvearrowleft, \curvearrowright\}, c \in \{\top,\bot \}$ 

\For {$1 \leq span \leq n$}
  \For{$1\leq i \leq n-span$}
     \State $j \gets i + span$
     \State\Comment{Arbres incomplets}
     \State C[i][j][$\curvearrowleft$][$\bot$] $\gets
     \mathop{\text{max}}_{i\leq k < j}(C[i][k][\curvearrowright][\top]
     + C[k+1][j][\curvearrowleft][\top] + score(\mathbf{x},j,i))$
     \State C[i][j][$\curvearrowright$][$\bot$] $\gets \mathop{\text{max}}_{i\leq k < j}(C[i][k][\curvearrowright][\top] + C[k+1][j][\curvearrowleft][\top] + score(\mathbf{x},i,j))$ 
     \State\Comment{Arbres complets}
     \State C[i][j][$\curvearrowleft$][$\top$] $\gets \mathop{\text{max}}_{i\leq k < j}(C[i][k][\curvearrowleft][\top] + C[k][j][\curvearrowleft][\bot])$     
     \State C[i][j][$\curvearrowright$][$\top$] $\gets \mathop{\text{max}}_{i < k \leq j}(C[i][k][\curvearrowright][\bot] + C[k][j][\curvearrowright][\top])$     

 \EndFor
\EndFor
\EndFunction
\end{algorithmic}

\caption{\label{algo-eisner}Algorithme d'analyse à arcs factorisés (Eisner)}
\end{algorithm}



\paragraph{Arbres incomplets}
Pour un empan donné $(i,j)$ l'algorithme commence par créer les arcs
$i\rightarrow j$ et $j\rightarrow i$. On dit de ces arcs qu'ils
représentent des arbres incomplets car ils ne codent pas toute la
projection du gouverneur. Par exemple, si $i$ est choisi comme
gouverneur et que l'arc $i\rightarrow j$ est ajouté,
l'arbre incomplet va capturer toutes les relations 
$i \stackrel{*}{\rightarrow} k$ pour $i\leq k \leq j$. Par contre il
est possible que des relations $i \stackrel{*}{\rightarrow} l$
existent avec $l > j$. 

\begin{figure}[htbp]
\begin{minipage}[t]{.5\textwidth}
\begin{center}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
i \& j \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{2}{ } 
\end{dependency}
\hrule
\scalebox{0.65}{
\begin{tabular}{cc}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{4}{ } 
  \depedge[hide label]{1}{2}{ }
  \depedge[hide label]{4}{3}{ }
\end{dependency}
&
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{4}{ } 
  \depedge[hide label]{1}{2}{ }
  \depedge[hide label]{3}{4}{ }
\end{dependency}\\
ok & DAG \\
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{4}{ } 
  \depedge[hide label]{2}{1}{ }
  \depedge[hide label]{4}{3}{ }
\end{dependency}
&
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{1}{4}{ } 
  \depedge[hide label]{2}{1}{ }
  \depedge[hide label]{3}{4}{ }
\end{dependency}\\
non projective & non projective + DAG \\
\end{tabular}}
\end{center}

\end{minipage}
\begin{minipage}[t]{.5\textwidth}
\begin{center}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
i \& j \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{2}{1}{ } 
\end{dependency}
\hrule
\scalebox{0.65}{
\begin{tabular}{cc}
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
 \depedge[hide label,edge style={ultra thick,dotted}]{4}{1}{ } 
  \depedge[hide label]{1}{2}{ }
  \depedge[hide label]{4}{3}{ }
\end{dependency}
&
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{4}{1}{ } 
  \depedge[hide label]{1}{2}{ }
  \depedge[hide label]{3}{4}{ }
\end{dependency}\\
ok & non projective \\
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{4}{1}{ } 
  \depedge[hide label]{2}{1}{ }
  \depedge[hide label]{4}{3}{ }
\end{dependency}
&
\begin{dependency}
\begin{deptext}[column sep=.5cm]
w$_i$ \& w$_k$ \& w$_{k+1}$ \&  w$_j$ \\
\end{deptext}
  \depedge[hide label,edge style={ultra thick,dotted}]{4}{1}{ } 
  \depedge[hide label]{2}{1}{ }
  \depedge[hide label]{3}{4}{ }
\end{dependency}\\
DAG & non projective + DAG \\
\end{tabular}}

\end{center}
\end{minipage}
\caption{\label{fig-incomplete}Cas admissibles pour les arbres incomplets}
\end{figure}

On peut remarquer en Figure \ref{fig-incomplete} que 
l'ajout d'un arc  $i \rightarrow j$ (ou $j \rightarrow i$)
n'est autorisé que dans peu de configurations préexistantes. Les différents cas sont
illustrés sur la figure et motivent les lignes correspondantes de
l'algorithme \ref{algo-eisner}. Seul le cas où à la fois $i$ et $j$
ont des dépendants qui sont situés dans l'intervalle $i\ldots j$ autorise
la création de l'arc. Les cas alternatifs potentiels créent des
structures en graphe ou des structures non projectives et sont donc interdits par
l'algorithme.

\paragraph{Arbres complets}
La création des arbres incomplets par ajout de l'arc $i\rightarrow j$ permet de créer des sous-arbres de
dépendances tels que le gouverneur $i$ domine l'ensemble des
dépendants $k$ tels que $i\leq k \leq j$. Autrement dit, l'algorithme
garantit la projectivité de l'analyse sur l'empan $i\ldots j$. Par
contre $i$ peut potentiellement dominer des mots $l$ tels que $l > j$
et tels que $i\stackrel{*}{\rightarrow} l$. C'est pour capturer ce
manque qu'il y a une étape supplémentaire de création d'arbres complets. 
Celle-ci consiste à créer des liens de type
$i\stackrel{*}{\rightarrow} l$ en concaténant un arbre incomplet
$i\rightarrow j$ avec un arbre complet de la forme $j\stackrel{*}{\rightarrow} l$.

En résumé, les arbres incomplets relient directement $i\rightarrow j$
(ou $j\rightarrow i$)
sur un empan $i\ldots j$ alors que les arbres incomplets représentent
des liens potentiellement indirects $i\stackrel{*}{\rightarrow} j$ (ou
 $j\stackrel{*}{\rightarrow} i$) qui combinent plusieurs empans.

\paragraph{Complexité}L'intérêt de cet algorithme est qu'il permet d'obtenir un analyseur en
dépendances projectif en ${\cal O}(n^3)$ alors que l'adaptation naïve
de l'algorithme {\sc cky} a une complexité en ${\cal O}(n^5)$

Comparison with naive CYK

\paragraph{Arc factored}

\begin{eqnarray*}
\mathbf{init}&\langle i,i,d,c\rangle &
(0\leq i < n , d\in \{\curvearrowright , \curvearrowleft\}, c \in
\{\top ,\bot \})\\
\mathbf{reduce}(\curvearrowleft)&
\frac{\langle i,k,\curvearrowright,\top \rangle\quad \langle k+1,j,\curvearrowleft,\top \rangle}
{\langle i,j,\curvearrowleft,\bot \rangle} \\
\mathbf{reduce}(\curvearrowright)&\frac{\langle i,k,\curvearrowright,\top \rangle\quad \langle k+1,j,\curvearrowleft,\top \rangle}
{\langle i,j,\curvearrowright,\bot \rangle}\\
\end{eqnarray*}

\begin{displaymath}
\frac{\langle i,k,\curvearrowright,\top \rangle\quad \langle k,j,\curvearrowright,\bot \rangle}
{\langle i,j,\curvearrowright,\top \rangle} \quad complete(\curvearrowright) \, s.c. (k < j)
\end{displaymath}
\begin{displaymath}
\frac{\langle i,k,\curvearrowleft,\bot \rangle\quad \langle k,j,\curvearrowleft,\top \rangle}
{\langle i,j,\curvearrowleft,\top \rangle} \quad complete(\curvearrowleft) \, s.c. (k < j)
\end{displaymath}

\paragraph{Estimation des poids} L'analyse syntaxique par factorisation des
arcs ({\em arc factored parsing}) suppose que le score d'un arbre se
décompose comme la somme des scores de ses arcs~:
\begin{equation}
\label{eq-arc-factored}
\Psi({\mathbf{y}}) = \sum_{(i,j) \in \mathbf{y}} \psi(\mathbf{x},i,j)
\end{equation}
On peut en principe utiliser n'importe quelle méthode d'apprentissage 
structurée (perceptron, large marge ou {\sc crf}) 
pour réaliser l'estimation de poids à partir de données.

Comme pour la plupart des algorithmes d'analyse syntaxique, 
l'estimation des poids par un {\sc crf} est un processus relativement
lourd en pratique (mais pas impossible en théorie). Par conséquent, on présente ici une variante de
l'algorithme du perceptron qui permet d'estimer les poids à partir
d'un treebank de référence.

On suppose qu’un corpus annoté $C = \mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$ est un
exemplaire de $N$ phrases où chaque séquence de mots $\mathbf{x}_i$
est associée à un arbre de référence $\mathbf{y}_i$.
L'algorithme \ref{perceptron-eisner} est un variante de l'algorithme
du perceptron vu précédemment qui tire parti de la décomposition
en arcs de l'arbre de dépendances telle que posée en équation (\ref{eq-arc-factored}).

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{arc-factored-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{\mathbf{y}} \gets \mathop{\text{argmax}}_{\mathbf{y}\in
  \mathbf{Y}} 
\sum_{(i,j) \in \mathbf{y}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,i,j)$
\Comment{Parsing}
\If{$\hat{\mathbf{y}} \not = \mathbf{y}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[ \sum_{(i,j) \in \mathbf{y}_i} \boldsymbol\Phi(\mathbf{x}_i,i,j) 
       - \sum_{(i,j) \in
         \hat{\mathbf{y}}}\boldsymbol\Phi(\mathbf{x}_i,i,j)   \right]$ 
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{perceptron-eisner}Perceptron pour l'analyse factorisée
en arcs}
\end{algorithm}



\section{Exercices}
\begin{itemize}
\item Add I/O and eval functions
\item Add dependency Labels
\item Add bi-LSTM tagger input (and switch to feed forward scorer ?)
\item Error analysis
\end{itemize}




\chapter{Convolutions}


\section{Origine}
Les modèles de convolutions proviennent du traitement du signal.
\'Etant donné un signal source représenté par une fonction du temps
$x(t)$, et un filtre $h(t)$, la convolution des fonctions $x$ et $h$ est
la fonction : 
\begin{displaymath}
(x \circledast h) (t) = \sum_{i = -\infty}^\infty x(i)\, h(t-i)  
\end{displaymath}
pour le cas discret.

La fonction de filtre est une fonction qui en général vaut 0 pour la
très grande partie du domaine temporel. Elle prend des valeurs
non nulles plutôt autour de 0.
\`A titre d'exemple, si:
\begin{displaymath}
  h(j) =
\left\{  \begin{array}{ll}
1 &\text{si } j = 0\\
0 & \text{sinon}
\end{array}\right.
\end{displaymath}
alors le filtre $h$ reproduit le signal $x$ à l'identique. Si
maintenant on définit : 
\begin{displaymath}
  h(j) =
\left\{  \begin{array}{ll}
\frac{1}{3} &\text{si } -1\leq  j \leq 1\\
0 & \text{sinon}
\end{array}\right.
\end{displaymath}
alors le filtre $h$ produit une sortie qui moyenne la valeur $x(t)$
avec les valeurs $x(t\pm 1)$ trouvées dans une fenêtre autour de $t$. 
Intuitivement l'opération de convolution déplace le filtre comme une
fenêtre glissante le long du domaine. 

Lorsqu'on calcule $(x \circledast h)(t)$ pour tout le domaine temporel,
Chaque valeur résultante est fonction des valeurs de $x$ autour de $t$. Par
exemple, en supposant un signal discrétisé $x(t)$:
\begin{center}
\begin{tabular}{lcccccccc}
$x(t)$ & 1 &3 &1 &1 &1& 1 & 3 & 1\\
$t$     & 0 &1 &2 &3 &4&5 & 6&7
\end{tabular}
\end{center}
La convolution en $(x \circledast h)(1) = \frac{1}{3} (1+3+1) =
\frac{5}{3}$. On peut calculer la convolution sur tout le domaine, ce
qui donne:
\begin{center}
\begin{tabular}{l|cccccccc}
$x(t)$                     & 1 &3 &1 &1 &1& 1 & 3 & 1\\
  $t$                       & 0 &1 &2 &3 &4&5 & 6  &7   \\
\hline\hline
$(x \circledast h)(t)$ & $\frac{4}{3}$& $\frac{5}{3}$&$\frac{5}{3}$&1&1&$\frac{5}{3}$&$\frac{5}{3}$&$\frac{4}{3}$
\end{tabular}
\end{center}
On peut observer que dans ce cas-ci le filtre produit un effet de
lissage autour des valeurs maximales de $x(t)$. Ici , il calcule
une moyenne glissante.

\paragraph{Filtre comme tableau de nombres}Observons toutefois que le filtre ne doit pas contenir que
des paramètres constants, par exemple : 
\begin{displaymath}
  h(j) =
\left\{  \begin{array}{ll}
           \frac{1}{2}  &\text{si }  j = \pm 1\\
           2 &\text{si }  j = 0\\
0 & \text{sinon}
\end{array}\right.
\end{displaymath}
Ce dernier filtre peut être noté alternativement comme un tableau de nombres de la forme
:
\begin{center}
  \begin{tabular}{l|ccc}
    $h(t)$ &$\frac{1}{2}$&2&$\frac{1}{2}$\\\hline
    $t$     &-1&0&1
  \end{tabular}
\end{center}
où seules les valeurs de $t$ pour lesquelles $h(t)$ est non nulle sont renseignées.


\section{Implémentations}
%http://colah.github.io/posts/2014-07-Understanding-Convolutions/

Les librairies numériques (Matlab, Numpy) proposent des fonctions de convolution
qui tirent parti de l'intuition qu'un filtre peut être vu comme une
fenêtre glissante de nombres que l'on fait progresser dans le temps. L'idée des
implémentations est de ne pas calculer le grand nombre d'opérations de
multiplication par 0 mais uniquement les opérations où le filtre a des
valeurs non nulles.

Ainsi dans les librairies numériques où le vecteur $h$ est de longueur
$h_N$ et celui-ci sera indexé à partir de 0, comme par exemple:
\begin{center}
  \begin{tabular}{l|ccc} 
    $h(t)$ &$\frac{1}{2}$&2&$\frac{1}{2}$\\\hline
    $t$     &0&1&2
  \end{tabular}
\end{center}
La convolution est implémentée
en itérant uniquement sur les valeurs de $h$
\begin{displaymath}
(x \circledast h)(t) = \sum_{j=0}^{h_N-1} x(t-j-1+ \lceil h_N/2\rceil)\quad h(j)
\end{displaymath}
les valeurs de $j$ sont choisies pour que les indices soient valides
pour les tableaux de nombres $x$ et $h$. Par exemple, supposons que l'on veuille calculer $(x \circledast
h)(2)$ dans l'exemple ci-dessous. 
\begin{center}
  \begin{tabular}{l|cccccccc}
                              &    &\color{gray}$\frac{1}{2}$&\color{gray}$2$&\color{gray}$\frac{1}{2}$\\ 
$x(t)$                     & 0 &0 &3 &0 &0& 0 & 3 & 0\\
  $t$                       & 0 &1 &2 &3 &4& 5 & 6  &7   \\
\hline\hline
$(x \circledast h)(t)$ & $0$& $\frac{3}{2}$&$6$&$\frac{3}{2}$&0&$\frac{3}{2}$&$6$&$\frac{3}{2}$
\end{tabular}
\end{center}
La formule nous indique qu'il faut centrer le filtre autour de
$t=2$ (illustré en gris). Ce qui donne  $\frac{1}{2} \times 0 + 2\times 3 +\frac{1}{2}\times 0
= 6$



\section{Convolutions et apprentissage profond} 

Les convolutions sont utilisées en deep learning principalement pour
traiter les problèmes de vision artificielle. Mais une application au
modèles de langage existe également.
Celle-ci consiste à représenter un mot ou un caractère par un vecteur
(embedding) à chaque étape $t$ temporelle. La convolution, au lieu de
réaliser des opérations sur des scalaires, opère directement sur des
vecteurs pour renvoyer un scalaire qui caractérise $t$.
 

%http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/11/27/Understanding-Convolutions-In-Text/








\appendix
\chapter{Représentations pour les modèles creux}
% \section{Représentation des matrices de poids}

% \subsection{Représentation explicite de la matrice de poids}

% Pour des modèles multiclasses à features,
% l'opération primitive consiste à scorer chaque classe de l'ensemble $\{a,b,c\ldots\}$ à l'aide du vecteur creux de features $\boldsymbol\Phi(x)$ et du vecteur de poids $\mathbf{w}_i$ correspondant à la classe $i$. Ainsi le score de la classe $i$ sera calculé comme suit~:
% \begin{displaymath}
% s_i =  \mathbf{w}_i \cdot \boldsymbol\Phi(x)
% \end{displaymath}
% Comme on souhaite en général donner un score à toutes les classes, on peut organiser les poids en matrice $\mathbf{W}$ dont chaque ligne représente les poids destinés à donner la pondération spécifique à une classe donnée, de telle sorte que le vecteur de scores $\mathbf{s} = \mathbf{W}\cdot \boldsymbol\Phi(x)$ se calcule en une opération.
% On illustre cette représentation ci-dessous~:
% \begin{center}
% \begin{tikzpicture}
% \matrix(S)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]} ] at (0,0)
% {
% 	s_a\\s_b\\s_c\\
% };
% \node[shape=circle,draw=white] (X) at (1.25,0) {=};
% \matrix(A)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]}] at (4,0)
% {
%  w_{a1} & w_{a2} & \ldots & w_{ap}\\
%  w_{b1} & w_{b2} & \ldots & w_{bp}\\
%  w_{c1} & w_{c2} & \ldots & w_{cp}\\
% };
% \matrix(V)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]}] at (8,0)
% {
%  \phi_{1}(x) \\ \phi_{2}(x) \\ \vdots \\ \phi_{p}(x)\\
% };
% \end{tikzpicture}
% \end{center}
% On aura alors que le score $s_i$ de la classe $i$ sera donné en position $i$ dans $\mathbf{s}$.

% Il faut remarquer que le vecteur $\boldsymbol\Phi(x) = \phi_1(x) \ldots \phi_p(x)$ est valué par des fonctions features qui valent 0 dans la plupart des cas et 1 dans de rares cas. 
% Par  conséquent $\boldsymbol\Phi(x)$ est un vecteur creux.



% \subsection{Représentation de la matrice de poids par un vecteur}

% {\bf dire que ce cas s'applique aux problèmes structurés où
%   l'ensemble $Y$ est très large ou infini (récursivement énumérable)}


% Dans un contexte ou le vecteur $\boldsymbol\Phi(x)$
% est un vecteur creux de très grande dimensionnalité, 
% on utilise couramment une représentation alternative qui consiste à coder la matrice $\mathbf{W}$ dans un vecteur $\mathbf{w}$ unique. Dans ce contexte le vecteur 
% de features sera valué à 1 uniquement pour certaines features de la forme $\phi_{y1},\phi_{y2}\ldots \phi_{yp}$ qui correspondent aux poids de la classe $y$ pour la feature $i$. Dans ce contexte le vecteur de features est noté $\boldsymbol\Phi(x,y)$ où $y$ indique la classe pour laquelle on calcule le score.
% Ainsi pour calculer le score $s_a$ de la classe $a$,  on réalisera un produit scalaire avec une représentation du type~:
% \begin{center}
% \begin{tikzpicture}
% \matrix(W)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]}] at (-1,0)
% {
%  w_{a1} & w_{a2} & \ldots & w_{ap}& w_{b1} & w_{b2} & \ldots & w_{bp}&  w_{c1} & w_{c2} & \ldots & w_{cp}\\
% };
% \matrix(V)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]} ]at (5.5,0)
% {
%  \phi_{a1}(x) \\ \phi_{a2}(x) \\ \vdots \\ \phi_{ap}(x)\\
% };
% \end{tikzpicture}
% \end{center}
% où seules certaines features de la forme $\phi_{a\cdot}$ sont valuées à 1 alors que les features de la forme $\phi_{b\cdot}$ et $\phi_{c\cdot}$ sont implicitement valuées à 0.

% \section{Exemple de structure de données}

% Une large classe de modèles d'apprentissage utilisés en \ac{tal}
% fait intervenir des modèles creux. Il s'agit de modèles où le vecteur 
% $\boldsymbol\Phi(x,y) \in \{0,1\}^d$ est un vecteur booléen de très grande dimension.
% Les scores calculés par ces modèles sont essentiellement des produits scalaires de la forme :
% \begin{displaymath}
% s = \mathbf{w}\cdot \boldsymbol\Phi(x,y)
% \end{displaymath}
% où $\mathbf{w} \in \mathbb{R}^d$ est un vecteur de poids de dimension identique à $\boldsymbol\Phi(x,y)$. Dans ce contexte l'évaluation d'un produit scalaire revient à sommer les poids des features actives (mises à 1). 

% Les autres opérations importantes est la mise à jour des poids lors de la descente de gradient, ce qui demande d'additionner (ou de soustraire) le vecteur de poids courant avec le vecteur gradient.

% La structure de données ci-dessous exprimée en python apporte une fonction de produit scalaire ({\sl dot}) à partir des valeurs discrètes de $(x,y)$. Pour les mises à jour, elle propose une fonction de codage {\sl code$\_$phi} qui code une liste de valeurs discrète $x$ et renvoie $\boldsymbol\Phi(x)$ ainsi que des opérateurs arithmétiques de vecteurs et de scalaires ($+,-,\times, / , +=$).
% Celle-ci peut-être étendue à d'autres usages, par exemple la surcharge d'opérateurs arithmétiques pour vecteurs et scalaires peut être complétée.

% La structure de donnée reste néanmoins exprimée dans le but pédagogique de rester facile à lire et à modifier mais réalise la plupart des opérations de manière peu efficace.  Pour privilégier l'efficacité, il est suggéré de s'appuyer sur des librairies numériques qui supportent les opérations creuses ou de réaliser des interfaces avec du code {\sl C} ou {\sl C++} spécialisé pour réaliser les opérations sur des vecteurs creux.


\begin{minted}{python}
from collections import defaultdict

class SparseWeightVector:

    def  __init__(self):
    
        self.weights = defaultdict(int)   

    def __call__(self,x_key,y_key):
        """
        This returns the weight of a feature couple (x,y)
        Enables an  x = w('a','b') syntax.
        
        @param x_key: a tuple of observed values
        @param y_key: a string being a class name
        @return : the weight of this feature
        """
        return self.weights[(x_key,y_key)]

    def dot(self,xvec_keys,y_key):
        """
        This computes the dot product : w . Phi(x,y).
        Phi(x,y) is implicitly  generated by the function given (x,y)
        @param xvec_keys: a list (vector) of x values
        @param y_key    : a y class name
        @return  w . Phi(x,y)
        """
        return sum([self.weights[(x_key,y_key)] for x_key in xvec_keys])
        
    @staticmethod
    def code_phi(xvec_keys,ykey):
        """
        Explictly generates a sparse boolean Phi(x,y) vector from (x,y) values
        @param xvec_keys:  a list of symbols
        @param ykey: a y class name
        """
        w = SparseWeightVector()
        for xkey in xvec_keys:
            w[(xkey,ykey)] = 1.0
        return w

    def __getitem__(self,key):
        """
        This returns the weight of feature couple (x,y) given as value.
        Enables the 'x = w[]' syntax.	
        
        @param key: a couple (x,y) of observed and class value
        @return : the weight of this feature
        """
        return self.weights[tuple(key)]

    def __setitem__(self,key,value):
        """
        This sets the weight of a feature couple (x,y) given as key.
        Enables the 'w[] = ' syntax.	
        @param key:   a couple (x,y) of observed value and class value
        @param value: a real
        """
        self.weights[key] = value

    def __add__(self,other):
	    """
        Vector addition
        """
        weights =  self.weights.copy() 
        for key,value in other.weights.items() :
            weights[key] += value
        w = SparseWeightVector()
        w.weights = weights
        return w
        
    def __sub__(self,other):
    	"""
        Vector substraction
        """
        weights =  self.weights.copy() 
        for key,value in other.weights.items() :
            weights[key] -= value
        w = SparseWeightVector()
        w.weights = weights
        return w
        
    def __mul__(self,scalar):
    	"""
        Scalar multiplication
        """
        weights =  self.weights.copy() 
        for key,value in self.weights.items() :
            weights[key] *= scalar
        w = SparseWeightVector()
        w.weights = weights
        return w

    def __rmul__(self,scalar):
    	"""
        commutativity of scalar multiplication
        """
        return self.__mul__(scalar)
        
        
    def __truediv__(self,scalar):
    	"""
        Python 3 division '/'
        """
        weights =  self.weights.copy() 
        for key,value in self.weights.items() :
            weights[key] /= scalar
        w = SparseWeightVector()
        w.weights = weights
        return w

    
    def __iadd__(self,other):    
        """
        Sparse Vector inplace addition. Enables the '+=' operator.	
        @param  other: a  SparseVectorModel object
        """
        for key,value in other.weights.items():
            self.weights[key] += value
        return self
    def __isub__(self,other):    
        """
        Sparse Vector inplace substraction. Enables the '-=' operator.	
        @param  other: a  SparseVectorModel object
        """
        for key,value in other.weights.items():
            self.weights[key] -= value
        return self
            
    def load(self,istream):
        """
        Loads a model parameters from a text stream
        @param istream: an opened text stream
        """
        self.weights =  defaultdictionary(int)
        for line in istream:
            fields = line.split() 	
            key,value = tuple(fields[:-1]),float(fields[-1])
            self.weights[key] =  value
        
    def save(self,ostream):
        """
        Saves model parameters to a text stream
        @param ostream: an opened text output stream
		"""
        for key,value in self.weights.items():
            print(' '.join(list(key)+[str(value)]),file=ostream)

    def __str__(self):
        """
        Pretty prints the weights vector on std output.
        May crash if vector is too wide/full
        """
        s = ''
        for key,value in self.weights.items():
            X,Y = key
            if isinstance(X,tuple):
                s += 'phi(%s,%s) = 1 : w = %f\n'%('&'.join(X),Y,value)
            else:
                s += 'phi(%s,%s) = 1 : w = %f\n'%(key,Y,value)
        return s
\end{minted}

\appendix

\chapter{Exercice noté (descente de gradient)}

Implémenter sur le même jeu de données avec Y catégorique : 

\begin{itemize}
\item Descente de gradient (régression logistique hyperparamètres)
\item Une descente de gradient en vecteur sparse de type (modèle à large marge ; 
utiliser le fichier
\href{https://github.com/bencrabbe/parsing-at-diderot/blob/master/Multiclass.py}{\tt
  multiclass.py} et ajouter la méthode d'entrainement à large marge)
\item Une descente de gradient multiclasse avec une librairie comme Keras
\item Donnez l'accurracy du classifieur résultant sur les données.
\end{itemize}

\chapter{Exercice Noté (tagger)}

Le fichier \url{nn_tagger.py} propose un exemple de tagger unigramme avec un système de pondération basé sur 
un réseau de neurones à propagation avant.

\begin{itemize}
\item Méthode baseline : produire un tagger qui assigne à chaque mot le tag le plus fréquent observé avec les données
\item Exercice principal (base) : transformer le tagger unigramme en tagger bigramme, ce qui implique de changer la forme du jeu de données 
pour l'entrainement et d'implémenter l'algorithme de Viterbi pour la prédiction.  (ou de Dijkstra)
\item Exercice principal (alternative) : implémenter un tagger bigramme de la famille \ac{MEMM}
\item Formalisez une méthode de gestion des mots inconnus.  
\item Evaluez votre tagger en divisant les données en train et en test.
\end{itemize}
Vous pouvez vous insipirer des fichiers \url{crf.py} et \url{structured_perceptron.py} pour vous aider à formuler la solution.















\end{document}
